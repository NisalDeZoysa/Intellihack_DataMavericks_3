{
    "questions": [
        "How do these automated metrics for human preferences differ and what factors do they consider when predicting human preferences?",
        "What does non-differentiable mean here? If the problem with previous metrics is that they are not per-token differentiable then why are they looking for a way to optimize non-differentiable objectives?",
        "Why is the action space of language modeling particularly large? Is it because of the vocab size? But then, moving in the real world also has a huge action space (degrees of movement).",
        "What are actor-critic algorithms and how do they differ to other RL algorithms like Q-learning?",
        "What do the equations for Q-value and value represent?",
        "Why is it helpful to mask out less relevant tokens if these are less likely to be sampled anyways?",
        "Why is the masking policy only updated every certain number of steps?",
        "How did the token-masking policy help in the results?",
        "What is the combinatorial action space? How is this different to general RL tasks? Are they not combinatorial?",
        "For the images used for visualization in the paper, were they selected randomly or picked by the authors?",
        "Does the paper's DNN use a a larger width kernel or multiple smaller width kernels? ",
        "Why did the authors choose the four particular regularizations instead of others?",
        "What is meant by \"linear sweep\" in hyperparameter space?",
        "What are the examples of the tools that enable understanding of Neural Networks for newcomers in deep learning? ",
        "How did the authors compute the contributions of the pixels in order to clip the pixels with smaller contributions?",
        "How does a \"network-centric\" approach differ from a \"dataset-centric approach\"?",
        "What is an example of a \"dataset-centric\" approach?",
        "What is an example of a \"network-centric\" approach?",
        "What is meant by \"hacks\"?",
        "The paper's pre-trained network is nearly identical to the “AlexNet”. Does it use the same training set as the \"AlexNet\"?",
        "What is meant by \"row-major\" order?",
        "Why was a zero-centered input used for training the paper's DNN, instead of using the training images as input directly?",
        "For the paper's pretrained DNN, if the input does not contain a training set class, why does the probability vector show sensitivity towards the noise in input?",
        "The paper wished to only show the main object , letting other regions be exactly zero if they are not needed. How did the authors achieve it?",
        "How many hyperparameter combinations were used for the random hyperparameter search?",
        "The paper lists tools that enable understanding of neural networks for beginners. Have they mentioned the tools for expert users as well?",
        "The paper's model implies that the discriminative parameters also contain significant “generative” structure from the training dataset. What is meant by \"generative\" structure?",
        "How does the performance change when a dense retriever is evaluated on out-of-domain queries and documents that are different from the domain on which the retriever was trained?",
        "What kinds of relevant documents are missing, when lexical matching is used for retrieval?",
        "What are the factors that should be considered for memory footprint for indexing?",
        "What are pros and cons of these models illustrated in Figure 2, and what are distinctions of the proposed model?  ",
        "What if a query term can be matched to multiple document terms? Does MaxSim suffice for capturing query-document relevance, for this case too?",
        "What are the metrics they used for measuring efficiency and effectiveness?",
        "What are the different aspects that MRR@10 and Recall@50/200/1000 capture, as evaluation metrics for end-to-end retrieval performance ?",
        "If both queries and documents are short, is still the fine-granular interaction required?",
        "Targeting memory-efficient indexing, can we also prune out redundant tokens in documents while preserving a sufficient level of fine granularity?",
        "How much does the late interaction decrease computational costs, and how close is the performance of the late interaction model to the early interaction model?",
        "What kinds of distribution shifts are considered for evaluating retrievers on out-of-distribution datasets?",
        "Does a zero-shot scenario in this context refer to cases where relevance annotations are not available? Or are you referring to the case where the query set is also unavailable?",
        "If dense/sparse retrievers are pre-trained on target corpus to enable the retrievers to be corpus-aware, can the fine-tuned retrievers outperform lexical models?",
        "How is the \"relevance\" defined in TREC-COVID dataset? ",
        "What does \"speed\" mean in retrieval contexts? ",
        "What are examples where we have annotation holes?",
        "What are the motivation behind choosing TREC-COVID for analysis on annotation bias?",
        "Did the authors have an experiment showing the self-supervised learning can mitigate data sparsity issue?",
        "Does the paper show that the learnt user intents by clustering are orthogonal to the sequence embeddings?",
        "What metrics are used to measure the robustness of the model?",
        "Does the parallelization of transformer part of the proposed method reduce time complexity effectively?",
        "What are some examples of the SR model that uses deep neural network to encode user behavior sequences?",
        "How sparse is the real-world dataset used in the experiment?",
        "What was the value of maximum length T used for the experiment and how was the ratio of sequences that longer than length T?",
        "How does the paper show that the clustering result can be interpreted as users' intent?",
        "Why does the proposed method introduced EM framework to optimize the model (instead of directly optimizing the loss)?",
        "How does temporal context-aware embedding and twin-attention network enable LSAN to be lightweighted compared to SASRec?",
        "What properties of costrastive self-supervised learning have attracted attention from researchers in the recommendation field?",
        "Can the proposed methodology utilize user intent information associated with user interaction data if available?",
        "What does the proposed method BUIR require instead of negative sampling for training?",
        "Is it true that approximating the online encoder slowly make the target encoder keep from converging to the collapsed solution?",
        "What component of the model eliminates the effect of uncertain negative interactions after the positive interaction augmentation?",
        "What are the benefits of using the predictor to calculate user-item interaction score instead of directly encoding into their inner product?",
        "What does \"stochastic\" mean in the stochastic data augmentation technique that the author introduced?",
        "What value of momentum coefficient (τ) makes the BULR model perform best?",
        "In BUIR, how does the online encoder updated compared to the target encoder?",
        "Why does assumning unobserved user-item pairs negative leads to limited performance for generative methods?",
        "How did previous OCCF studies mitigated the problem of performance being largely depend on negative sampling distribution?",
        "How does the negative pairs prevent the problem of collapsed solution during optimization in contrastive learning methods?",
        "How does the authors show utilizing augmented views of positive interactions can lead the performance improvement, especially in sparser datasets?",
        "Does utilizing the multi-hop neighbor information in meta-graph help improve the performance of the proposed model?",
        "What components of the proposed method aggregate explicit knowledge into implicit knowledge for query and passage embedding?",
        "Does the paper show how each component of KERM can contribute to passage re-ranking performance quantitatively and qualitatively?",
        "Does the author showed that the distillation on the knowledge graph can be useful for re-ranking task?",
        "Who collected the queries from MSMARCO-Passage dataset to make MSMARCO-TRAIN query set?",
        "What methods refine the graph containing external knowledge in 1) global and 2) local way?",
        "What is the example of unreliable relations in knowledge graph for passage re-ranking scenario?",
        "What does \"meta\" means in the term graph meta network (GMN)?",
        "What is the other example of frameworks that can be used in PaddlePaddle like Paddle Graph Learning?",
        "How many entities and relations does ConceptNet has?",
        "How is next sentence prediction (NSP) different from sentence relation prediction (SRP)?",
        "How is DPR retriever different from BM25?",
        "What is the difference of RocketQAv1 and RocketQAv2 model?",
        "Would the performance be improved if the PLM model is pre-trained or fine-tuned on bio-medical domain datasets?",
        "What characteristics of large-scale pre-trained language models made it remarkable successful for passage re-ranking task?",
        "How does the knowledge distilation works if meta-graph can't be constructed (i.e. there is no corresponding entities in knowledge graph for query/passage)?",
        "Does this method likely to show similar tendency of performance improvement when other backbone model (like BERT_large) is used?",
        "Why does existing knowledge enhanced PLMs (such as CokeBERT and CoLake) cannot be used directly for re-ranking tasks?",
        "Would there be a performance gain if the model utilizes the IE (information extraction) model instead of the exact match for target entity recognition?",
        "How does TransE learns entity and relatio embeddings in unsupervised way?",
        "What is the maximum memory capacity of FPGA? ",
        "What is an example of an autonomous car that uses CNN?",
        "High accuracy is crucial for safety in autonomous vehicles. Would deploying smaller models using over-the-air updates in Tesla result in a trade-off with accuracy(and hence safety)?",
        "What is an example of an FPGA?",
        "What is an example of model compression approaches?",
        "What is an example of a \"module\" in CNN?",
        "What is an example of a DSE approach?",
        "What is the ratio of 1x1 filters in the total number of filters?",
        "How does the choice of layers, in which to downsample, affect the size of activation maps?",
        "Why did the authors use a mix of 1x1 and 3x3 filters in the expand layer of fire module?",
        "What is the total number of filters in squeeze convolution layer?",
        "The Caffe framework does not natively support a convolution layer that contains multiple filter resolutions .To get around this, the authors implement the expand layer with two separate convolution layers. What is the additional cost incurred by using two convolution layers?",
        "Did the authors use AlexNet for evaluation of SqueezeNet?",
        "How would the effectiveness of SqueezeNet's model compression be affected if a significantly smaller CNN is used instead of AlexNet?",
        "What was the size of model obtained by applying Deep Compression \nto SqueezeNet, using 33% sparsity and 8-bit quantization?",
        "To investigate the effect of the squeeze ratio on model size and accuracy, were the models fine-tuned or trained from scratch?",
        "Does complex bypass connections add extra parameters to the model?",
        "The paper mentions that SqueezeNet achieves AlexNet-level accuracy on ImageNet. Was the accuracy exactly the same as AlexNet or roughly the same?",
        " Why did the simple bypass achieve a higher accuracy improvement than complex bypass?",
        "The goal of authors regarding microarchitectural design space was to understand the impact of CNN architectural choices on model size and accuracy. Were they able to draw a conclusive impact?",
        "How YoloV3 calculates the sizes of the anchor boxes?",
        "How many total bounding boxes are predicted by YOLOv3 for all three scales?",
        "How the YOLOv3 algorithm calculates the coordinates of the predicted box from anchor box and output coordinates?",
        "Which data augmentation techniques YoloV3 algorithm used during training?",
        "Does DarkNet-53 backbone of YoloV3 uses any skip connections?",
        "Why the YoloV3 performs poorly with higher values of AP when compared with RetinaNet?",
        "Why the focal loss strategy did not worked for the authors? ",
        "YOLO detectors are now being used everywhere including both civil and military use. As a researcher how much authors should be concerned on positive and negative use of their research work? ",
        "What are some of the limitations of the YOLOv3 object detection model?",
        "Compare accuracy and speed of Darknet-53 with ResNet-101.",
        "In its loss function YoloV3 uses logistic regression with multilabel classification or Softmax over all class probabilities?",
        "YoloV3 is most suited for small, medium or large size objects?",
        "How does YOLOv3 improve upon previous versions of the YOLO object detection algorithm?",
        "In paper authors make the predictions at three different scales, but what is advantage of making object detections at different scales?",
        "How would the loss function of YoloV3 look after changing Mean squared errors with the logistic regression cross-entropy error terms?",
        "How many different types of experiments are performed to test the proposed models?",
        "Which variants of LSTM encoder-decoder models are used in this study?",
        "List down supervised and unsupervised tasks on which the proposed model is tested?",
        "Historically, which architectures have been used for supervised sequence learning tasks?",
        "How good the LSTM based encode/decoder work for real time applications keeping in view their sequential nature?",
        "The authors extended which baseline framework to learn representation of image sequences?",
        "Why the authors prefer to learn video representations through unsupervised models?",
        "How a target sequence is produced from a input frame sequence using LSTM?",
        "What are the different input types used for the proposed model?",
        "Why should LSTM based auto-encoder models learn good features?",
        "How the proposed autoencoder architecture prevent overfitting or identity mapping?",
        "How many future frames can be predicted by the proposed LSTM Future Predictor Model",
        "How the proposed LSTM future predictor model is different from the  Ranzato model.",
        "Why there is no need to label objects in videos for the encoder-decoder model.",
        "Why the conditional decoder is difficult to optimize?",
        "Out of conditional and unconditional decoder blocks, which one is better?",
        "Which datasets are used by the paper for supervised learning?",
        "Which datasets are used by the paper for training and testing of unsupervised learning?",
        "What is the average video sequence length used for experiments in this study?",
        "Does the features learned by unsupervised learning improved the performance of supervised learning tasks?",
        "What is the impact of number of training videos on the performance of supervised and unsupervised tasks?",
        "Which evaluation criteria was used to compare the performance of action recognition models?",
        "Which metric is used to compare different unsupervised models?",
        "Why is it a good idea to apply the convolutions across patches of the video instead of whole frames?",
        "What is kernel size used in each layer of SegNet?",
        "How the features are converted to pixel labels in SegNet?",
        "What is the advantage of stacking encoders and decoders for semantic segmentation?",
        "What is a major drawback of deep learning approaches adapting networks designed for object categorization to pixel wise labeling?",
        "Can we use image classification models for semantic segmentation?",
        "SegNet architecture is inspired from which domain?",
        "What are the total number of encoders and decoders used in SegNet?",
        "How many features are used in each layer of SegNet?",
        "What are the advantages of using a flat architecture in SegNet?",
        "Define local contrast normalization (LCN)?",
        "Are the test images released to the public after the competition is finished each year?",
        "How are the images for this challenge collected for each category?",
        "Does the challenge also include a workshop to discuss the ideas?",
        "How long is this challenge been running?",
        "ImageNet challenge benchmarks which problems in computer vision domain?",
        "What is the difference between classification and object detection?",
        "How many images do the ILSVRC dataset has?",
        "Objects are divided into how many classes in the ILSVRC dtaset?",
        "What added benefits do the ILSVRC provide over the existing PASCAL-VOC challenge?",
        "Is taking a closer look at the current state of the field of categorical object recognition the only goal behind this challenge?",
        "Fast YOLO processes double the mAP of other real-time detectors, what is the actual value of the mAP ?",
        "What are the metrics used to compare the performance between YOLO & DPM/RCNN?",
        "How did the authors verify that YOLO learns very general representation of objects ?",
        "The authors claim that autonomous cars would be able to drive without specialized sensors using only fast and accurate algorithms, is that true ?",
        "What does the authors means by reframing object detection as a \"single regression problem\" ?",
        "What is the ratio of background errors that Yolo does compared to Fast R-CNN ?",
        "Since YOLO sees the entire image during training and testing, doesn't it influence badly on its performance ?",
        "Is it true that YOLO is highly generalizable and performs well in new unseen data ?",
        "What is the speed of YOLO, when it pushes its mAP performance to 63.4% ?",
        "According to the authors, the VGG-16 version of Faster R-CNN is 6 time slower than YOLO, what is the actual speed of the model ?",
        "What motivated the authors to choose the Pascal VOC 2007 dataset to compare YOLO with other models ?",
        "Why was the IOU metric used and not other segmentation metrics such as the Dice coefficient?",
        "Yolo makes different kinds of mistakes, but it is still really accurate, wouldn't that play against it when using it to boost Fast R-CNN ?",
        "Why does YOLO struggle in localizing objects correctly ?",
        "Why did the authors chose to train YOLO using VGG-16 and not other neural network architecture ?",
        "Why does Yolo outperform R-CNN in other categories such as cat and train ?",
        "What is \"“Vector of Locally Aggregated Descriptors” image representation ?",
        "To obtain the final compact descriptor of the image, why did the authors use PCA instead of other compression algorithms?.",
        "What is the number of images in the dataset, that is gathered by the authors to train the architecture for place recognition?",
        "All the relevant learning-based approaches fall into one or both of the following two categories: (i) learning for an auxiliary task , and (ii) learning on top of shallow hand-engineered descriptors that cannot be fine-tuned for the target task. How does the authors' approach differs from these two categories?",
        "What is the relative improvement achieved by authors over the other benchmaeks for image retrieval?",
        "The output VLAD image representation matrix is converted into a vector and, after normalization, used as the image representation. What is the normalization method used by authors?",
        "How does the NetVLAD layer differ from the original VLAD?",
        "Can the the NetVLAD pooling layer be inserted into any other CNN or does it support certain architectures?",
        "Did the authors use the entire Pittsburgh (Pitts250k) dataset for experiments or did they use a subset of the dataset? ",
        "Is Google Street View Time Machine used for the first time to create a dataset by the authors, or has it been previously used in another reserach?",
        "What metric is used to compare VLAD methods with their Max pooling counterparts? ",
        "What are the metrics used to compare authors' approach with image retrieval benchmarks?",
        "What are the two place recognition benchmarks used by the authors?",
        "The authors crop the CNN at the last convolutional layer and view it as a dense descriptor extractor. Why did the authors do the cropping at the last convolutional layer and not in the middle?",
        "What does \"multi-orientation pooling\" means ?",
        "The authors claim that low-frequency information in 3D is discriminative for object classification, is that true ?",
        "How can auxiliary tasks help the volumetric CNN avoid overfitting and improve performances ?",
        "How can anisotropic probing kernel encode long-range interactions between points of 3D objects ?",
        "Wouldn't training on sub-volumes of a 3D object that isn't much representative of the global object affect the learning of the model negatively ?",
        "The authors claims that the probing mechanism combined with multi-orientation pooling can capture any 3D structure, is this true ?",
        "How are 2D multi resolution filter approaches similar to 3D approaches ?",
        "Why did the authors chose the ModelNet dataset for evaluating the developed architectures ?",
        "Who were the annotators of the new real-world scanning dataset used for real-world reconstruction ?",
        "Why didn't the authors try different methods of data augmentation for 3D objects ?",
        "Why did  the authors didn't use other metrics to evaluate/compare the performance of the architectures ?",
        "What are the difference and similarities between volumetric representations CNN &  multi-view representations CNN ?",
        "What is the reasons that made the authors choose the 3D data from CAD model & RGB-D sensors ?",
        "Why was the model trained with synthetic data rather than reel 3D data directly?",
        "What does \"2.5D data\" means ?",
        "Is there a reason of not realizing pre-processing techniques to the real data to remove noise before the training ?",
        "What does \"anisotropic probing kernel\" means ?",
        "Why did the authors choose a format of the 3D input as 30x30x30 ?",
        "Is it true, as the authors suggest, that a neural network's depth is essential to its success?",
        "What does \"information highways\" mean ?",
        "What makes the extremely deep architectures important to study ?",
        "The authors claims that the LSTM networks systems allow the flow of information across many layers without attenuation, is that true?",
        "What are the difference between plain networks and deep highway networks ?",
        "Why is the carry gate C can be expressed in function of the transform gate T with C = 1 - T ?",
        "From the left graph of Figure 1, we observe that even the deepest highway network has same/worse performance than the plain network, so what are the benefits of using the highway networks with deeper layers ?",
        "What hyperparameters values were used to train both the plain and highway networks ?",
        "Does it really assist bridge long-term temporal dependencies early in learning, as the authors say, to bias the gates in LSTM networks initially?",
        "What are the reasons behind the guidelines of choosing values of {-1,-2 and -3} for the initial bias for convolutional highway network of depth {10, 20 and 30} ?",
        "The authors claim that no attention mechanism has been applied for image classification task before, is that true ?",
        "What do the authors mean by attention-aware features in the context of images ? ",
        "They claim that the attention mechanism bring more discriminative feature representation, is that true ?",
        "Which specific metrics are improved when increasing attention modules ?",
        "What are the metrics used to compare the performance of the residual network to the other models ?",
        "What are the consequences of stacking a really big number of attention module in the performance of attention modules? ",
        "How would stacking attention modules directly woud lead to performance drop? Why is the attention residual learning mechanism necessary?",
        "What does \"bottom-up top-down feedforward structure\" means ?",
        "Why was ResNet network chosen as baseline method ",
        "Is choosing NAL as a baseline a good choice knowing that it always results in performance drop ?",
        "The authors claims that the  performance increase with the number of attention module, is that true, knowing that they tried only m = {1,2,3,4} ?",
        "How is using an encoder-decoder structure as a mask different than local convolutions soft masks, a part from the test error ?",
        "What does the confusion matrix Q in the authors noisy label robustness experiment refers to?",
        "Why did the authors chose to do experiments on different basic units to prove the generalization of the residual attention network?",
        "They claim that in brain tumours, there is a hierarchical layout of sub-components. Is this True ? Any related experiments that proved it ?",
        "What are the examples of the high level features that separate the anatomical structures for lesions regions identification ?",
        "Is using 46 Images for training and 15 images for testing enough for the model to learn the features well and generalize to new unseen cases ?",
        "Why does a deeper network with smaller kernel size have better performances ?",
        "What are the signs that showed that BigDeep+ has been overfitting ?",
        "The authors claim that the brain MRI scan are often anisotropic, is that true ?",
        "Who were recruited to annotate the visible lesions? and what did they base their annotation on ?",
        "What are the benefits of normalization with zero-mean techniques compared to other normalization techniques? have they been tested ?",
        "How did the authors showed that the methods performed worse on the data coming from the second clinical center? Using which metrics ?",
        "The authors claims that DeepMedic  behaves very well in preserving the hierarchical structure tumours, is that true ? Have they tried it across different types of varying cases?",
        "The brain tumour segmentation data consists of 274 cases in total, is this dataset large enough to not consider adding regularisation technics ?",
        "Why did the GAN-based image editing approach succeed only on highly curated datasets and struggle over large and diverse datasets?",
        "How is deep spatial features of the noisy image \\phi(z_t) different from noisy image z_t?",
        "Why the slightest change in the textual prompt can lead to a completely different output image in the large-scale language-image models?",
        "What are the examples in which important structural information is removed when masking the image content?",
        "What does \"interaction between the pixels to the text embedding through the diffusion process\" mean?",
        "How the embeddings of visual and textual features are fused during the noise prediction process? ",
        "Are both of them use user-provided masks for guidance but Diffusionclip (Kim et al.) perform global changes while Blended diffusion (Avrahami et al.) perform local manipulations? ",
        "Do only Blended diffusion (Avrahami et al.) use user-provided masks for the guidance of manipulation? ",
        "What is the difference between deep spatial features of the noisy image \\phi(z_t) and noisy image z_t? ",
        "The reason why the diffusion step can be applied on both z_{t-1} and z^*_t in parallel is their one timestep difference is matched each other. Is it right?",
        "Is there any benefit to using fader control instead of numbers (e.g., percentages)?",
        "How is the inversion of text-guided diffusion models different from the inversion of GAN?",
        "What does distortion-editability tradeoff mean?",
        "How do the authors recognize that reducing the classifier-free guidance parameter improves reconstruction but constrains the ability to perform significant manipulation? ",
        "How can the mask extracted directly from the attention maps mitigate the limitation of inversion process? ",
        "Attention maps are calculated by query of spatial feature of the noisy image (\\phi(z_t)) and key of textual embedding (\\psi(P)). Is it true?",
        "How can the authors verify if the attention reflects the overall composition of the given image? ",
        "How does the timestamp \\tau control for stylization, specification of object attributes, or global manipulations for editing image by text prompt?",
        "Did the method proposed in this paper perform on par with or better than the state-of-the-art methods that require users to provide spatial masks for editing?",
        "What are the examples of suitable prompt for inversion?",
        "They generated the cross-attention output weight by calculating the similarity between spatial features of the noise image and textual embedding. Is it right?",
        "Who is responsible for designating the control signal?",
        "What is the example of ideal control signal?",
        "How does a role-shift captioning model contribute to generating captions?",
        "How do the authors verify that the two characteristics mentioned in the sentence are indispensable for the ideal control signal?  ",
        "Are control signals hyper-parameters or not?",
        "How are objective control signals more advantageous than subjective control signals when controlling the caption generation process?",
        "What is the big reason of making difficult to decide whether a control signal is sample-suitable in advance? ",
        "What are the metrics used to evaluate the trade-off between the quality and diversity of generated captions?",
        "What are the examples of sub-roles?",
        "What does the b of the sub-role, s^b_i mean in the semantic structure of sentence S?",
        "How is N, the number of disjoint sets of proposals determined?",
        "What types of control signals are present?",
        "Do α control the strength of the length normalization and β control the strength of the coverage penalty each other?",
        "How can the attention mechanism connecting the bottom layer of the decoder to the top layer of the encoder contribute to improving parallelism?",
        "In terms of the effectivenesses of coverage penalty and length normalization, how does having RL-based model refinement differ from not having RL-based model refinement?",
        "What are the weaknesses of conventional phrase-based translation systems compared to neural machine translation? ",
        "What are the roles of attention connections from the decoder network to the encoder?",
        "How is “character”-delimited models different from “word”-delimited models?",
        "How can the limited set of common sub-word units (“wordpieces”) provide a good balance between the flexibility of “character”-delimited models and the efficiency of “word”-delimited models?",
        "Why do NMT systems sometimes produce output sentences that do not translate all parts of the input sentence?",
        "Is there a disadvantage to using low-precision arithmetic for inference, such as decreased inference accuracy?",
        "Is it true that they used the output from the bottom decoder layer for y_{i-1}, not the decoder-RNN output from the past decoding time step?",
        "In the model architecture described in this paper, how many residual connections are used?",
        "Is the trained wordpiece model the same as the Google speech recognition system developed to solve a Japanese/Korean segmentation problem the authors mentioned above?",
        "Why is there a larger number of basic characters used for Asian languages than for Western languages?",
        "Does the task reward function in this context mean the translation task-related reward function?",
        "Is the \\delta a hyper-parameter?",
        "Why are the constraint value of δ and γ separated?",
        "What kinds of domain knowledge do the authors refer to in this context?",
        "How does the size of a large neural network for NMT affect memory?",
        "What are the pros and cons of a global approach and a local approach?",
        "How are hard attention models different from soft attention models?",
        "What kinds of alignment functions are used for their attention-based models?",
        "What kinds of RNN architectures were used for the decoder in various prior research?",
        "How are the RNN architectures used for the decoder in prior research different from each other?",
        "In this sentence, do the current target state and all source states mean hidden states of the encoder?",
        "What does \"variable-length alignment\" mean?",
        "Why did the authors use hidden states only at the top LSTM layers in both the encoder and decoder?",
        "Why is the \"hard attention model\" non-differentiable?",
        "How is the tokenized BLEU different from the NIST BLEU?",
        "What was the size of the model?",
        "In Figure 6, why are the BLEU scores fluctuating when the sentence lengths are less than 40?",
        "Why did the dot scoring function perform well for global attention while the general scoring function performed well for local attention? ",
        "How did the attention method contribute to word alignments?",
        "Alignment functions refer to 4 calculation methods (dot, general, concat, location) for obtaining an alignment vector. Is that true?",
        "The cited papers are in the NLP domain, while this paper targets Text-to-Video generation. How did the authors have confidence in adopting unsupervised learning techniques that could perform well in this Text-to-Video domain as well?",
        "How short is it? What if the video that I want to generate is longer than its limitation? It would not be very pragmatic if it has too many restrictions in its length.",
        "What kind of text prompt does it contain? What were the criteria to set these prompts?",
        "How can we define text-video paired dataset? For example, how long each video should be and how long should be the text description?",
        "To me, it sounds like an excuse for not collecting the dataset. How difficult is it to collect an open-source text-to-video dataset? What kind of procedure does it contain?",
        "Can the number of frames be extended to more than 16? If exists, what is the upper bound for the number of frames?",
        "How is this x converted to y using which network?",
        "Does it have to be integrated into the network in an end-to-end manner? I guess it could make the network heavier.",
        "How can this prevent flickering artifacts? Any backup publications for further explanation?",
        "Does this bring better performance? If so, what is the reasoning for this?",
        "How can this value be calculated? Why does the authors set the value as 0.5?",
        "What if the text prompt is exactly the same? I guess there can be cases where the text prompt is the same, but the videos are different. Did the authors remove such cases prior to running the evaluation?",
        "Does this also guarantee a generalizable performance over several domains? Did the authors evaluate the performance by specific domain?",
        "We also collect a test set of 300 prompts for zero-shot T2V human evaluation which we plan to release",
        "As a result, a model that has only seen text describing images is surprisingly effective at generating short videos, as demonstrated by our temporal diffusion-based method. Make-A-Video sets the new state-of-the-art in T2V generation.",
        "Unsupervised learning has long had great success in advancing the field of natural language processing (NLP) (Liu et al., 2019a; Brown et al., 2020).",
        "Does lower FVD value mean more coherent generation? What is a coherent video in the first place?",
        "What are the reasons for such results? Why does it excel in such cases?",
        "I believe T2I models can do this using latent exploration. What is the difference between them? What is novel about T2V’s interpolation?",
        "Is there any other method to do this instead of simply averaging the values out? There can be a smarter way to do this.",
        "the generated videos inherit the vastness (diversity in aesthetic, fantastical depictions, etc.) of today’s image generation models.",
        "How could this vastness be defined or quantitatively measured?",
        "Does this use text input as well or not? I thought it should use a text prompt to reflect a natural flow of images, but it does not seem to.",
        "Can’t it be generated by video interpolation? I thought we can do this by giving two images and running interpolation.",
        "What does this initial results mean?",
        "Does making higher resolution have to be incorporated into the network? Can't we do this as a separate process?",
        "What does it mean to perform better in Text-to-Video generation? Does it mean that generated videos are aligned well with the text description?",
        "What does this condition include? Text input?",
        "How does the authors accommodate the video datasets?",
        "I was wondering whether this results came from various settings (e.g., training only on video dataset).",
        "Why does it have to be fixed? Can't we extend it to more frames?",
        "What is the reason for doing the joint training? Does it related to the model performance?",
        "Is there a rule or criteria to have certain number of frames per second for a video? I think the number of frames per second can bring some bias in training.",
        "I understand that the quality of xb depends on xa. So the quality could get worse if we generate more frames?",
        "Why did the authors focus on the verb? Is there any reason?",
        "Just out of curiosity, how humans are so well at this? Cab human's technique be used for the machines as well? or do we need a totally different approach?",
        "How efficient it is?",
        "How about other terms like adjective?",
        "What is the reason for adopting this?",
        "Does it have any performance degradation if we generate too many frames?",
        "What is the reason that the space-time attention does not work well to generate consistent content?",
        "Is it inspired by transformer network?",
        "How does this v1 related to generating consistent content?",
        "Is there any limitation of this technique?",
        "How well RoBERTa language modeling on Wiki-40B?",
        "Are English pretrained language models good at transfer to other language?",
        "Why the authors suggest there is no truly monolingual pre-trained model?",
        "What kind of pretrained language models they mentioned?",
        "How could English models performs well on non-English POS tasks?",
        "What is the difference ratio of non-English text in pretraining data between T5 and RoBERTa?",
        "What is training method used for decreasing the gap between monolingual model and multilingual model?",
        "What are the two factors to show potential reason for cross-lingual generalization",
        "How did the authors find potential causes of cross-lingual transfer?",
        "What is the correlation value between target pretraining data size and model performance for latin data on T5? ",
        "Which factor is more related to model performance between pretraining data size and language similarity?",
        "What is the role of non-English data for English pretrained models in the finding?",
        "What is used for measure the quantities of non-English data?",
        "What are two kinds of pretrained language models?",
        "What is the range of the number of non-English tokens found in English corpus? ",
        "Is there any problems from using web crawl data? If so, what is the problem?",
        "How many categories used in non-English text classifier?",
        "Is the line contains both English and non-English text is the most common in classifier?",
        "What are tasks to show how well English models tend to be multilingual?",
        "Is RoBERTa better for cross-lingual transfer rather than BERT?",
        "What are the pretraining datasets used in analyses?",
        "There is a mention of using search depth as halting criterion. Are there alternate ways?",
        "Based on the results of the baseline and other models, will you rule out occurrence of overfitting in the data? How?",
        "How were the 50 examples chosen for proof accuracy?",
        "From the sign agreement, one can see improvement in accuracy with facts. Why?",
        "How can Lambada be adapted for other NLP tasks?",
        "How different would a BC version of chain of thought be than Lambada model?",
        "In one of the examples in the paper, the longer rule gave validated fact check over short rule. Does that hinder your intuition?",
        "Does prediction of Unknown values have an influence on proved and disproved?",
        "Will doing batch calls use cached values?",
        "Will results be similar for 5 hops?",
        "How can you come to the intuition that shorter rules have smaller sub goals?",
        "How is it better to decrease the depth by 1 over other values?",
        "Are the results similar for other variants of values, given test set has only 1000 examples?",
        "Doesn’t the possibility of having many rules make it ambiguous?",
        "Given the triggered sentences, how can this problem be rectified?",
        "Doesn’t breaking the problem into sub problems increase computation?",
        "How trustworthy are the ML decisions made by the system?",
        "How are other questions handled?",
        "Did the authors use commonly used one-vs-all scheme for extending DeepFool method to the multiclass case?",
        "How is the authors' work different from the “fast gradient sign” method?",
        "What does an \"adversarial perturbation\" mean?",
        "What are the metrics used to compare the efficiency of different methods which compute the adversarial perturbations?",
        "What does an \"affine classifier\" mean?",
        "What is the value of η used by the authors in experimentation?",
        "The paper's algorithm yields very small perturbations which are believed to be good approximations of the minimal perturbation. Quantitatively, how far is the paper's approximation from the minimal perturbation?",
        "Why did the authors choose a greedy approach for general classifier?",
        "Which deep neural network architectures were used for experimental comparison of DeepFool algorithm with existing methods?",
        "Why did the authors measure the perturbations using the L`2 norm?",
        "How can the DeepFool algorithm be adapted to find minimal adversarial perturbations for any L`p norm?",
        "What is most important feature in hair fall disease model ? Is it false positive or false negative rate?",
        "What are the possible reason androgenetic alopecia or MPB is less severe in women as compared to men?",
        "What were the various treatment found in ayurved for hair loss?",
        "How does immune therapy helps in resolving AA ?",
        "According to the author most hair and scalp disease is diagnosed in advanced stages. What could be the possible reason behind this ? How can we sensitize people for early diagnosis of hair disease?",
        "What were the various sources of data collection in the paper?",
        "What were the various pre processing techniques used before feeding the data to Neural network?",
        "Can CNN used in hair disease prediction really give very high accuracy,  given not enough dataset is present for training of model?",
        "How does the author conclude that non-local means filter is the best filter for denoising the images ? Are there any other filters that can be used for the same task?",
        "How CLAHE is better than HE for image equalization?",
        "What is 'autokeras' ? How it works?",
        "Author took batch_size to be 16 with 50 epochs while training the model . What was the intution behind taking these particular numbers?",
        "What were the various hyperparameter used in 'grid search'?",
        "Can using more epochs while training may increase the validation accuracy ? if no why ?",
        "Does the author believe using pretrained models may have resulted in better accuracy in classification?",
        "Why in the case of Alopecia areata the body's immune cell can't recognise hair follicle as 'self?",
        "Is it true that More than 15% of all deaths in children younger than\n5 is  due to Pneumonia ?",
        "What is difference between CNN and D-CNN?",
        "Which ensemle learning avg. probablity or weighted avg. probablity is used by the author in modelling?",
        "How does the author take care of class imbalance problem?",
        "How does author take care of imbalanced class problem?",
        "What are the various category of architecture author talks about in this section?",
        "How many extra image is generated for each class?",
        "Was there any particular reason for using the set value of various parameter ? If yes then what were the reasons?",
        "Why does author use K-mode instead of K-means?",
        "What are 'AVI-AI' administrative systems?",
        "What are various features used to judge person facial emotion and speech emotion ?",
        "How does AVI-AI model functions?",
        "How does the proposed model increases the reliablity of the assesment?",
        "Is it true the proposed model enhances the efficiency of the interviews?",
        "What are the various component of individual work performance?",
        "Is AVI followed by certain set of questionnaire for the implementation of model?",
        "How does the author choose optimal number of cluster in the proposed model ?",
        "Can image content and style be \"fully\" or \"completely\" separated?",
        "Which loss function is used by authors during image synthesis? ",
        "To carry out manipulations in feature spaces, did the authors use a pretrained Deep Neural Networks or trained the model from scratch?",
        "Why did the authors particularly use \"Gradient Descent\" instead of any other optimization algorithm?",
        "What does a \"Gram\" matrix mean?",
        "What is the benefit of using \"white noise\" instead of any other noise like Salt-and-pepper or Gaussian noise?",
        "The authors measure mean-squared distance between the entries of the Gram matrix from the original image and the Gram matrix of the image to be generated. Which distance measure did they use (For example, Euclidean distance, Manhattan distance etc.)? ",
        "How was the ratio α/β of weighting factors for content (α) and style reconstruction(β) used by the authors?",
        "What is an example of usefulness of authors' work for experiments concerning electrophysiological neural recordings?",
        "Would the reconstruction from higher layers be as good as reconstruction from the lower layers? Why or why not?",
        "How did the authors ensure to keep the factor wl equal to one divided by the number of active layers with a non-zero loss-weight wl?",
        "What makes SBM-Transformer novel compared to existing efficient Transformer variants?",
        "What is a mixed-membership Stochastic Block Model?",
        "In what way can SBM-Transformer be considered better than Reformer?",
        "What is a \"Hamiltonian path\"?",
        "What is \"local attention\"?",
        "How is the \"average attention sparsity\" measured in the experiments?",
        "Why was the random edge exploration technique used during training of SBM-Transformer?",
        "Transformers are typically used with multiple attention layers and heads. Why did the authors use a single-layer single-head Transformer architecture for the synthetic task of finding repeated tokens?",
        "The forward step of SBM-Transformer requires additional parameters and computation compared to the original Transformer architecture due to SBM sampling. Is this additional cost outweighed by exploiting sparsity?",
        "Why is each attention head equipped with a 2-layer MLP in particular?",
        "The proof of Theorem 1 is a direct application of previous results on sparse Transformers. What is the exact significance of this theoretical result?",
        "Considering that GMPool requires matrix decomposition, how good is the efficiency aspect of the algorithm? Can the algorithm be used for large graphs?",
        "How does NGMPool work exactly? How is it different from GMPool?",
        "The paper mentions Eigenvalue Decomposition (EVD) as well as Singular Value Decomposition numerous times. How are the two related, and how are they different?",
        "How was the hyperparameters chosen for the baseline methods, and what were the chosen values for he experiments presented?",
        "What makes GMPool and NGMPool novel compared to existing graph pooling methods?",
        "Why did the authors choose to test the proposed graph pooling method specifically on molecular property prediction tasks?",
        "How do the authors deal with the numerical instability that may occur due to incorporating SVD into the proposed method?",
        "Would it be possible to reduce the asymptotic cost of GMPool from cubic to quadratic, yet retain its expressive power?",
        "The paper mentions GMPool can be used with any GNN architecture besides DMPNN. Are there any results leveraging more recent GNN architectures such as GIN or Graph Transformers?",
        "Why is deduplication chosen as one of the baselines?",
        "Only a small number of examples (32) are randomly selected to be unlearned. Have the authors tried unlearning much larger portions of the training data and observing the effect on the resulting model?",
        "How much does the success of the EL metric vary depending on which n tokens are used as a prompt for this metric?",
        "Why not just use membership inference attack recall [1,2] and exposure metric [3], which are commonly used and established metrics? These two basically do what the currently proposed metrics do.",
        "How was the value of n set to 10?",
        "What happens when we perform unlearning for really big LMs?",
        "What does the author mean by “empirically” consider some token sequences to be forgotten? ",
        "What was Memorization Accuracy Metric first used to quantify? ",
        "What is the reason the standard deviation is not shown in the table?",
        "How is the proposed work different from the previous works using Transformer-based VAE frameworks in terms of representation learning? ",
        "Why would melody harmonization task be important for understanding human composition?",
        "What is the benefit of using note-based representation over grid-based representations?",
        "The authors claim that LSTM-based approaches have failed to capture realistic pattern of chords. Is it true?",
        "Is TimeToNote method truly a novel idea to capture a musical hierarchy? It seems to be just a simple trick that also have been used in one of the previous music generation studies (MuseMorphose, 2021).",
        "What does \"global key signature\" mean?",
        "How \"chord coverage\" can represent chord complexity, which cannot be simply defined without considering the human perception of music?",
        "Why does the objective for STHarm not include condition c?",
        "What is the benifit of using the HLSD dataset that does not contain various key signatures for evaluating the models?",
        "Were the baseline models implemented from scratch or from existing codes from the original authors?",
        "The authors seem to mention specific reasons only for lambda KL. Did the authors conduct any ablation study to decide lambda Reg? ",
        "What is the difference between TPSD anc DICD?",
        "Generating average chords and low diversity score are not analogous. Is it true that STHarm generates \"common\" chords that are frequent in real-world music?",
        "How is a harmonic similarity to human music connected to the structuredness of chord patterns?",
        "Why can't training VTHarm guarantee a disentangled representation of the desired aspect? ",
        "What would be a proper measure to quantize how the attention maps differ by a value of alpha?",
        "What is the reason to select these three values for alpha?",
        "What is the benefit of rVTHarm compared to VTHarm, although it does not show the best scores in any of the metrics in Table 5?",
        "Is it valid to conclude that the baseline models are weaker than the proposed models since they generate some syncopated rhythms of chords?",
        "In the decoder input, what is the \"beginning\" over which the latent variable z and the key signature token c are added? Is it a <bos> token?",
        "Key signature may be helpful to constrain harmonic context. Then, wouldn't it be more valid to conduct an ablation study on chord coherence rather than harmonic similarity?",
        "What would be an example of the methods that explore the effect of melody awareness?",
        "What are some examples of \"explicit planning\"?",
        "What is the difference between IsTopVoice and PositionInChord?",
        "Why didn't the authors intend a \"chord\" to represent a more meaningful unit in music, such as a beat?",
        "Is there no temporal dependency between the latent variable for explicit planning?",
        "Why did the authors use a polynomial function to extract explicit planning of the performance data?",
        "Why did the authors use only one composer rather than several composers together?",
        "Why didn't the authors use the previous studies mentioned in the Introduction section as baseline models?",
        "What is the reason for using the reconstruction metric calculated from zero explicit planning?",
        "Why did the authors use the randomly sampled z(str) to measure explicit planning, while using z(pln) from zero explicit planning to measure structural attributes?",
        "Why didn't the authors try the listening test for the samples from non-zero, realistic explicit planning, like other performance rendering studies?",
        "How can the difference between the black and orange lines, which represent two samples from different z(str), be specificaly interpreted from a musical perspective?",
        "What is the difference between conducting polynomial regression and predicting explicit planning with the learned representation?",
        "What would be the possible genres or composers to use in the experiments for further investigation?",
        "Among the 5 GNNs used for evaluation, is there a GNN for heterogeneous graphs?",
        "Why does negative transfer occur when learning with auxiliary tasks? ",
        "How did the authors design the meta-path prediction task? ",
        "What do challenging auxiliary tasks mean?",
        " How can Hint Network help with challenging auxiliary tasks?",
        "How does this paper experimentally show that auxiliary tasks are not beneficial?",
        "Have the authors experimented with extending to other auxiliary tasks other than meta-path prediction?",
        "What is a meta-path? Please explain with examples.",
        "What is the role of meta-data in the proposed method?",
        "Why is bi-level optimization for meta-learning difficult?",
        "What is the anchor point in this paper?",
        "What does it mean the realistic sample?",
        "Why should the proposed method have smoothly varying weights for transformations?",
        "Why is it necessary to maximize the coverage of anchor points?",
        "What is the difficulty of augmentation on point clouds compared to augmentation on traditional 2d images?",
        "What does non-linguistic means?",
        "Is this true? Despite using three different pretraining data (text domain), the model shows similar accuracy in big sample case.",
        "Does codeBERT trained by natural language?",
        "Does DeBERTa has a larger representations dimensions than BERT large?",
        "According to the paper, does BERT is overfitted?",
        "Is odd classification task is linguistic?",
        "Is this true?: Calculating length of a string is string reasoning task.",
        "Is this true? NILM has only classification tasks.",
        "How is SNLI sort and SNLI shuffle different?",
        "How Zipf distribution and Uniform distribution different?",
        "How is this paper and other previous works which have explored the ability of RNN and Transformer architecture?",
        "What does NILM means? Is it different to GLUE?",
        "What does SNLI means? Is it a model?",
        "Explain Mode task in Decimal & word operation with examples.",
        "What does inductive bias means?",
        "Explain the motivation of this paper",
        "What is the major one structural difference between ELMO model and others (BERT small, BERT large, DeBERTa)",
        "Why author said that underperformance of non-pretrained models comes from small data?",
        "Why author did 7.3 Non-english and computer languages tast? What is the objective of this section?",
        "what is the evidence for auther’s saying: “Our observation that is behavior is seen even when pretraining on synthetically generated languages”?",
        "Look Figure 4.  Give your one observation by comparing (a) and (b), or pretrained and non-pretrained. Reason them.",
        "What are the examples of offline RL algorithms that are not straightforwardly applicable to the task-oriented dialogue domain?",
        "How does the author show that the algorithm is free from the issue of diverging from human-language?",
        "What are the metrics used to evaluate the performance in terms of task success?",
        "What are the metrics used to evaluate the naturalness of the sentences generated by the policy?",
        "Did the authors have an experiment with training the state-of-the-art offline RL algorithm with MultiWOZ dataset?",
        "CRR is also an algorithm that is free from issues that diverge from human language. What are the advantages compared to CRR?",
        "They claim that the proposed algorithm can maintain the GPT-2’s ability to generate human-like responses while improving the task performance. Is this true?",
        "Which of the baseline algorithms are the offline RL algorithms?",
        "How are actions defined in task-oriented dialogue?",
        "What does “KL control” means?",
        "What does “offline RL” means?",
        "What is “overestimation issue” in RL?",
        "What are the examples of offline RL algorithms that are applicable to the task-oriented dialogue domain without diverging from human language?",
        "How is learning a task-oriented dialogue agent different from the problems in the RL domain?",
        "What is main different between the experiments on MultiWOZ and ConvLab?",
        "How is the proposed method free from the issue of diverging from human language?",
        "How does the proposed method address the issue of large action spaces?",
        "They claim that the proposed policy update guarantees the policy improvement. Is this true?",
        "Why are most of the existing offline RL algorithms not straightforward to apply to the task-oriented dialogue?",
        "Why does the proposed algorithm not outperforms in turn metric in the results of ConvLab experiments?",
        "In the human evaluation, what does the author want to show differently from MultiWOZ and Convlab experiments?",
        "What is different between the results denoted by planning and learning in Table 2.",
        "Did the authors have an experiment with training the state-of-the-art RL algorithm on the Jericho envrionment?",
        "Which of the baseline algorithms are the planning-based RL algorithms?",
        "Which of the baseline algorithms require the resettable simulator?",
        "What is the hyperparameter of the proposed method? How did you tune it? ",
        "[Section 4.2]: What characteristics do the aforementioned datasets in transfer learning have? ",
        "Why should we care about the batch size in cost of performance on the unsupervised representation learning methods?",
        "Is it possible to say the proposed method learns better representation? What is the meaning of the downstream tasks?",
        "Why is it adequate to say this problem is strictly convex? ",
        "How does the proposed method address the issue of cluster collapse?",
        "How does the cluster-based method learn meaningful representation from scratch?",
        "Can clustering-based self-supervised approaches learn a piece of local information? If not, task applicability would be limited.",
        "How is MIRA similar or different compared to other clustering-based methods? (e.g. SwaV)",
        "What are the benefits of applying clustering-based methods to self-supervised learning? ",
        "What is mutual information means in the paper?",
        "What is the optimal transport used in SwaV?",
        "What are EMA and multi-crop strategies? ",
        "How is MIRA different to TWIST fundamentally?",
        "Why should we focus on the self-supervised method? For example, the limited label can make a tremendous gap against the self-supervised approaches.",
        "Why does the performance increase of TWIST deteriorates when the epoch further increases over 400?",
        "Why localization, objection detection, and image segmentation downstream tasks are underwhelming?",
        "What is the role of epoch in self-supervised learning?",
        "Is GLUE a benchmark for BERT or corpus for BERT?",
        "QNLI and WNLI is a part of GLUE. Is this true? ",
        "Is RACE is binary classification task?",
        "RoBERTa is based on BERT-large or BERT base?",
        "How NSP plays a role in BERT?",
        "Give two examples of public BERT-style english corpora.",
        "What is the difference between BERT paper and RoBERTa paper’s point of views? Give an answer in NSP loss and their performance perspective.",
        "In models inserting token expression, ([CLS],x1,...,xN,[SEP],y1,...,yM,[EOS]) calculate maximum value of N + M in RoBERTa case.",
        "In models inserting token expression \"([CLS],x1,...,xN,[SEP],y1,...,yM,[EOS])\", calculate maximum value of N + M in RoBERTa case.",
        "How many tokens are changed to [MASK] in BERT training? Give a ratio.",
        "RoBERTa uses large batch size. How many times larger than BERT-large one?",
        "Why RoBERTa uses Dynamic masking rather than Static masking?",
        "Why author said that “the data used for pretraining” have been under-emphesized? Give an evidence data on Table 4.",
        "Why author said that they adopt a much simpler approach for SQuAD compared to past work?",
        "How can author said that their results illustrate the importance of previously overlooked design decisions on BERT?",
        "Why author said that it can be challenging to determine which aspects of the methods contribute the most?",
        "Explain the author’s motivation to make CC-News dataset.",
        "Does RoBERTa also takes as input a concatenation of two segments, as well as BERT did?",
        "According to the paper, does BERT imporved by several other papers?",
        "BERT originally trained with a batch size of 256 sequences and RoBERTa simply followed that. Is this true? ",
        "Why does zero-shot evaluation has been suggested as a genuine measure for reasoning capability?",
        "What is AdapterFusion?",
        "How do the authors generate synthetic QA?",
        "What is the main weak point of conventional Multi-task learning for zero-shot learning with multiple types of commonsense knowledge? ",
        "Why is KG Modularization needed?",
        "What are the advantages of KG modularization using adapters?",
        "How does the author show the mitigation of interference?",
        "What is the difference between zero-shot fusion and original AdapterFusion?",
        "Which dataset is used for fusion layer training?",
        "Why is KG-Classifier adapter suggested?",
        "Which dataset is used for KG-Classifier adapter training?",
        "Which benchmark has been used for evaluation?",
        "What does STL stand for?",
        "What is the difference in test results according to the presence or absence of adapters?",
        "How does KG-Classifier affect zero-shot fusion?",
        "What is the correlation between the number of KGs and the performance when using zero-shot fusion?",
        "Why is neural integration of different KGs better than symbolic KG integration?",
        "What are the limitations of the parametric aggregation of knowledge with MTL?",
        "How does the author convert the triplet in KG into synthetic QA specifically?",
        "What does MTL stand for?",
        "What can be the future work related to this paper?",
        "Why is there decrease of the performance of the zeor-shot fusion without ATOMIC?",
        "What is the main motivation of this work?",
        "How does KG-Classifier work in framework?",
        "What is Majority in baselines?",
        "What are the examples of the Synthetic QA?",
        "How does the authors claim that the proposed method could improve the accuracy-latency tradeoff over existing SoTA CNN models?",
        "What is the contribution of this paper?",
        "Why focusing on latency-aware NAS is important?",
        "How \"superkernel\" is different from supernet?\n",
        "Why did the authors choose MIDAP as the target NPU to experiment on?",
        "Why the authors experiment on an NPU simulator, not the real hardware chip?",
        "How does the authors select SE blocks to remove?",
        "How does authors verify that searching in a small supernet then scaling is good tactic to search a big network?\n",
        "Why does author experiment the quantized linear supernet design even though Radosavovic et al. already provided similar result?",
        "How does authors claim that squeeze-and-excitation block removal is beneficial?",
        "Is the extended search strategy beneficial? Does the gain simply come from modified search space?",
        "How the proposed loss function is different from that of original Single-Path NAS?\n",
        "Why authors choose to extend Single-Path NAS as the search strategy, instead of famous NAS methods such as MNASNet?",
        "How does equation 2 let the supernet search kernel size?",
        "What is 'cumulative depth up to a specific stage' ?",
        "How does the authors verify adding h-swish and SE is beneficial?",
        "What happens if author removes the linear supernet design and opt to use the covnentional supernet design?",
        "How can rely on this latency prediction model?",
        "What is the difference between Siamese Network and our works?",
        "What does Active learning means?",
        "If there are few examples for learn, we called them few-shot learning. Guess the meaning of zero-shot learning.",
        "What is the demerit of using GNN?",
        "Explain the meaning of N-Way and M-shot. ",
        "Few-shot learning and semi-supervised learning is the same term. Is this true?",
        "Does previous researches, which paper mentioned, using GNN?",
        "Matching network uses BERT. Is this true?",
        "Give two examples which fit in following case: “Despite these successes, this learning setup does not cover many aspects where learning is nonetheless possible and desirable.”",
        "What does Omniglot means?",
        "What significance do the numbers like 51.3 and 30.0 have with respect to the One Billion Word benchmark? ",
        "What exactly is \"smoothing\" and how does it help count-based LMs account for unseen sequences?",
        "What is a \"recurrent state space\"?",
        "What is the difference between a 1-d CNN and a 2-layer highway network?",
        "What is a 128-dim correction?",
        "What is dropout and how does it alleviate overfitting?",
        "How does IS and NCE compare in terms of model performance? ",
        "Why doesn't character-level embeddings degrade performance compared to word-level embeddings? ",
        "How does maximizing log-likelihood lead to optimizing cross-entropy between target probability distribution and the model prediction?",
        "How does increasing the embedding and projection size help with respect to the model? ",
        "Previous RE task SOTA model was provided by Yamada et. al. at 2020. Is this true?",
        "Give one example Relation Extraction question and its answer.",
        "What are the obstacles of RE? Does this paper solved them?",
        "Is there any different way to construct RE model instead of using PLM strategy previously?",
        "What datasets did this paper used for?",
        "Can improvement of NER technology improves RE technology?",
        "Should RE model use spanBERT instead of BERT?",
        "Author said that they achieved to make SOTA RE models. Give an evidences for this statement.",
        "Entity marker and entity mask are same terms. Is this true?",
        "BLINK is Scalable. Is this true?",
        "BLINK have two different versions, bi-encoding version and cross-encoding version. Is this true?",
        "Using cross-encoder is time-consuming but accurate. Is this true?",
        "When does cross-encoder powerful? Give an example.",
        "They said that cross-encoder make mistakes sometimes. Give an example. This is provided on the paper.",
        "What TACKBP-2010 means?",
        "Why author emphasized their model as “Zero-shot”?",
        "How we can say Wikia dataset is zero-shot dataset?",
        "How BLINK can achieved zero-shot linking?",
        "Why BLINK valuable?",
        "This paper deals with NIL. It is true?",
        "Is joint model achieved state-of-the-art?",
        "Can joint model fit on coreference resolution task?",
        "What is maximum spanning tree problem?",
        "What is the difference between the local model and the global model?",
        "What datasets provide important corner cases, which was mentioned by paper?",
        "Why author build their model jointly?",
        "Give a situation that global model is necessary.",
        "What is the difference between AIDA and AIDA+?",
        "Why author explained their model as end-to-end?",
        "What are different types of categories in the FashionMNIST dataset?",
        "What is the distribution of images in the training and testing set of FashionMNIST dataset?",
        "Which dataset is similar to FashionMNIST in terms of image size, data format, structure if train test split, etc?",
        "Why is MNIST so popular?",
        "Among MNIST and FashionMNIST, which dataset poses more challenging classification task?",
        "What is the issue with EMNIST dataset?",
        "What was the process of creating FashionMNIST?",
        "What is Zalando?",
        "The shuffling task of data is left to algorithm developer by authors. Is this true?",
        "Which are the classification models used by the authors for benchmarking on the dataset?",
        "Which ML tasks can be performed using FashionMNIST dataset?",
        "How does the performance of ML algorithms on the FashionMNIST dataset compare to those on real world fashion images?",
        "Can the FashionMNIST dataset be used to train and test deep learning models?",
        "What type of ML models have been successful on the FashionMNIST dataset?",
        "What is the most widely used dataset in the deep learning comminity?",
        "For a given benchmarking algorithm, did the authors try different hyper-parameters?",
        "What is the purpose of FashionMNIST?",
        "What is the MNIST dataset?",
        "How do we get the silhoutte code for the class labels?",
        "Why did the author choose to use the standard COCO metrics for the comparison of Mask R-CNN to the state of the art on the COCO dataset ?",
        "What is the goal of this work ?",
        "What is instance segmentation ?",
        "What are the outputs of Mask-RNN",
        "What are the stage the Mask R-CNN consists of ??",
        "What is the loss used during training of Faster R-CNN ?",
        "What are the consequences of using class labels and box layouts ?",
        "What are the hyperparameters used for inference ?",
        "Does adding the third branch result in better results for the Mask R-CNN over the faster R-CNN ?",
        "What is RoIPool used for in relation to Mask R-CNN ??",
        "What metrics should be used for comparison of Mask R-CNN to the state of the art on the COCO dataset ?",
        "What is the reason behind the Mask R-CNN outperforming all the winner of COCO 2015 - 2016 ??",
        "Why it is sufficient to predict a binary mask without concern for the categories once the instance has been classified as a whole ?",
        "Is it better to use class specific or class agnostic masks in general ?",
        "Can we use Faster R-CNN for human pose estimation ?",
        "How is Mask R-CNN used to estimate human poses ?",
        "Can we use Faster R-CNN for multi task learning ?",
        "How did adding the segment branch affect the results ?",
        "What is the difference between Mask R-CNN and Faster R-CNN ?",
        "How can we solve the chllenges of image segmentation ?",
        "Was the GPT3 model finetuned on Self-Instruct also finetuned only on 50k instances?",
        "Why is it crucial for the pipeline to identify whether the instruction represents a classification task? How are classification tasks particularly distinct or special?"
    ],
    "answers": [
        "The ultimate aim of language technology is to interact with humans.However, most language models are trained without direct signals of human preference,with supervised target strings serving as (a sometimes crude) proxy.One option to incorporate user feedback is via human-in-the-loop, i.e., a user would be expected to provide feedback for each sample online as the model trains, but this degree of dense supervision is often prohibitive and inefficient.Automated metrics offer a promising compromise: learned models of human preference like BERTScore (Zhang et al., 2019), BLEURT (Sellam et al., 2020), summarization preferences (Wu et al., 2021) have significantly improved correlation with human judgment compared to earlier metrics (BLEU, METEOR, etc.), and are cheap to evaluate. But — these functions are usually not per-token differentiable: like humans, metrics can only offer quality estimates for full generations.Reinforcement Learning (RL) offers a natural path forward for optimizing non-differentiable, scalar objectives for LM-based generation when it is cast as a sequential decision-making problem. However, Goodhart’s Law222Strathern (1997) paraphrases: When a measure becomes a target, it ceases to be a good measure.looms: particularly in the case of imperfect metrics that use neural networks, it is easy to find nonsense samples that achieve high-quality estimates. Recent works have shown promising results in aligning LMs to human preferences via RL by constraining preference-based rewards to incorporate notions of fluency (Wu et al., 2021; Ouyang et al., 2022) but progress in this line of work is heavily hindered by a lack of open-source benchmarks and algorithmic implementations—resulting in perception that RL is a challenging paradigm for NLP (Choshen et al., 2020; Kreutzer et al., 2021).\n\n#### The automated metrics that are mentioned while discussing related work are BERTScore (Zhang et al., 2019), BLEURT (Sellam et al., 2020), and Ouyang et al (2022). More information on these automated metrics, including the differences between them, can probably be gleaned by reading these cited works. The current paper does not contain any additional information about these related automated metrics.",
        "The ultimate aim of language technology is to interact with humans.However, most language models are trained without direct signals of human preference,with supervised target strings serving as (a sometimes crude) proxy.One option to incorporate user feedback is via human-in-the-loop, i.e., a user would be expected to provide feedback for each sample online as the model trains, but this degree of dense supervision is often prohibitive and inefficient.Automated metrics offer a promising compromise: learned models of human preference like BERTScore (Zhang et al., 2019), BLEURT (Sellam et al., 2020), summarization preferences (Wu et al., 2021) have significantly improved correlation with human judgment compared to earlier metrics (BLEU, METEOR, etc.), and are cheap to evaluate. But — these functions are usually not per-token differentiable: like humans, metrics can only offer quality estimates for full generations.Reinforcement Learning (RL) offers a natural path forward for optimizing non-differentiable, scalar objectives for LM-based generation when it is cast as a sequential decision-making problem. However, Goodhart’s Law222Strathern (1997) paraphrases: When a measure becomes a target, it ceases to be a good measure.looms: particularly in the case of imperfect metrics that use neural networks, it is easy to find nonsense samples that achieve high-quality estimates. Recent works have shown promising results in aligning LMs to human preferences via RL by constraining preference-based rewards to incorporate notions of fluency (Wu et al., 2021; Ouyang et al., 2022) but progress in this line of work is heavily hindered by a lack of open-source benchmarks and algorithmic implementations—resulting in perception that RL is a challenging paradigm for NLP (Choshen et al., 2020; Kreutzer et al., 2021).\n\n#### A formal definition of non-differentiability has not been provided by the authors. However, authors in this context use this idea of differentiability to explain that most automated metrics cannot provide quality estimates after a language model generates one token or a parietal output - similar to humans, they can provide quality estimates only after a language model generates a full sequence. This non-differentiability is pointed out as a problem by the authors for the new metrics (i.e. things like BLUERT or BERTScore) - it is unclear from this paper alone if previous vanilla metrics (i.e. BLEU) were per token differentiable or not. The authors are looking for ways to use these non-differentiable scores in RL frameworks, potentially as a reward function.",
        "Language generation action spaces are orders of magnitude larger than what most discrete action space RL algorithms are designed for (Ranzato et al., 2015; Ammanabrolu, 2021), e.g., GPT-2/3 and T5 have a vocabulary size of 50K and 32K respectively.We hypothesize that the size of the action space is a core cause of instability when training LMs with existing RL methods.To address this issue, we introduce NLPO (Natural Language Policy Optimization), which is inspired by work on action elimination/invalid-action masking (Zahavy et al., 2018; Huang & Ontañón, 2020; Ammanabrolu & Hausknecht, 2020). NLPO, a parameterized-masked extension of PPO, learns to mask out less relevant tokens in-context as it trains. NLPO accomplishes this via top-p sampling, which restricts tokens to the smallest possible set whose cumulative probability is greater than the probability parameter p (Holtzman et al., 2018).\n\n#### The action space for language modeling is equal to the vocabulary set of language models. Since the vocabularies are very large (i.e. tens of thousands of possible tokens), the action space is also very large. In general, locomotion in the real world can be condensed to three quantities - moving across X, Y or Z axes, or a linear combination thereof. The authors mention that typical RL problems have an action space that is an order of magnitude smaller, but do not specifically explain how the action spaces for typical problems is modeled or constructed.",
        "RL4LMs supports fine-tuning and training LMs from scratch via on-policy actor-critic algorithms on language environments.Formally, this class of algorithms allows us to train a parameterized control policy defined as \\pi_{\\theta}:\\mathcal{S}\\rightarrow\\mathcal{A}, a function that attempts to select an action in a given state so as to maximize long term discounted rewards over a trajectory \\mathbb{E}_{\\pi}[\\sum_{t=0}^{T}\\gamma^{t}\\mathcal{R}(\\bm{s}_{t},a_{t})].Our benchmark experiments focus on fine-tuning a pre-trained LM denoted as \\pi_{0} from which we initial our agent’s policy \\pi_{\\theta}=\\pi_{0}.Similarly, the value network V_{\\phi} used to estimate the value function is also initialized from \\pi_{0} except for the final layer which is randomly initialized to output a single scalar value.As with other deep RL actor-critic algorithms, we define our value and Q-value functions as V_{t}^{\\pi}=\\mathbb{E}_{a_{t}\\sim\\pi}[\\sum_{\\tau=t}^{T}\\gamma R(\\bm{s}_{\\tau},a_{\\tau},{\\bm{y}})],Q_{t}^{\\pi}(\\bm{s}_{t},a_{t})=R(\\bm{s}_{t},a_{t},{\\bm{y}})+\\gamma\\mathbb{E}_{s_{t+1}\\sim P}[V_{t+1}^{\\pi}(\\bm{s}_{t+1})]leading to a definition of our advantage function as A_{t}^{\\pi}(\\bm{s},a)=Q_{t}^{\\pi}(\\bm{s},a)-V_{t}^{\\pi}.To increase training stability, advantage is appoximated using Generalized Advantage Estimation (Schulman et al., 2015).\n\n#### Actor critic models are a class of reinforcement learning algorithms. The paper does not contain information on Q-learning or how actor critic models are different from Q-learning models.",
        "RL4LMs supports fine-tuning and training LMs from scratch via on-policy actor-critic algorithms on language environments.Formally, this class of algorithms allows us to train a parameterized control policy defined as \\pi_{\\theta}:\\mathcal{S}\\rightarrow\\mathcal{A}, a function that attempts to select an action in a given state so as to maximize long term discounted rewards over a trajectory \\mathbb{E}_{\\pi}[\\sum_{t=0}^{T}\\gamma^{t}\\mathcal{R}(\\bm{s}_{t},a_{t})].Our benchmark experiments focus on fine-tuning a pre-trained LM denoted as \\pi_{0} from which we initial our agent’s policy \\pi_{\\theta}=\\pi_{0}.Similarly, the value network V_{\\phi} used to estimate the value function is also initialized from \\pi_{0} except for the final layer which is randomly initialized to output a single scalar value.As with other deep RL actor-critic algorithms, we define our value and Q-value functions as V_{t}^{\\pi}=\\mathbb{E}_{a_{t}\\sim\\pi}[\\sum_{\\tau=t}^{T}\\gamma R(\\bm{s}_{\\tau},a_{\\tau},{\\bm{y}})],Q_{t}^{\\pi}(\\bm{s}_{t},a_{t})=R(\\bm{s}_{t},a_{t},{\\bm{y}})+\\gamma\\mathbb{E}_{s_{t+1}\\sim P}[V_{t+1}^{\\pi}(\\bm{s}_{t+1})]leading to a definition of our advantage function as A_{t}^{\\pi}(\\bm{s},a)=Q_{t}^{\\pi}(\\bm{s},a)-V_{t}^{\\pi}.To increase training stability, advantage is appoximated using Generalized Advantage Estimation (Schulman et al., 2015).\n\n#### Q and V are mathematically expressed as: V_{t}^{\\pi}=\\mathbb{E}_{a_{t}\\sim\\pi}[\\sum_{\\tau=t}^{T}\\gamma R(\\bm{s}_{\\tau},a_{\\tau},{\\bm{y}})],Q_{t}^{\\pi}(\\bm{s}_{t},a_{t})=R(\\bm{s}_{t},a_{t},{\\bm{y}})+\\gamma\\mathbb{E}_{s_{t+1}\\sim P}[V_{t+1}^{\\pi}(\\bm{s}_{t+1})] where R is the reward function, s means states, and the variable 'a' denotes actions. Further information on what these values mean, or their interpretation is not found in this paper.",
        "Specifically, NLPOmaintains a masking policy \\pi_{\\psi}: the masking policy is a copy of the current policy (\\pi_{\\theta}), but is updated only every \\mu steps.A parameterized-invalid-mask is created from \\pi_{\\psi} by first selecting the top-p tokens from the vocabulary,444\\pi_{\\psi} could be trained with alternate sampling techniques like top-k or beam search (or even hard-coded via rules by domain experts), though we find top-p sampling to be most effective in practice. and then applying an invalid-mask to the remaining tokens—i.e. setting their probabilities to zero when sampling actions from \\pi_{\\theta} during training;this periodic updating policy \\pi_{\\psi} is inspired by off-policy Q-learning algorithms (Andrychowicz et al., 2017),providing the policy \\pi_{\\theta} with an additional constraint that balances between the benefits of containing more task relevant information than the KL penalty derived from \\pi_{0} and the risk of reward hacking.We provide pseudocode in Algorithm 1 (green portions highlight the differences with PPO).\n\n#### The authors hypothesize that their dynamic masking function helps because it adds a new constraint that the RL algorithm has to abide by. Additionally, since this is a dynamic function, being updated oftenly (every mu steps), it is likely that the masking function ensures that the selected top-p tokens are more relevant to the current state the RL algorithm needs to analyse and decide on.",
        "Language generation action spaces are orders of magnitude larger than what most discrete action space RL algorithms are designed for (Ranzato et al., 2015; Ammanabrolu, 2021), e.g., GPT-2/3 and T5 have a vocabulary size of 50K and 32K respectively.We hypothesize that the size of the action space is a core cause of instability when training LMs with existing RL methods.To address this issue, we introduce NLPO (Natural Language Policy Optimization), which is inspired by work on action elimination/invalid-action masking (Zahavy et al., 2018; Huang & Ontañón, 2020; Ammanabrolu & Hausknecht, 2020). NLPO, a parameterized-masked extension of PPO, learns to mask out less relevant tokens in-context as it trains. NLPO accomplishes this via top-p sampling, which restricts tokens to the smallest possible set whose cumulative probability is greater than the probability parameter p (Holtzman et al., 2018).\n\n#### The authors mention that they update the masking function every \"mu\" steps, but the main text of the paper itself does not appear to contain the exact value of mu itself - there is a possibility that the author's model could work with mu=1 instead (i.e. update every step) instead of updating it every couple of steps (i.e. mu > 1), though the authors do not explain in this paper if this were done. However, the authors mention that one reason why NLPO outperforms PPO is probably because of this dynamic masking function that is updated occasionally - this indicates to us that mu is probably not an unbounded or very large number (if mu were very large, tending to infinity, the function would no longer be dynamic).",
        "Specifically, NLPOmaintains a masking policy \\pi_{\\psi}: the masking policy is a copy of the current policy (\\pi_{\\theta}), but is updated only every \\mu steps.A parameterized-invalid-mask is created from \\pi_{\\psi} by first selecting the top-p tokens from the vocabulary,444\\pi_{\\psi} could be trained with alternate sampling techniques like top-k or beam search (or even hard-coded via rules by domain experts), though we find top-p sampling to be most effective in practice. and then applying an invalid-mask to the remaining tokens—i.e. setting their probabilities to zero when sampling actions from \\pi_{\\theta} during training;this periodic updating policy \\pi_{\\psi} is inspired by off-policy Q-learning algorithms (Andrychowicz et al., 2017),providing the policy \\pi_{\\theta} with an additional constraint that balances between the benefits of containing more task relevant information than the KL penalty derived from \\pi_{0} and the risk of reward hacking.We provide pseudocode in Algorithm 1 (green portions highlight the differences with PPO).\n\n#### The use of token-masking policy in the proposed method (NLPO) is theorized by the authors to have been a key reason on why it was able to outperform the PPO based model. They hypothesized that their masking function acts as a dynamic constraint added to the algorithm, that is able to more effectively filter and capture relevant information about the state thanks to its' dynamic nature.",
        "Language generation action spaces are orders of magnitude larger than what most discrete action space RL algorithms are designed for (Ranzato et al., 2015; Ammanabrolu, 2021), e.g., GPT-2/3 and T5 have a vocabulary size of 50K and 32K respectively.We hypothesize that the size of the action space is a core cause of instability when training LMs with existing RL methods.To address this issue, we introduce NLPO (Natural Language Policy Optimization), which is inspired by work on action elimination/invalid-action masking (Zahavy et al., 2018; Huang & Ontañón, 2020; Ammanabrolu & Hausknecht, 2020). NLPO, a parameterized-masked extension of PPO, learns to mask out less relevant tokens in-context as it trains. NLPO accomplishes this via top-p sampling, which restricts tokens to the smallest possible set whose cumulative probability is greater than the probability parameter p (Holtzman et al., 2018).\n\n#### The combinatorial action space here probably refers to the set of all possible actions that a RL agent for optimizing a language model could possibly take - here, the action set consists of the entire vocabulary of the language model, which can range to tens of thousands for typical GPT/T5 models used today. This is unlike general RL tasks, where the action space is an order of magnitude smaller.",
        "If the above regularization methods are applied individually, they aresomewhat effective at producing more interpretable images; Figure 3 shows the effects of each individual hyperparameter.However, preliminary experiments uncovered that their combinedeffect produces better visualizations. To pick a reasonable set ofhyperparameters for all methods at once, we ran a randomhyperparameter search of 300 possible combinations and settled on fourthat complement each other well. The four selected combinations arelisted in Table 1 and optimized images using each are shown for the “Gorilla” class output unit in Figure 4. Of the four, some show highfrequency information, others low frequency; some contain densepixel data, and others contain only sparse outlines of importantregions.We found the version in the lower-left quadrant to be the best single set of hyperparameters, but often greater intuition canbe gleaned by considering all four at once.Figure 5 shows the optimization results computed for a selection of units on all layers. A single image for every filter of all five convolutional layers is shown in Supplementary Figure S1. Nine images for each filter of all layers, including each of the 1000 ImageNet output classes, can be viewed at http://yosinski.com/deepvis.\n\n#### Authors best practices were to combine effects of different ways of regularization to produce interpretable images. They first search randomly through 300 different combinations of  hyperparameters, then they pick the best four sets of hyperparameters that are compliments to each other and then these sets would be used to visualize preferred images for different classes.",
        "Gaussian blur: Producing images via gradient ascent tends to produce examples with high frequency information (see Supplementary Section S1 for a possible reason). While these images cause high activations, they are neither realistic nor interpretable (Nguyen et al., 2014). A useful regularization is thus to penalize high frequency information. We implement this as a Gaussian blur step rθ (x) = GaussianBlur(x, θb width). Convolving with a blur kernel is more computationally expensive than the other regularization methods, so we added another hyperparameter θb every to allow, for example, blurring every several optimization steps instead of every step. Blurring an image multiple times with a small width Gaussian kernel is equivalent to blurring once with a larger width kernel, and the effect will be similar even if the image changes slightly during the optimization process. This technique thus lowers computational costs without limiting the expressiveness of the regularization. Mahendran & Vedaldi (2014) used a penalty with a similar effect to blurring, called total variation, in their work reconstructing images from layer codes.\n\n#### The paper's DNN uses multiple smaller Gaussian kernels iteratively as a way of regularization during the optimization process as seen in equation 2 .",
        "We investigated the following four regularizations. All are designed to overcome different pathologies commonly encountered by gradient descent without regularization.\n\n#### Authors mainly introduce four different and newly used regularizations that would help researchers in visualizing responses from different layers. These regularizations are designed to overcome different pathologies commonly encountered by gradient descent without regularization : L2 decay to penalize large pixel values which do not naturally occur, Gaussian blur:a useful regularization to iteratively penalize high frequency information associated with generated images via gradient ascent through each optimization step, Clipping pixels with small norm or Clipping pixels with small contribution.",
        "Figure 3. The effects of each regularization method from Section 3 when used individually. Each of the four rows shows a linear sweep in hyperparameter space from no regularization (left) to strong regularization (right). When applied too strongly, some regularizations cause the optimization to fail (e.g. L2 decay, top row) or the images to be less interpretable (small norm and small contribution clipping, bottom two rows). For this reason, a random hyperparameter search was useful for finding joint hyperparameter settings that worked well together (see Figure 4). Best viewed electronically, zoomed in.\n\n#### linear sweep can be seen as a regular increment in the values of some regularization hyperparameter (from leftmost where there is no regularization to rightmost where strong regularization occur ) to see the variation of their effects on the corresponding activations.",
        "The first tool is software that interactively plots the activations produced on each layer of a trained DNN for user-provided images or video. Static images afford a slow, detailed investigation of a particular input, whereas video input highlights the DNNs changing responses to dynamic input. At present, the videos are processed live from a user’s computer camera, which is especially helpful because users can move different items around the field of view, occlude and combine them, and perform other manipulations to actively learn how different features in the network respond.\n\n#### The paper talked about two main tools; the first is a software tool to plot activations of each trained layer of a network, for images or videos. Second is introducing new regularization ways to help with understanding learned features through network.These tools are supposed to help newcomers in deep learning to have better intuitions for hidden interpretations of well known structures and give motivations for more new ideas.",
        "Clipping pixels with small contribution: Instead of clipping pixels with small norms, we can try something slightly smarter and clip pixels with small contributions to the activation. One way of computing a pixel’s contribution to an activation is to measure how much the activation increases or decreases when the pixel is set to zero; that is, to compute the contribution as |a_{i}(\\mathbf{x})-a_{i}(\\mathbf{x}_{-j})|, where \\mathbf{x}_{-j} is \\mathbf{x} but with the j^{th} pixel set to zero. This approach is straightforward but prohibitively slow, requiring a forward pass for every pixel. Instead, we approximate this process by linearizing a_{i}(\\mathbf{x}) around \\mathbf{x}, in which case the contribution of each dimension of \\mathbf{x} can be estimated as the elementwise product of \\mathbf{x} and the gradient. We then sum over all three channels and take the absolute value, computing \\left|\\sum_{c}\\mathbf{x}\\circ\\nabla_{\\mathbf{x}}a_{i}(\\mathbf{x})\\right|. We use the absolute value to find pixels with small contribution in either direction, positive or negative. While we could choose to keep the pixel transitions where setting the pixel to zero would result in a large activation increase, these shifts are already handled by gradient ascent, and here we prefer to clip only the pixels that are deemed not to matter, not to take large gradient steps outside the region where the linear approximation is most valid. We define this r_{\\theta}(\\mathbf{x}) as the operation that sets pixels with contribution under the \\theta_{\\mathrm{c\\_pct}} percentile to zero.\n\n#### Calculating absolute difference between some neuron activation of an input and the activation for same input without certain pixel can be considered a way of measuring the contribution of that pixel in the total response of the neuron. To ensure faster computation, we can estimate activation near the input with 1st order approximation (linear) and hence this leads  to total contribution estimated as the element wise product of the activation gradient and the input x (each element in this product shows how this pixel affects the total response ), we repeat this product for all different channels ,sum them all, and take absolute value  to find pixels with small contribution in either direction, positive or negative to get rid of.",
        "Another approach is to try to interpret the function computed by each individual neuron. Past studies in this vein roughly divide into two different camps: dataset-centric and network-centric. The former requires both a trained DNN and running data through that network; the latter requires only the trained network itself. One dataset-centric approach is to display images from the training or test set that cause high or low activations for individual units. Another is the deconvolution method of Zeiler & Fergus (2013), which highlights the portions of a particular image that are responsible for the firing of each neural unit.\n\n#### \"Dataset-centric approach\" requires the trained network together with some dataset  to run through the network showing high or low responses of different units while interacting with most significant images of such dataset. This approach can also use deconvolution layers and upsampling to map and highlight the regions of an image that were responsible of the firing of the different units.\n\"Network-centric approach\" deals only with network without the need to any dataset.You can start with some initial input, compute activations through the forward path and then compute gradients while backprop. You can then ascent or descent the input towards gradient until you reach a preferred input stimulus x* for the unit under consideration. Working with input images, you can visualize that x* if you want.",
        "Another approach is to try to interpret the function computed by each individual neuron. Past studies in this vein roughly divide into two different camps: dataset-centric and network-centric. The former requires both a trained DNN and running data through that network; the latter requires only the trained network itself. One dataset-centric approach is to display images from the training or test set that cause high or low activations for individual units. Another is the deconvolution method of Zeiler & Fergus (2013), which highlights the portions of a particular image that are responsible for the firing of each neural unit.\n\n#### An example of \"dataset-centric\" approach can be deconvolution method which is used to highlight certain regions of some image that has the highest effects in the response of different units.",
        "Network-centric approaches investigate a network directly without any data from a dataset. For example, Erhan et al. (2009) synthesized images that cause high activations for particular units. Starting with some initial input \\mathbf{x}=\\mathbf{x_{0}}, the activation a_{i}(\\mathbf{x}) caused at some unit i by this input is computed, and then steps are taken in input spacealong the gradient \\partial a_{i}(\\mathbf{x})/\\partial\\mathbf{x} to synthesize inputs that cause higher and higher activations of unit i, eventually terminating at some \\mathbf{x^{*}} which is deemed to be a preferred input stimulus for the unit in question. In the case where the input space is an image, \\mathbf{x^{*}} can be displayed directly for interpretation. Others have followed suit, using the gradient to find images that cause higher activations (Simonyan et al., 2013; Nguyen et al., 2014) or lower activations (Szegedy et al., 2013) for output units.\n\n#### An example of such approach would be to consider a trained network, start with some initial input and compute the forward path activations. compute gradients through backprop and then move this input towards or against the gradient direction until you have some interesting input that is of much significance in the responses of considered neurons.",
        "These gradient-based approaches are attractive in their simplicity, but the optimization process tends to produce images that do not greatly resemble natural images. Instead, they are composed of a collection of “hacks” that happen to cause high (or low) activations: extreme pixel values, structured high frequency patterns, and copies of common motifs without global structure (Simonyan et al., 2013; Nguyen et al., 2014; Szegedy et al., 2013; Goodfellow et al., 2014). The fact that activations may be effected by such hacks is better understood thanks to several recent studies. Specifically, it has been shown that such hacks may be applied to correctly classified images to cause them to be misclassified even via imperceptibly small changes (Szegedy et al., 2013), that such hacks can be found even without the gradient information to produce unrecognizable “fooling examples” (Nguyen et al., 2014), and that the abundance of non-natural looking images that cause extreme activations can be explained by the locally linear behavior of neural nets(Goodfellow et al., 2014).\n\n#### 'Hacks' means that they are not likely to naturally exist (non-natural looking images). However they may even cause harmful changes in the response of the network. Adversarial points for instance are examples of such hacks where slight increments in pixels of even correctly classified images can make them fool the network and tend to go beyond there original part of space and hence be misclassified.",
        "Both of our tools are released as open source and are available athttp://yosinski.com/deepvis. While the tools could be adapted to integrate with any DNN software framework, they work out of the box withthe popular Caffe DNN software package (Jia et al., 2014).Users may run visualizations with their own Caffe DNN or our pre-trained DNN, which comes with pre-computed images optimized to activate each neuron in this trained network. Our pre-trained network is nearly identical to the “AlexNet” architecture (Krizhevsky et al., 2012), but with local reponse normalization layers after pooling layers following (Jia et al., 2014). It was trained with the Caffe framework on the ImageNet 2012 dataset (Deng et al., 2009).\n\n#### Yes both were trained on ImageNet 2012 dataset but paper's network first subtracted the per-pixel mean of examples in ImageNet before inputting training examples to the network. Hence, direct input to the network, x, can be thought of as a zero-centered input.",
        "Figure 1 shows examples of this type of plot for the \\mathsf{conv5} layer.The \\mathsf{conv5} layer has size 256\\times13\\times13, which we depict as 256 separate 13\\times13 grayscale images. Each of the 256 small images contains activations in the same spatial x-y spatial layout as the input data, and the 256 images are simply and arbitrarily tiled into a 16\\times16 grid in row-major order.Figure 2 shows a zoomed in view of one particular channel, \\mathsf{conv5_{151}}, that responds to human and animal faces. All layers can be viewed in the software tool, including pooling and normalization layers. Visualizing these layers provides intuitions about their effects and functions.\n\n#### \"row-major\" means that consecutive small grayscale images of each row reside next to each other unlike \"column-major\" and both are methods of storing elements in memory.",
        "Our network was trained on ImageNet by first subtracting the per-pixel mean of examples in ImageNet before inputting training examples to the network. Thus, the direct input to the network, \\mathbf{x}, can be thought of as a zero-centered input. We may pose the optimization problem as finding an image \\mathbf{x^{*}} where\n\n#### Zero mean input data and Standardization in general improve the convergence properties of BP training, so it can help to reach desired solution fast. Also, Authors may intend to have centered inputs so that network reduces its biasing towards certain classes or certain large or tiny response values, hence we can have reasonable values for activations and more visualizable responses from different neurons.",
        "•One of the most interesting conclusions so far has been that representations on some layers seem to be surprisingly local. Instead of finding distributed representations on all layers, we see, for example, detectors for text, flowers, fruit, and faces on \\mathsf{conv4} and \\mathsf{conv5}. These conclusions can be drawn either from the live visualization or the optimized images (or, best, by using both in concert) and suggest several directions for future research (discussed in Section 4).•When using direct file input to classify photos from Flickr or Google Images, classifications are often correct and highly confident (softmax probability for correct class near 1). On the other hand, when using input from a webcam, predictions often cannot be correct because no items from the training set are shown in the image. The training set’s 1000 classes, though numerous, do not cover most common household objects. Thus, when shown a typical webcam view of a person with no ImageNet classes present, the output has no single high probability, as is expected. Surprisingly, however, this probability vector is noisy and varies significantly in response to tiny changes in the input, often changing merely in response to the noise from the webcam. We might have instead expected unchanging and low confidence predictions for a given scene when no object the network has been trained to classify is present. Plotting the fully connected layers (\\mathsf{fc6} and \\mathsf{fc7}) also reveals a similar sensitivity to small input changes.•Although the last three layers are sensitive to small input changes, much of the lower layer computation is more robust. For example, when visualizing the \\mathsf{conv5} layer, one can find many invariant detectors for faces, shoulders, text, etc. by moving oneself or objects in front of the camera. Even though the 1000 classes contain no explicitly labeled faces or text, the network learns to identify these concepts simply because they represent useful partial information for making a later classification decision. One face detector, denoted \\mathsf{conv5_{151}} (channel number 151 on \\mathsf{conv5}), is shown in Figure 2 activating for human and lion faces and in Figure 1 activating for a cat face. Zhou et al. (2014) recently observed a similar effect where convnets trained only to recognize different scene types — playgrounds, restaurant patios, living rooms, etc. — learn object detectors (e.g. for chairs, books, and sofas) on intermediate layers.\n\n#### The reason is that convolution layers learn parameters that can extract useful information and relations from the feature map that can help it afterwards to judge and give suitable responses of what this category is. Responses from learned detectors can resemble among some set of categories and can also differ among other set of categories. Input -not being in the training classes- still has a feature map that different layers would respond to according to those different detectors which the network has already learned and would still give a probability vector which may not be accurate. Hence, having noise in the input can stimulate different detectors to respond and fire different activations that would lead to changes in the probability output vector.",
        "Clipping pixels with small norm: The first two regularizations suppress high amplitude and high frequency information, so after applying both, we are left with an \\mathbf{x^{*}} that contains somewhat small, somewhat smooth values. However, \\mathbf{x^{*}} will still tend to contain non-zero pixel values everywhere. Even if some pixels in \\mathbf{x^{*}} show the primary object or type of input causing the unit under consideration to activate, the gradient with respect to all other pixels in \\mathbf{x^{*}} will still generally be non-zero, so these pixels will also shift to show some pattern as well, contributing in whatever small way they can to ultimately raise the chosen unit’s activation. We wish to bias the search away from such behavior and instead show only the main object, letting other regions be exactly zero if they are not needed. We implement this bias using an r_{\\theta}(\\mathbf{x}) that computes the norm of each pixel (over red, green, and blue channels) and then sets any pixels with small norm to zero. The threshold for the norm, \\theta_{\\mathrm{n\\_pct}}, is specified as a percentile of all pixel norms in \\mathbf{x}.\n\n#### The paper reaches this goal by calculating each pixel norm over the 3 colour channels and zeroing out small-norm pixels according to some threshold (the percentile of all pixel norms in x).",
        "If the above regularization methods are applied individually, they aresomewhat effective at producing more interpretable images; Figure 3 shows the effects of each individual hyperparameter.However, preliminary experiments uncovered that their combinedeffect produces better visualizations. To pick a reasonable set ofhyperparameters for all methods at once, we ran a randomhyperparameter search of 300 possible combinations and settled on fourthat complement each other well. The four selected combinations arelisted in Table 1 and optimized images using each are shown for the “Gorilla” class output unit in Figure 4. Of the four, some show highfrequency information, others low frequency; some contain densepixel data, and others contain only sparse outlines of importantregions.We found the version in the lower-left quadrant to be the best single set of hyperparameters, but often greater intuition canbe gleaned by considering all four at once.Figure 5 shows the optimization results computed for a selection of units on all layers. A single image for every filter of all five convolutional layers is shown in Supplementary Figure S1. Nine images for each filter of all layers, including each of the 1000 ImageNet output classes, can be viewed at http://yosinski.com/deepvis.\n\n#### 300 sets of possible hyperparameter combinations then choose four of them that complement each other well.",
        "We also note that tools that enable understanding will especially benefit the vast numbers of newcomers to deep learning, who would like to take advantage of off-the-shelf software packages — like Theano (Bergstra et al., 2010), Pylearn2 (Goodfellow et al., 2013), Caffe (Jia et al., 2014), and Torch (Collobert et al., 2011) — in new domains, but who may not have any intuition for why their models work (or do not). Experts can also benefit as they iterate ideas for new models or when they are searching for good hyperparameters. We thus believe that both experts and newcomers will benefit from tools that provide intuitions about the inner workings of DNNs. This paper provides two such tools, both of which are open source so that scientists and practitioners can integrate them with their own DNNs to better understand them.\n\n#### They didn't mention specific tools for expert users. However, they have thoughts that even experts would benefit from their new ideas such as when experts iterate ideas for new models or while searching for good hyperparameters or maybe from intuitions about the inner workings of DNNs.",
        "However, the results presented here suggest an alternate possibility: the previously used priors may simply have been too weak (see Section S1 for one hypothesis of why a strong p(x) model is needed). With the careful design or learning of a p(x) model that biases toward realism,one may be able to harnessthe large number of parameters present in a discriminately learned p(y|x) modelto generate realistic images by enforcing probability under both models simultaneously.Even with the simple, hand-coded p(x) models we use in this paper as regularizers, complex dependencies between distant pixels already arise (cf. the beetles with structure spanning over 100 pixels in Figure 4). This implies that the discriminative parameters also contain significant “generative” structure from thetraining dataset; that is, the parameters encodenot only the jaguar’s spots, but to some extent also its four legs.With better, learned probabilistic models over the input and activations of higher layers, much more structure may be apparent. Work by Dai et al. (2015) shows some interesting results in this direction.While the images generated in this paper are far from being photo-realistic, they do suggest thattransferring discriminatively trained parameters to generative models — opposite the direction of the usual unsupervised pretraining approach — may be a fruitful area for further investigation.\n\n#### Generative structure is how the data is distributed inside the space where it lives, for example when learning to detect jaguar class, parameters encode not only the jaguar’s spots(Only to distinguish it through a rare property), but to some extent also its four legs(to learn the pattern with which the whole creature can be found). So, discriminative parameters also contain significant “generative” structure.",
        "However, as shown in Thakur et al. (2021b), dense retrieval methods require large amounts of training data to work well.333For reference, the popular MS MARCO dataset (Nguyen et al., 2016) has about 500k training instances; the Natural Questions dataset (Kwiatkowski et al., 2019) has more than 100k training instances.  Most importantly, dense retrieval methods are extremely sensitive to domain shifts: Models trained on MS MARCO perform rather poorly for questions for COVID-19 scientific literature (Wang et al., 2020; Voorhees et al., 2021). The MS MARCO dataset was created before COVID-19, hence, it does not include any COVID-19 related topics and models did not learn how to represent this topic well in a vector space.\n\n#### It is said that when evaluating a retriever trained on a source domain in an out-of-domain setting, the performance is obtained lower than BM25. Also, dense retrievers are said to be sensitive to domain shift and models that perform well on MS MARCO do not perform well on COVID-19 data. There have been many studies on unsupervised sentence embedding learning, but it is said that they do not work well in unsupervised dense retrieval. Therefore, the performance of the retriever in out-of-domain may be worse.",
        "Information Retrieval (IR) is a central component of many natural language applications. Traditionally, lexical methods (Robertson et al., 1994) have been used to search through text content. However, these methods suffer from the lexical gap (Berger et al., 2000) and are not able to recognize synonyms and distinguish between ambiguous words.\n\n#### Using lexical matching makes it difficult to identify synonyms or to distinguish between ambiguous words.",
        "To evaluate the latency of neural re-ranking models in §4.2, we use a single Tesla V100 GPU that has 32 GiBs of memory on a server with two Intel Xeon Gold 6132 CPUs, each with 14 physical cores (24 hyperthreads), and 469 GiBs of RAM. For the mostly CPU-based retrieval experiments in §4.3 and the indexing experiments in §4.5, we use another server with the same CPU and system memory specifications but which has four Titan V GPUs attached, each with 12 GiBs of memory. Across all experiments, only one GPU is dedicated per query for retrieval (i.e., for methods with neural computations) but we use up to all four GPUs during indexing.\n\n#### During indexing, we use another server with the same CPU and system memory specifications but which has four Titan V GPUs attached, each with 12 GiBs of memory. Across all experiments, only one GPU is dedicated per query for retrieval (i.e., for methods with neural computations) but we use up to all four GPUs during indexing.",
        "These increasingly expressive architectures are in tension. While interaction-based models (i.e., Figure 2 (b) and (c)) tend to be superior for IR tasks (Guo et al., 2019; Mitraet al., 2018), a representation-focused model—by isolating the computations among q and d—makes it possible to pre-compute document representations offline (Zamani et al., 2018), greatly reducing the computational load per query. In this work, we observe that the fine-grained matching of interaction-based models and the pre-computation of document representations of representation-based models can be combined by retaining yet judiciously delaying the query–document interaction. Figure 2 (d) illustrates an architecture that precisely does so. As illustrated, every query embedding interacts with all document embeddings via a MaxSim operator, which computes maximum similarity (e.g., cosine similarity), and the scalar outputs of these operators are summed across query terms. This paradigm allows ColBERT to exploit deep LM-based representations while shifting the cost of encoding documents offline and amortizing the cost of encoding the query once across all ranked documents. Additionally, it enables ColBERT to leverage vector-similarity search indexes (e.g., (Johnsonet al., 2017; Abuzaidet al., 2019)) to retrieve the top-k results directly from a large document collection, substantially improving recall over models that only re-rank the output of term-based retrieval.\n\n#### Using figure 2, \nThese increasingly expressive architectures are in tension. While interaction-based models (i.e., Figure 2 (b) and (c)) tend to be superior for IR tasks (Guo et al., 2019; Mitraet al., 2018), a representation-focused model—by isolating the computations among q and d—makes it possible to pre-compute document representations offline (Zamani et al., 2018), greatly reducing the computational load per query. In this work, we observe that the fine-grained matching of interaction-based models and the pre-computation of document representations of representation-based models can be combined by retaining yet judiciously delaying the query–document interaction. Figure 2 (d) illustrates an architecture that precisely does so. As illustrated, every query embedding interacts with all document embeddings via a MaxSim operator, which computes maximum similarity (e.g., cosine similarity), and the scalar outputs of these operators are summed across query terms. This paradigm allows ColBERT to exploit deep LM-based representations while shifting the cost of encoding documents offline and amortizing the cost of encoding the query once across all ranked documents. Additionally, it enables ColBERT to leverage vector-similarity search indexes (e.g., (Johnsonet al., 2017; Abuzaidet al., 2019)) to retrieve the top-k results directly from a large document collection, substantially improving recall over models that only re-rank the output of term-based retrieval.\n\n\n\n\n\n\nThe distinction of proposed model : 1) a highly-effective model is proposed that employs novel BERT-based query and document encoders within the late interaction paradigm.(2) We show how to leverage ColBERT both for re-ranking on top of a term-based retrieval model (3) and for searching a full collection using vector similarity indexes.(4)We evaluate ColBERT on MS MARCO and TREC CAR, two recent passage search collections.",
        "Using E_{q} and E_{d}, ColBERT computes the relevance score between q and d via late interaction, which we define as a summation of maximum similarity (MaxSim) operators. In particular, we find the maximum cosine similarity of each v\\in E_{q} with vectors in E_{d}, and combine the outputs via summation. Besides cosine, we also evaluate squared L2 distance as a measure of vector similarity. Intuitively, this interaction mechanism softly searches for each query term t_{q}—in a manner that reflects its context in the query—against the document’s embeddings, quantifying the strength of the “match” via the largest similarity score between t_{q} and a document term t_{d}. Given these term scores, it then estimates the document relevance by summing the matching evidence across all query terms.\n\n#### if a query term can be matched to multiple document terms, MaxSim suffice for capturing query-document relevance.  ColBERT computes the relevance score between q and d via late interaction, which we define as a summation of maximum similarity (MaxSim) operators. In particular, we find the maximum cosine similarity of each v\\in E_{q} with vectors in E_{d}, and combine the outputs via summation.",
        "Diving deeper into the quality–cost tradeoff between BERT and ColBERT, Figure 4 demonstrates the relationships between FLOPs and effectiveness (MRR@10) as a function of the re-ranking depth k when re-ranking the top-k results by BM25, comparing ColBERT and BERT{}_{\\textnormal{base}} (our training). We conduct this experiment on MS MARCO (Dev). We note here that as the official top-1000 ranking does not provide the BM25 order (and also lacks documents beyond the top-1000 per query), the models in this experiment re-rank the Anserini (Yanget al., 2018) toolkit’s BM25 output. Consequently, both MRR@10 values at k=1000 are slightly higher from those reported in Table 1.\n\n#### They used (MRR@10) for measuring efficiency and effectiveness .",
        "Shifting our attention to ColBERT’s end-to-end retrieval effectiveness, we see its major gains in MRR@10 over all of these end-to-end models. In fact, using ColBERT in the end-to-end setup is superior in terms of MRR@10 to re-ranking with the same model due to the improved recall. Moving beyond MRR@10, we also see large gains in Recall@k for k equals to 50, 200, and 1000. For instance, its Recall@50 actually exceeds the official BM25’s Recall@1000 and even all but docTTTTTquery’s Recall@200, emphasizing the value of end-to-end retrieval (instead of just re-ranking) with ColBERT.\n\n#### In fact, using ColBERT in the end-to-end setup is superior in terms of MRR@10 to re-ranking with the same model due to the improved recall. Moving beyond MRR@10, large gains in Recall@k for k equals to 50, 200, and 1000. For instance, its Recall@50 actually exceeds the official BM25’s Recall@1000 and even all but docTTTTTquery’s Recall@200, emphasizing the value of end-to-end retrieval (instead of just re-ranking) with ColBERT.",
        "These increasingly expressive architectures are in tension. While interaction-based models (i.e., Figure 2 (b) and (c)) tend to be superior for IR tasks (Guo et al., 2019; Mitraet al., 2018), a representation-focused model—by isolating the computations among q and d—makes it possible to pre-compute document representations offline (Zamani et al., 2018), greatly reducing the computational load per query. In this work, we observe that the fine-grained matching of interaction-based models and the pre-computation of document representations of representation-based models can be combined by retaining yet judiciously delaying the query–document interaction. Figure 2 (d) illustrates an architecture that precisely does so. As illustrated, every query embedding interacts with all document embeddings via a MaxSim operator, which computes maximum similarity (e.g., cosine similarity), and the scalar outputs of these operators are summed across query terms. This paradigm allows ColBERT to exploit deep LM-based representations while shifting the cost of encoding documents offline and amortizing the cost of encoding the query once across all ranked documents. Additionally, it enables ColBERT to leverage vector-similarity search indexes (e.g., (Johnsonet al., 2017; Abuzaidet al., 2019)) to retrieve the top-k results directly from a large document collection, substantially improving recall over models that only re-rank the output of term-based retrieval.\n\n#### During indexing, we use another server with the same CPU and system memory specifications but which has four Titan V GPUs attached, each with 12 GiBs of memory. Across all experiments, only one GPU is dedicated per query for retrieval (i.e., for methods with neural computations) but we use up to all four GPUs during indexing.",
        "Document Encoder. Our document encoder has a very similar architecture. We first segment a document d into its constituent tokens d_{1}d_{2}...d_{m}, to which we prepend BERT’s start token [CLS] followed by our special token [D] that indicates a document sequence. Unlike queries, we do not append [mask] tokens to documents. After passing this input sequence through BERT and the subsequent linear layer, the document encoder filters out the embeddings corresponding to punctuation symbols, determined via a pre-defined list. This filtering is meant to reduce the number of embeddings per document, as we hypothesize that (even contextualized) embeddings of punctuation are unnecessary for effectiveness. \n\n#### Targeting memory-efficient indexing, tokens are not appended in documents. We first segment a document d into its constituent tokens d_{1}d_{2}...d_{m}, to which we prepend BERT’s start token [CLS] followed by our special token [D] that indicates a document sequence. Unlike queries, we do not append [mask] tokens to documents. After passing this input sequence through BERT and the subsequent linear layer, the document encoder filters out the embeddings corresponding to punctuation symbols, determined via a pre-defined list. This filtering is meant to reduce the number of embeddings per document, as we hypothesize that (even contextualized) embeddings of punctuation are unnecessary for effectiveness.",
        "In contrast with this trend, ColBERT (which employs late interaction over BERT{}_{\\textnormal{base}}) performs no worse than the original adaptation of BERT{}_{\\textnormal{base}} for ranking by Nogueira and Cho (Nogueira and Cho, 2019; Nogueiraet al., 2019b) and is only marginally less effective than BERT{}_{\\textnormal{large}} and our training of BERT{}_{\\textnormal{base}} (described above). While highly competitive in effectiveness, ColBERT is orders of magnitude cheaper than BERT{}_{\\textnormal{base}}, in particular, by over 170\\times in latency and 13,900\\times in FLOPs. This highlights the expressiveness of our proposed late interaction mechanism, particularly when coupled with a powerful pre-trained LM like BERT. While ColBERT’s re-ranking latency is slightly higher than the non-BERT re-ranking models shown (i.e., by 10s of milliseconds), this difference is explained by the time it takes to gather, stack, and transfer the document embeddings to the GPU. In particular, the query encoding and interaction in ColBERT consume only 13 milliseconds of its total execution time. We note that ColBERT’s latency and FLOPs can be considerably reduced by padding queries to a shorter length, using smaller vector dimensions (the MRR@10 of which is tested in §4.5), employing quantization of the document vectors, and storing the embeddings on GPU if sufficient memory exists. We leave these directions for future work.\n\n#### In contrast with this trend, ColBERT (which employs late interaction over BERT performs no worse than the original adaptation of BERT for ranking and is only marginally less effective than BERT and our training of BERT. While highly competitive in effectiveness, ColBERT is orders of magnitude cheaper than BERT, in particular, by over 170\\times in latency and 13,900\\times in FLOPs.",
        "3. Dense retrieval models with issues for out-of-distribution data. Dense retrieval models (esp. ANCE and TAS-B), that map queries and documents independently to vector spaces, perform strongly on certain datasets, while on many other datasets perform significantly worse than BM25. For example, dense retrievers are observed to underperform on datasets with a large domain shift compared from what they have been trained on, like in BioASQ, or task-shifts like in Touché-2020. DPR, the only non-MSMARCO trained dataset overall performs the worst in generalization on the benchmark.\n\n#### BioASQ, or task-shifts like in Touché-2020 distribution shifts are considered for evaluating retrievers on out-of-distribution datasets",
        "However, creating a large training corpus is often time-consuming and expensive and hence many retrieval systems are applied in a zero-shot setup, with no available training data to train the system. So far, it is unclear how well existing trained neural models will perform for other text domains or textual retrieval tasks. Even more important, it is unclear how well different approaches, like sparse embeddings vs. dense embeddings, generalize to out-of-distribution data.\n\n#### creating a large training corpus is often time-consuming and expensive and hence many retrieval systems are applied in a zero-shot setup, with no available training data to train the system. Hence, a zero-shot scenario in this context refer to cases where relevance annotations are not available and  does not refer to unavailability of query set.",
        "We use beir to evaluate ten diverse retrieval methods from five broad architectures: lexical, sparse, dense, late interaction, and re-ranking. From our analysis, we find that no single approach consistently outperforms other approaches on all datasets. Further, we notice that the in-domain performance of a model does not correlate well with its generalization capabilities: models fine-tuned with identical training data might generalize differently. In terms of efficiency, we find a trade-off between the performances and the computational cost: computationally expensive models, like re-ranking models and late interaction model perform the best. More efficient approaches e.g. based on dense or sparse embeddings can substantially underperform traditional lexical models like BM25. Overall, BM25 remains a strong baseline for zero-shot text retrieval.\n\n#### If dense/sparse retrievers are pre-trained on target corpus to enable the retrievers to be corpus-aware, the fine-tuned retrievers underperform lexical models",
        "Finally, we notice that there can be a strong lexical bias present in datasets included within the benchmark, likely as lexical models are pre-dominantly used during the annotation or creation of datasets. This can give an unfair disadvantage to non-lexical approaches. We analyze this for the TREC-COVID Voorhees et al. (2021) dataset: We manually annotate the missing relevance judgements for the tested systems and see a significant performance improvement for non-lexical approaches. Hence, future work requires better unbiased datasets that allow a fair comparison for all types of retrieval systems.\n\n#### relevance\" is defined as judgements in TREC-COVID dataset",
        "Models need to potentially compare a single query against millions of documents at inference, hence, a high computational speed for retrieving results in real-time is desired. Besides speed, index sizes are vital and are often stored entirely in memory. We randomly sample 1 million documents from DBPedia Hasibi et al. (2017) and evaluate latency. For dense models, we use exact search, while for ColBERT we follow the original setup Khattab and Zaharia (2020) and use approximate nearest neighbor search. Performances on CPU were measured with an 8 core Intel Xeon Platinum 8168 CPU @ 2.70GHz and on GPU using a single Nvidia Tesla V100, CUDA 11.0.\n\n#### Index are important as speed in retrieval system.",
        "The results reveal large differences between approaches: Lexical approaches like BM25 and docT5query have a rather low Hole@10 value of 6.4% and 2.8%, indicating that the annotation pool contained the top-hits from lexical retrieval systems. In contrast, dense retrieval systems like ANCE and TAS-B have a much higher Hole@10 of 14.4% and 31.8%, indicating that a large fraction of hits found by these systems have not been judged by annotators.Next, we manually added for all systems, the missing annotation (or holes) following the original annotation guidelines. During annotation, we were unaware of the system who retrieved the missing annotation to avoid a preference bias. In total, we annotated 980 query-document pairs in TREC-COVID. We then re-computed nDCG@10 for all systems with this additional annotations.\n\n#### Lexical approaches like BM25 and docT5query have a rather low Hole@10 value of 6.4% and 2.8%, indicating that the annotation pool contained the top-hits from lexical retrieval systems. In contrast, dense retrieval systems like ANCE and TAS-B have a much higher Hole@10 of 14.4% and 31.8%, indicating that a large fraction of hits found by these systems have not been judged by annotators",
        "Finally, we notice that there can be a strong lexical bias present in datasets included within the benchmark, likely as lexical models are pre-dominantly used during the annotation or creation of datasets. This can give an unfair disadvantage to non-lexical approaches. We analyze this for the TREC-COVID Voorhees et al. (2021) dataset: We manually annotate the missing relevance judgements for the tested systems and see a significant performance improvement for non-lexical approaches. Hence, future work requires better unbiased datasets that allow a fair comparison for all types of retrieval systems.\n\n#### This dataset could be made unbiased by manual annotations",
        "Sequential recommendation aimsto accurately characterize users’ dynamic interestsby modeling their past behavior sequences (Rendle, 2010; Rendle et al., 2010; Kang and McAuley, 2018; Chen et al., 2021; Liet al., 2021a; Liuet al., 2021a).Early works on SR usually modelanitem-to-item transaction patternbased on MarkovChains (Rendle, 2010; He and McAuley, 2016).FPMC (Rendle et al., 2010)combines the advantages of Markov Chainsand matrix factorizationto fuse both sequential patternsand users’ general interest.With the recent advances of deep learning,many deep sequential recommendation modelsare also developed (Tang and Wang, 2018; Hidasi et al., 2015; Kang and McAuley, 2018; Sunet al., 2019). Such as Convolutional Neural Networks (CNN)-based (Tang and Wang, 2018) andRNN-based (Hidasi et al., 2015) models.The recent success of Transformer (Vaswani et al., 2017)also motivatesthe developments of pure Transformer-based SR models.SASRec (Kang and McAuley, 2018)utilizes unidirectional Transformerto assign weights to each interacted item adaptively.BERT4Rec (Sunet al., 2019) improves that byutilizing a bidirectional Transformerwith a Cloze task (Taylor, 1953)to fuse user behaviors information fromleft and right directions into each item.LSAN (Liet al., 2021a) improves SASRecon reducing model size perspective.It proposes a temporal context-aware embeddingand twin-attention network, which are light weighted.ASReP (Liuet al., 2021b) further alleviatesthe data-sparsity issueby leveraging a pre-trained Transformeron the revised user behavior sequences toaugment short sequences.In this paper, we study thepotential of addressing data sparsity issuesand improving SR via self-supervised learning.\n\n#### No, they do not.",
        "Effectively modeling latent intentsfrom user behaviorsposes two challenges.First,it is extremely difficult to learn latent intents accuratelybecause we have no labelling data for intents.The only available supervision signals for intents are the user behavior data. Nevertheless, as aforementioned example indicates, distinct behaviors may reflect the same intent.Besides,effectively fusing intent informationinto a SR model is non-trivial.The target in SR is to predict next items in sequences, which is solved by encoding sequences.Leveraging latent intents of sequences into the model requires the intentfactors to be orthogonal to the sequence embeddings,which otherwise would induce redundant information.\n\n#### No, it does not.",
        "We follow (Wanget al., 2019a; Krichene andRendle, 2020) to rank the prediction on the whole item set without negative sampling.Performance isevaluated ona variety of evaluation metrics, including Hit Ratio@k (\\mathrm{HR}@k), and Normalized DiscountedCumulative Gain@k (\\mathrm{NDCG}@k) where k\\in\\{5,20\\}.\n\n#### No metrics are mentioned for explicitly measuring robustness.",
        "In every iteration of the training phase,the computation costsof our proposed methodare mainly fromthe E-step estimation of Q(\\cdot) and M-step optimization of \\thetawith multi-tasks training.For the E-step,the time complexity is O(|U|mKd) from clustering, where d is the dimensionalityof the embedding and m is themaximum iteration number in clustering (m=20 in this paper).For the M-step,since we have three objectivesto optimize the network f_{\\theta}(\\cdot),the time complexity is O(3⋅(|U|2d+|U|d2)O(3\\cdot(|U|^{2}d+|U|d^{2})italic_O ( 3 ⋅ ( | italic_U | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_d + | italic_U | italic_d start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ).The overall complexity is dominated by the term O(3\\cdot(|U|^{2}d)),which is 3 times of Transformer-based SR with only next item prediction objective, e.g., SASRec.Fortunately,the model can be effectively parallelized becausef_{\\theta} is Transformer and we leave it in future work.In the testing phase,the proposed ICL as wellas the SeqCL objectivesare no longer needed, which yields themodel to have the sametime complexity as SASRec (O(d|V|)).The empirical time spending comparisonsare reported in Sec. 5.2.The convergence of ICL is guaranteedunder the generalized EM framework.Proof is provided in Appendix B.\n\n#### Logically, yes. Empirically, no.",
        "•Non-sequential models:BPR-MF (Rendle et al., 2012) characterizesthe pairwise interactionsvia a matrix factorization model andoptimizes through apair-wiseBayesian Personalized Ranking loss.•Standard sequential models.We include solutionsthat train the models with a next-itemprediction objective.Caser (Tang and Wang, 2018) is a CNN-based approach, GRU4Rec (Hidasi et al., 2015)is an RNN-based method, and SASRec (Kang and McAuley, 2018) is one of the state-of-the-art Transformer-basedbaselines for SR.•Sequential models with additional SSL:BERT4Rec (Sunet al., 2019)replaces the next-item prediction witha Cloze task (Taylor, 1953)tofuse informationbetween an item (a view) in a userbehavior sequence and its contextual information.S{}^{3}\\text{-Rec} (Zhou et al., 2020) uses SSL to capture correlation-ship among item, sub-sequence, and associated attributes from the given user behavior sequence.Its modules for mining on attributes are removedbecause we don’t have attributes for items,namely S{}^{3}\\text{-Rec}_{ISP}.CL4SRec (Xieet al., 2020) fusescontrastive SSL with aTransformer-based SR model.•Sequential models considering latent factors:We include DSSRec(Maet al., 2020),which utilizes seq2seq trainingand performs optimization inlatent space.We do not directly compare ASLI (Tanjim et al., 2020),as it requires user action type information (e.g.,click, add-to-favorite, etc).Instead, we provide a case study inSec. 5.6 toevaluate the benefits of the learnt intent factorwith additional item category information.\n\n#### BERT4Rec and S3-Rec are two examples",
        "We follow (Zhou et al., 2020; Xieet al., 2020) to prepare the datasets. In detail, we only keep the ‘5-core’ datasets, in which all users and items have at least 5 interactions. The statistics of the prepared datasets are summarized inAppendix C.\n\n#### They are about 99.95% sparse.",
        "Assume that a recommender system has a set of usersand items denoted by \\mathcal{U} and \\mathcal{V} respectively.Each user u\\in\\mathcal{U} has a sequence of interacted itemssorted in chronological order S^{u}=[s^{u}_{1},\\dots,s^{u}_{t},\\dots,s^{u}_{|S^{u}|}]where |S^{u}| is the number of interacted itemsand s^{u}_{t} is the item u interacted atstep t. We denote \\mathbf{S}^{u}as embedded representation of S^{u},where \\mathbf{s}^{u}_{t} is the d-dimensional embedding of item s^{u}_{t}.In practice, sequences are truncated withmaximum length T.If the sequence length is greater than T, the mostrecent T actions are considered. If the sequence length is less than T, ‘padding’ items will beadded to the left until the length isT (Tang and Wang, 2018; Hidasi et al., 2015; Kang and McAuley, 2018).For each user u,the goal of next item prediction task is to predictthe next item that the user uis most likely to interact withat the |S_{u}|+1 step among the item set \\mathcal{V},given sequence \\mathbf{S}^{u}.\n\n#### The value of T is not mentioned, and neither is the ratio of sequences that exceed T in length.",
        "The main goal of next item prediction task is to optimizeEq. (1).Assume that there are also K different user intents (e.g., purchasing holiday gifts, preparing for fishing activity, etc.)in a recommender system that formsthe intent variable c=\\left\\{c_{i}\\right\\}_{i=1}^{K}, thenthe probability of a user interacting with a certainitem can be rewritten as follows:(7)\\begin{split}P_{\\theta}(s^{u})=\\mathbb{E}_{(c)}\\left[P_{\\theta}(s^{u},c)\\right].\\end{split}However, users intents are latent by definition.Because of the missing observation of variable c,we are in a ‘chicken-and-eggs’ situation thatwithout c, we cannot estimate parameter \\theta,and without \\theta we cannot inferwhat the value of c might be.\n\n#### It does not. K as a hyperparameter is only best believed as the number of user intents and does not necessarily equal the actual number of user intents.",
        "Later, we will show that a generalized Expectation-Maximization frameworkprovides a direction to address above problemwith a convergence guarantee.The basic idea of optimizing Eq. (7) via EMis to start with an initial guessof the model parameter \\thetaand estimate the expected valuesof the missing variable c, i.e., the E-step.And once we have the values of c,we can maximize the Eq. (7) w.r.t theparameter \\theta, i.e., the M step.We can repeat this iterative process until the likelihood cannot increase anymore.\n\n#### EM guarantees convergence.",
        "Sequential recommendation aimsto accurately characterize users’ dynamic interestsby modeling their past behavior sequences (Rendle, 2010; Rendle et al., 2010; Kang and McAuley, 2018; Chen et al., 2021; Liet al., 2021a; Liuet al., 2021a).Early works on SR usually modelanitem-to-item transaction patternbased on MarkovChains (Rendle, 2010; He and McAuley, 2016).FPMC (Rendle et al., 2010)combines the advantages of Markov Chainsand matrix factorizationto fuse both sequential patternsand users’ general interest.With the recent advances of deep learning,many deep sequential recommendation modelsare also developed (Tang and Wang, 2018; Hidasi et al., 2015; Kang and McAuley, 2018; Sunet al., 2019). Such as Convolutional Neural Networks (CNN)-based (Tang and Wang, 2018) andRNN-based (Hidasi et al., 2015) models.The recent success of Transformer (Vaswani et al., 2017)also motivatesthe developments of pure Transformer-based SR models.SASRec (Kang and McAuley, 2018)utilizes unidirectional Transformerto assign weights to each interacted item adaptively.BERT4Rec (Sunet al., 2019) improves that byutilizing a bidirectional Transformerwith a Cloze task (Taylor, 1953)to fuse user behaviors information fromleft and right directions into each item.LSAN (Liet al., 2021a) improves SASRecon reducing model size perspective.It proposes a temporal context-aware embeddingand twin-attention network, which are light weighted.ASReP (Liuet al., 2021b) further alleviatesthe data-sparsity issueby leveraging a pre-trained Transformeron the revised user behavior sequences toaugment short sequences.In this paper, we study thepotential of addressing data sparsity issuesand improving SR via self-supervised learning.\n\n#### Authors do not discuss how.",
        "Recent advances in contrastive SSLhave inspired therecommendation communityto leverage contrastive SSL tofuse correlations amongdifferent views of one sequence (Chenet al., 2020; Yao et al., 2020; Wuet al., 2021),following themutual information maximization (MIM) principle.Existing approaches in SRcan be seen asinstance discrimination tasksthat optimize a lower bound of MIM,such as InfoNCE (Oordet al., 2018; Heet al., 2020b; Chenet al., 2020; Liet al., 2020b).It aims to optimize theproportion of gap of positive pairs and negative pairs (Liu et al., 2021c).In such an instance discrimination task,sequence augmentations such as ‘mask’, ‘crop’, or ‘reorder’ are required tocreatedifferent views of the unlabeled data in SR (Sunet al., 2019; Zhou et al., 2020; Xieet al., 2020; Zhou et al., 2021).Formally, given a sequence S^{u},and a pre-defined data transformationfunction set \\mathcal{G}, we can createtwo positive views of S^{u} as follows:(4)\\tilde{S}^{u}_{1}=g_{1}^{u}(S^{u}),\\tilde{S}^{u}_{2}=g_{2}^{u}(S^{u}),\\text{ s.t. }g_{1}^{u},g_{2}^{u}\\sim\\mathcal{G},where g_{1}^{u} and g_{2}^{u} are transformation functions sampledfrom \\mathcal{G} to createa different view of sequence s_{u}.Commonly, views created from the same sequenceare treated as positive pairs,and the views of any different sequencesare considered as negative pairs.The augmented views are first encoded with thesequence encoder f_{\\theta}(\\cdot) to\\mathbf{\\tilde{H}}^{u}_{1} and \\mathbf{\\tilde{H}}^{u}_{2},and then be fed into an ‘Aggregation’layer to get vector representationsof sequences, denoted as \\mathbf{\\tilde{h}}^{u}_{1} and \\mathbf{\\tilde{h}}^{u}_{2}. In this paper,we ‘concatenate’ users’ interest representations over time stepsfor simplicity. Note that sequences are prepossessed to have the same length (See Sec. 3.1), thustheir vector representations after concatenationhave the same length too.After that,we can optimize \\theta via InfoNCE loss:(5)\\mathcal{L}_{\\mathrm{SeqCL}}=\\mathcal{L}_{\\mathrm{SeqCL}}(\\mathbf{\\tilde{h}}^{u}_{1},\\mathbf{\\tilde{h}}^{u}_{2})+\\mathcal{L}_{\\mathrm{SeqCL}}(\\mathbf{\\tilde{h}}^{u}_{2},\\mathbf{\\tilde{h}}^{u}_{1}),and(6)\\mathcal{L}_{\\mathrm{SeqCL}}(\\mathbf{\\tilde{h}}^{u}_{1},\\mathbf{\\tilde{h}}^{u}_{2})=-\\log\\frac{\\exp(\\text{sim}(\\mathbf{\\tilde{h}}^{u}_{1},\\mathbf{\\tilde{h}}^{u}_{2}))}{\\sum_{neg}\\exp(\\text{sim}(\\mathbf{\\tilde{h}}^{u}_{1},\\mathbf{\\tilde{h}}_{neg}))},where sim(\\cdot) is dot product and\\mathbf{\\tilde{h}}_{neg} are negativeviews’ representations of sequence S^{u}.Figure 2(a) illustrates how SeqCL works.\n\n#### Sequences of user behavior can be maximally separated or brought together by means of contrastive SSL.",
        "Robustness w.r.t. user interaction frequency.Theuser ‘cold-start’ problem (Caiet al., 2021; Yinet al., 2020) is one of thetypical data-sparsity issues thatrecommender systems often face, i.e.,most users have limited historical behaviors.To check whether ICL improves the robustnessunder such a scenario,wesplit user behavior sequences into three groupsbased on their behavior sequences’ length, and keepthe total number of behavior sequencesthe same.Models are trained and evaluated on each group of usersindependently. Figure 3shows the comparison results on four datasets.We observe that:(1) The proposed ICLRec canconsistentlyperforms better thanSASRec among all user groups whileCL4SRec fails to outperform SASRecin Beauty and Yelpwhen user behavior sequences areshort.This demonstrates thatCL4SRec requires individual userbehavior sequences long enough to provide‘complete’ informationfor auxiliary supervisionwhileICLRec reducesthe need by leveraginguser intent information,thus consistently benefiting userrepresentation learning evenwhen users have limited historical interactions.(2) Compared with CL4SRec,we observe thatthe improvement of ICLRec is mainly becauseit provides betterrecommendations tousers with low interaction frequency.Thisverifies thatuser intent informationis beneficial, especiallywhen the recommender system facesdata-sparsity issues whereinformationin each individual user sequenceis limited.\n\n#### Yes, it can.",
        "For all the datasets, BUIRid shows the substantially higher performance than the discriminative methods taking only user-id/item-id (i.e., BPR, NeuMF, CML, and SML).In particular, the sparser the training set becomes, the larger the performance improvement of BUIRid is achieved over the best baseline (denoted by Improvid).It is obvious that BUIRid is more robust to the extreme sparsity compared to the other baselines that are more likely to explicitly use “positive but unobserved” interactions as negative interactions when positive user-item interactions are more rarely observed.BUIRid is not affected by such inconsistent supervision from uncertain negative interactions because it directly optimizes the representations of users and items by using only positive interactions.\n\n#### BUIR requires positive user-item pairs instead of negative sampling for training.",
        "Bypassing the collapsed solution.  It is obvious that the loss in Equation (3) admits the collapsed solution with respect to \\theta and \\xi, which means both the encoders generate the same representations for all users and items.For this reason, the conventional end-to-end learning strategy, which optimizes both f_{\\theta} and f_{\\xi} to minimize the loss (i.e., cross-prediction error), may easily lead to such collapsed solution.In contrast, our proposed framework updates each of the encoders in different ways.From Equation (4), the online encoder is optimized to minimize the loss, while the target encoder is updated to slowly approximate the online encoder.That is, the direction of updating the target encoder (\\theta-\\xi) totally differs from that of updating the online encoder (-\\nabla_{\\theta}\\mathcal{L}_{\\theta,\\xi}),and this effectively keeps both the encoders from converging to the collapsed solution.Several recent work on bootstrapping-based representation learning (Grill et al., 2020; Chen and He, 2021) empirically demonstrated that this kind of dynamics (i.e., updating two networks differently) allows to avoid the collapsed solution without any explicit term to prevent it.\n\n#### Approximating the online encoder keep the target encoder from converging to the collapsed solution.",
        "We argue that the above collapsed solution is incurred by the si\\x02multaneous optimization of 𝑢 and 𝑣 within the end-to-end learning framework of a single encoder. Hence, we instead adopt the student\\x02teacher-like network [6, 29] in which only the student’s output 𝑢 (and 𝑣) is optimized to predict the target 𝑣 (and 𝑢) presented by the teacher. Specifically, BUIR directly bootstraps1 the representations of users and items by employing two distinct encoder networks, referred to as online encoder and target encoder. The high-level idea is training only the online encoder for the prediction task between 𝑢 and 𝑣, where the target for its prediction is provided by the target encoder. That is, the online encoder is optimized so that its user (and item) vectors get closer to the item (and user) vectors com\\x02puted by the target encoder. At the same time, the target encoder is updated based on momentum-based moving average [6, 8, 29] to slowly approximate the online encoder, which encourages to pro\\x02vide enhanced representations as the target for the online encoder. By doing so, the online encoder can capture the positive relation\\x02ship between 𝑢 and 𝑣 into the representations, while preventing the model from collapsing to the trivial solution without explicitly using any negative interactions for the optimization.\n\n#### Online encoders prevent models from collapsing into trivial solutions without explicitly using negative interactions for optimization.",
        "Existing discriminative OCCF methods (Rendle et al., 2009; Hsieh et al., 2017) have tried to optimize the latent space where the user-item interactions are directly encoded into their inner product (or Euclidean distance).On the contrary, BUIR additionally uses the predictor to model their interaction, which results in the capability of encoding the high-level relationship between users and items into the representations.In conclusion, with the help of the predictor, BUIR accurately computes the user-item interaction scores as well as optimizes the representation without explicitly using negative samples.\n\n#### Using predictor can optimize the representation without any negative sample.",
        "In Figure 4, our stochastic data augmentation (i.e., P>0) brings a significant improvement compared to the case of using the fixed neighborhood information (i.e., P=0) as encoder inputs.This result shows that the augmented views of positive interactions encourage BUIR to effectively learn users’ preference on items even in much sparse dataset.Interestingly, in case of the Ciao dataset which is less sparse than CiteULike, the benefit of our augmentation linearly increases with the maximum drop probability.This is because there is room for producing more various views (i.e., larger perturbation) based on a relatively more number of neighbors, and it eventually helps to boost the recommendation performance.To sum up, our framework that adopts the neighbor augmentation function successfully relieves the data sparsity issue of the OCCF problem, by leveraging the augmented views of few positive interactions.\n\n#### Stochastic means it use random neighborhood information of each user and item during data augmentation.",
        "Implementation Details.  We implement the proposed framework and all the baselines by using PyTorch, and use the Adam optimizer to train them.For BUIR, we fix the momentum coefficient \\tau to 0.995, and adopt a single linear layer for the predictor q_{\\theta}.666We empirically found that these hyperparameters hardly affect the final performance of BUIR, and the sensitivity analysis on the parameters is provided in Section 4.6.The augmentation function \\psi simply uses a uniform distribution for drawing a drop probability p\\sim\\mathcal{U}(0,1), where each user’s (item’s) neighbor is independently deleted with the probability p.\n\n#### Model gets best performance when the value of parameter tau is larger or equal than 0.9 and smaller than 1.",
        "BUIR makes use of two distinct encoder networks that have the same structure: online encoder f_{\\theta} and target encoder f_{\\xi}.They are parameterized by \\theta and \\xi, respectively.The key idea of BUIR is to train the online encoder by using outputs of the target encoder as its target, while gradually improving the target encoder as well.The main difference of BUIR from existing end-to-end learning frameworks is that f_{\\theta} and f_{\\xi} are updated in different ways.The online encoder is trained to minimize the error between its output and the target, whereas the target network is slowly updated based on the momentum update (Heet al., 2020b) so as to keep its output consistent.\n\n#### The online encoder is updated to minimize the error between the output and the target and updated by the gradients back-propagated from the loss, but target network is updated based on the momentum update and updated as the moving average of the online encoder .",
        "Nevertheless, the negative sampling approach has critical limitations in the following aspects.First, the underlying assumption about negative interactions becomes less valid as user-item interactions get sparser.This is because as fewer positive interactions are observed, the number of ”positive but unobserved” interactions increases, which consequently makes it even harder to sample correct negative ones.Such uncertainty of supervision eventually degrades the performance for top-K recommendation.Second, the convergence speed and the final performance depend on the specific choice of distributions for negative sampling.For example, sampling negative pairs from a non-uniform distribution (Rendle andFreudenthaler, 2014; Dinget al., 2019) (e.g., the multinomial distribution which models the probability of each interaction being actually negative) can improve the final performance, but inevitably incurs high computational costs, especially when a lot of users and items should be considered.\n\n#### Assuming unobserved user-item pairs negative leads to limited performance since there are some cases of positive but unobserved, and the number of this case is increased.",
        "However, since the negative interactions are not available in the OCCF problem, previous discriminative methods assume that all unobserved interactions are negative.In other words, for each user, the items that have not been interacted yet are regarded to be less preferred to positive items.In this sense, they either use all unobserved user-item interactions as negative or adopt a negative sampling, which randomly samples unobserved user-item interactions in a stochastic manner to alleviate the computational burden.For better recommendation performance and faster convergence, advanced negative sampling strategies (Rendle andFreudenthaler, 2014; Dinget al., 2019) are also proposed to sample from non-uniform distributions.\n\n#### Previous OCCF studies assume that all unobserved interactions are negative to mitigate the problem of performance being largely depend on negative sampling distribution",
        "Pointing out that the contrastive methods need to carefully treat the negative instances during the training for effectiveness and efficiency, the most recent work proposed a bootstrapping-based self-supervised learning framework (Grill et al., 2020; Chen and He, 2021), which is capable of avoiding the collapsed solution without the help of negative instances.Inspired by bootstrapping methods in deep reinforcement learning (Mnihet al., 2015; Mnih et al., 2016), it directly bootstraps the representation of images by using two neural networks that iteratively learn from each other.This approach achieves the state-of-the-art performance for various downstream tasks in computer vision, and also shows better robustness to the choice of data augmentations used for self-supervision.\n\n#### To prevent the problem of collapsed sollution, they update target encoder and online encoder differently.",
        "In Figure 4, our stochastic data augmentation (i.e., P>0) brings a significant improvement compared to the case of using the fixed neighborhood information (i.e., P=0) as encoder inputs.This result shows that the augmented views of positive interactions encourage BUIR to effectively learn users’ preference on items even in much sparse dataset.Interestingly, in case of the Ciao dataset which is less sparse than CiteULike, the benefit of our augmentation linearly increases with the maximum drop probability.This is because there is room for producing more various views (i.e., larger perturbation) based on a relatively more number of neighbors, and it eventually helps to boost the recommendation performance.To sum up, our framework that adopts the neighbor augmentation function successfully relieves the data sparsity issue of the OCCF problem, by leveraging the augmented views of few positive interactions.\n\n#### They show augmented views of positive interactions can lead the performance improvement, especially in sparser datasets by showing the experimental result of stochastic data augmentation achieved a big improvement compared to the case of using the fixed neighborhood information as encoder inputs.",
        "Knowledge propagation via meta-graph.It is worth noting that, the above-defined knowledge injection process only leverages knowledge embeddings learned by TransE on the global graph \\overline{\\mathcal{G}}. Particularly, it lacks considering the knowledge that bridges the semantics between query and passage. To this end, we introduce a Graph Meta Network (GMN) module that refines knowledge with the constructed meta-graph \\mathbf{G}_{\\mathbf{q},\\mathbf{p}}, The multi-hop paths of \\mathbf{G}_{\\mathbf{q},\\mathbf{p}} allow the knowledge to be propagated between query and passage, which can enhance the relevance signal to be captured by the model, and thus alleviate the semantic gap.\n\n#### Through experiments, the authors demonstrated that the performance of the model (i.e., MRR@10) decreased without knowledge propagation and that it was comparable to vanilla ERNIE, which demonstrated that multi-hop neighbors were essential for ranking performance. This result can be attributed to how using multi-hope neighbors allows for knowledge to propagate between query and passage.",
        "Knowledge propagation via meta-graph.It is worth noting that, the above-defined knowledge injection process only leverages knowledge embeddings learned by TransE on the global graph \\overline{\\mathcal{G}}. Particularly, it lacks considering the knowledge that bridges the semantics between query and passage. To this end, we introduce a Graph Meta Network (GMN) module that refines knowledge with the constructed meta-graph \\mathbf{G}_{\\mathbf{q},\\mathbf{p}}, The multi-hop paths of \\mathbf{G}_{\\mathbf{q},\\mathbf{p}} allow the knowledge to be propagated between query and passage, which can enhance the relevance signal to be captured by the model, and thus alleviate the semantic gap.\n\n#### This work proposes an aggregation module that employs a PLM and a Graph Neural Network (GMN) to model the interaction between explicit and implicit knowledge. The PLM encodes text to obtain word representations (i.e., implicit knowledge), and the Graph Neural Network (GMN) encodes knowledge meta-graphs to obtain entity representations (i.e., explicit knowledge). This module aggregates the word and entity representations to aggregate the implicit and explicit knowledge.",
        "Here we compare ranking performances of KERM and other PLMs based re-rankers on the first two widely used query sets. Moreover, ablation studies for each component of KERM are also explored. All experimental results were reported under the same BM25 setting.\n\n#### This work conducted ablation studies to investigate the contribution of each component in the performance of KERM. By testing different settings for the knowledge injector, this work found that performance decreases without knowledge interaction and also without knowledge propagation. By testing the model without global or local distillation, they also demonstrated that performance decreases without global distillation and efficiency decreases without either global or local distillation. These experiments demonstrate that each component of KERM contributes to passage re-ranking performance quantitatively.",
        "Existing knowledge graphs are usually incomplete and noisy. It is unsuitable for direct introduction of them to the current model. Specially, there is no knowledge base particularly for passage re-ranking task. For example, ConceptNet (Speeret al., 2017) is a general knowledge graph that contains common sense knowledge, where the information might not be useful for our passage re-ranking task. Therefore, it is critical for us to propose a knowledge graph distillation process from both global and local perspectives.\n\n#### This work proposes using knowledge graph distillation as it can help retain only informative knowledge needed for passage re-ranking. By investigating the effect of global and local distillation separately, this work found that the MRR@10 score and efficiency decreased slightly without global distillation, and that time efficiency decreased the most without local distillation. Therefore, this work demonstrates that both global and local distillation of knowledge graphs is useful for re-ranking tasks in terms of performance and efficiency.",
        "We use a large-scale public available corpus, i.e., MSMARCO-Passage collection (Nguyen et al., 2016), as our passage collection. This collection contains approximately 8.8 million passages extracted from 3.2 million web documents covering multiple fields. We train our model on the MSMARCO-TRAIN query set of 502,939 queries and evaluate KERM on three query sets. Table 1 provides the detailed information of these query sets.The first test set is MSMARCO-DEV, which includes 6,980 sparsely-judged queries mixed with multiple domains. Each query has an average of 1.1 relevant passages with binary relevance label.The second test set is TREC 2019 DL (Craswell et al., 2020), which contains 43 densely-judged queries with fine-grained relevance labels, i.e., irrelevant, relevant, highly relevant and perfectly relevant. On average, a query has 95.4 relevant passages, and most queries have more than 10 relevant passages. With fine-grained labels and multiple relevant passages per query, TREC 2019 DL can be used to reflect the fine-grained ranking performance between relevant passages.To evaluate KERM on specific domains, we further introduce Ohsumed 111http://disi.unitn.it/moschitti/corpora.htm query set, which contains 63 queries on bio-medical domain.The collection of Ohsumed is constructed from the first 20,000 passages in Mesh categories of the year 1991.Following the previous work (Joachims, 1998), the test collection including 10,000 passages are utilized for performance comparison on Ohsumed query set.Each query has an average of 50.9 relevant passages with three graded relevance labels. In section 6.4, we demonstrate that the quality of external knowledge constructed by KERM in such domain could be more useful.\n\n#### MARCO-Passage collection is a large-scale publicly available corpus and two query sets derived from this corpus are used in the paper: MSMARCO-TRAIN and MSMARCO-DEV. How and who collected the queries from MARCO-Passage to construct MSMARCO-TRAIN cannot be answered from this paper.",
        "For knowledge graph distillation, we propose a novel pipeline to establish knowledge meta graphs, which only retain informative knowledge for passage re-ranking. Specifically, we first distill a graph globally for passage re-ranking scenario from an existing knowledge graph by pruning some unreliable or noisy relations based on TransE embedding. Then for a specific query-passage pair, we extract entities from both the query and passage, and construct a query-document bipartite entity graph based on query and passage entities and their k-hop neighbors, namely knowledge meta graph. Challenge 1. could be addressed in this distillation process.\n\n#### The knowledge graph is distilled globally by taking an existing knowledge graph and pruning unreliable or noise relations based on TransE embeddings. The graph is then distilled locally by extracting entities from both the given query and passage, and constructing a query-document bipartite entity graph based on the extracted entities and their k-hop neighbors.",
        "•Challenge 1. Existing knowledge graph are not constructed for re-ranking task. They usually contain trivial factual triples, which can hardly bring information gain. The inappropriate selection of external knowledge could even jeopardize the re-ranker performance. How to utilize existing knowledge graph to re-ranking task is remain a challenge.•Challenge 2.The explicit knowledge and implicit knowledge are highly heterogeneous due to the different sources, which makes the aggregation of the two difficult.How to mutually refine each other and effectively aggregate explicit knowledge into implicit knowledge to alleviate the semantic gap between query and passage is still a challenge.\n\n#### Unreliable relations in a knowledge graph involve trivial factual triplets that do not bring substantial information gain. For example, in ConceptNet, the entity “hepatitis” has relations with both “infectious disease” and “adult”. To the concept “hepatitis”,  the concept “adults” is more general than “infectious disease” and thus the relationship between “hepatitis” and “infectious disease” is more reliable and informative.",
        "Knowledge propagation via meta-graph.It is worth noting that, the above-defined knowledge injection process only leverages knowledge embeddings learned by TransE on the global graph \\overline{\\mathcal{G}}. Particularly, it lacks considering the knowledge that bridges the semantics between query and passage. To this end, we introduce a Graph Meta Network (GMN) module that refines knowledge with the constructed meta-graph \\mathbf{G}_{\\mathbf{q},\\mathbf{p}}, The multi-hop paths of \\mathbf{G}_{\\mathbf{q},\\mathbf{p}} allow the knowledge to be propagated between query and passage, which can enhance the relevance signal to be captured by the model, and thus alleviate the semantic gap.\n\n#### The Graph Meta Network (GMN) refines knowledge in a meta-graph. A meta-graph is a graph that is constructed by constructing multi-hop paths between the entities in a query and a passage using the knowledge from a global graph. The meaning for “meta” in both graph meta network (GMN) and meta-graph is not explicitly defined in this paper.",
        "We use the traditional sparse retriever BM25 (Yanget al., 2017) as our first stage method. All experiments are conducted under the same BM25 setting with 1000 retrieved candidates. We conduct experiments with the deep learning framework PaddlePaddle (Maet al., 2019) on up to 4 NVIDIA Tesla A100 GPUs (with 40G RAM). For the GMN module, we use Paddle Graph Learning (PGL) 222https://github.com/PaddlePaddle/PGL, an efficient and flexible graph learning framework based on PaddlePaddle. For training, we used the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 1e-5 for text encoder and 1e-4 for knowledge injector. The model is trained up to 5 epochs with a batch size of 640 and 240 for base and large models respectively.In our experiments, the PLM small, base and large models have 6, 12 and 24 Transformer layers respectively.The text encoder has 9 layers and 21 layers for base and large model respectively, and the knowledge injector both has 3 layers in our experiment. The dropout rates are set to 0.1. The ratio of the positive to the hard negative is set to 1:19.All transformer layers in KERM’s backbone are initialized from ERNIE-2.0 base (Sunet al., 2020b), which is a BERT-like model pre-trained with a continual pre-training framework on multiple tasks. We perform Knowledge-enhanced pre-training on MARCO passage collection to warm up the parameters in knowledge injector, which has 60,000 iterations under the batch size of 256.For a fair comparison, the same pre-training without knowledge enhancement is also conducted on \\textrm{ERNIE}_{\\textrm{base}} re-ranker and all models in ablation studies.\n\n#### This work mentions using the Paddle Graph Learning (PGL) framework from the deep learning framework PaddlePaddle. Other examples of frameworks in PaddlePaddle are not mentioned in this paper.",
        "We use ConceptNet (Speeret al., 2017), a general knowledge graph as our external knowledge base \\mathcal{G}. Following KagNet (Linet al., 2019), we merge relation types to increase graph density and construct a multi-relational graph with 17 relation types, including atlocation, causes, createdby, etc.\n\n#### ConceptNet is a general knowledge graph and, in this work, they merged relation types in the graph to construct a multi-relational graph with 17 relation types. The full number of entities and relations that are found in ConceptNet cannot be answered in this paper.",
        "Knowledge-enhanced pre-training.Following previous studies (Nogueiraet al., 2019a; Yanet al., 2021; Kim and Ko, 2021), we conduct continual pre-training on MSMARCO corpus to warm up the parameters of GMN module.We apply Masked Language Model (MLM) (Devlinet al., 2018) and Sentence Relation Prediction (SRP) (Wang et al., 2019) as the pre-training tasks in KERM.Compared to conventional Next Sentence Prediction (NSP) (Devlinet al., 2018), the task of SRP is to predict whether a given sentence is the next sentence, previous sentence relation or no relation with another sentence. To incorporate knowledge during the pre-training stage, we construct a meta-graph for each sentence pair, and apply the knowledge aggregation process as introduced above.The pre-training loss is defined as\\mathcal{L}_{p}=\\mathcal{L}_{MLM}+\\mathcal{L}_{SRP}.\n\n#### Compared to conventional Next Sentence Prediction (NSP), Sentence Relation Prediction (SRP) aims to predict whether a given sentence is the next sentence, previous sentence relation, or no relation with another sentence.",
        "The low-dimensional dense representations for query and passage are computed by PLMs based retrievers from the dual-encoder architecture. Afterward, the candidate passage set could be retrieved efficiently via approximate nearest neighbor algorithms.Existing studies could be categorized into two parts:(1) By optimizing the matching stage: DPR (Karpukhin et al., 2020) is the first study to leverage PLM to empower the retriever by a single vector. Other researches, such asRepBERT (Zhanet al., 2020), ColBERT (Khattab andZaharia, 2020), COIL (Gaoet al., 2021) and Interactor (Yeet al., 2022), obtain multiple vectors for query and passage for matching.(2) By optimizing the representation learning module: RocketQAv1 (Qu et al., 2021) and RocketQAv2 (Ren et al., 2021) boost the representation learning of retriever by leveraging the power of cross-encoder in a cascade or joint manner. Other studies boost the representation learning by designed IR-oriented pre-training tasks.ICT (Leeet al., 2019) treats sentences as pseudo-queries and matched them to the passage they originate from. Condenser (Gao and Callan, 2021) utilizes a novel pre-training task, which can produces an information-rich representation to condense an input sequence.\n\n#### BM25 and DPR are both examples of retrievers used in large-scale passage collection. BM25 is described as a traditional sparse retriever and DPR leverages PLM to empower the retriever by a single vector. How both BM25 and DPR function is not described in detail in this paper and thus their differences cannot be answered in this paper.",
        "Existing PLMs based re-rankers typically improve ranking performance from two aspects: (1) By optimizing the ranking procedure: monoBERT (Nogueira and Cho, 2019) is the first work that re-purposed BERT as a passage re-ranker and achieves state-of-the-art results. duoBERT (Nogueiraet al., 2019a) integrates monoBERT in a multistage ranking architecture and adopts a pairwise classification approach to passage relevance computation. UED (Yanet al., 2021) proposes a cascade pre-training manner that can jointly enhance the retrieval stage through passage expansion with a pre-trained query generator and thus elevate the re-ranking stage with a pre-trained transformer encoder. The two stages can facilitate each other in a unified pre-training framework. H-ERNIE (Chuet al., 2022) proposes a multi-granularity PLM for web search.(2) By designing rational distillation procedure: LM Distill + Fine-Tuning (Gaoet al., 2020) explores a variety of distillation methods to equip a smaller re-ranker with both general-purpose language modeling knowledge learned in pre-training and search- specific relevance modeling knowledge learned in fine-tuning, and produces a faster re-ranker with better ranking performance. CAKD (Hofstätter et al., 2020) proposes a cross-architecture knowledge distillation procedure with a Margin-MSE loss, which can distill knowledge from multiple teachers at the same time. RocketQAv1 (Qu et al., 2021) trains dual-encoder and cross-encoder in a cascade manner, which leverages the powerful cross-encoder to empower the dual-encoder. RocketQAv2 (Ren et al., 2021) proposes a novel approach that jointly trains the dense passage retriever and passage re-ranker. The parameters of RocketQAv2 are inherited from RocketQAv1. Besides, RocketQAv2 utilizes a large PLM for data augmentation and denoising, which can also be regarded as a distillation procedure. Notably, these two types of studies anticipate more insightful information to be captured by the advanced ranking and training procedures, while neglecting the limitations of implicit knowledge extracted from noisy and heterogeneous data. Therefore, in this paper, we proposed the first knowledge-enhanced PLM based re-ranker, which thoughtfully leverages explicit external knowledge that improve the effectiveness of the model.\n\n#### RocketQAv1 trains dual-encoder and cross-encoder in a cascade manner, which leverages the powerful cross-encoder to empower the dual-encoder. While it inherits the parameters from RocketQAv1, RocketQAv2 extends the first version through a novel approach that jointly trains the dense passage retriever and passage re-ranker, and by using a large PLM for data augmentation and denoising (i.e.,  a distillation procedure).",
        "However, implicit knowledge still has some inherent weaknesses, which limits the applicability of PLMs based re-rankers. First,queries and passages are usually created by different persons and have different expression ways (Nogueiraet al., 2019b), such as word usage and language style.Worse still, the data distributions of search queries and web contents are highly heterogeneous (Liuet al., 2021), where various specialized domains (e.g., bio-medical) may only have few training examples in a general corpus. Domain-specific knowledge can hardly be revealed and captured by the model, and thus the processing of domain-specific queries is often inaccurate.\n\n#### In their experiments, the authors showed that all of the models performed poorly on the bio-medical domain due to the textual data of the domain not being covered widely in the PLMs’ pretraining dataset. This lack of data can cause the PLM to struggle to reveal and capture knowledge specific to that domain. These results suggest that further training on bio-medical data could increase performance.",
        "Passage Re-ranking is a crucial stage in modern information retrieval systems, which aims to reorder a small set of candidate passages to be presented to users. To put the most relevant passages on top of a ranking list, a re-ranker is usually designed with powerful capacity in modeling semantic relevance, which attracted a wealth of research studies in the past decade (Guo et al., 2020). Recently,large-scale pre-trained language models (PLMs), e.g. BERT (Devlinet al., 2018), ERNIE (Sun et al., 2019) and RoBERTa (Liu et al., 2019), have dominated many natural language processing tasks, and have also achieved remarkable success on passage re-ranking.For example, PLM based re-rankers (MacAvaney et al., 2019; Liet al., 2020; Dong and Niu, 2021; Donget al., 2022) have achieved state-of-the-art performance, which takes the concatenation of query-passage pair as input, and applies multi-layer full-attention to model their semantic relevance. Their superiority can be attributed to the expressive transformer structure and the pretrain-then-finetune paradigm, which allow the model to learn useful implicit knowledge (i.e., semantic relevance in the latent space) from massive textual corpus (Fan et al., 2021).\n\n#### Large-scale pre-trained language models (PLMs) have been found to be successful for passage re-ranking due to their ability to learn semantic relevance in the latent space from massive textual corpus. PLMs obtain this ability from their expressive transformer architecture and the pretrain-then-finetune paradigm.",
        "(1)Key sentence selection. The actual information need of a user usually concentrates on a small part of a relevant passage (Guo et al., 2020). To this end, we mimic human judgment and only focus on the sentence of each passage that is the most related to a query (Zou et al., 2021).In particular, we define the relevance score between a query q and a sentence \\textbf{s}_{i} as(7)Rel_{qs}(\\textbf{q},\\textbf{s}_{i})=\\frac{\\sum_{q=1}^{|\\textbf{q}|}\\textbf{E}(w_{q})}{|\\textbf{q}|}\\cdot\\frac{\\sum_{s=1}^{|\\textbf{s}_{i}|}\\textbf{E}(w_{s})}{|\\textbf{s}_{i}|}.For the sake of efficiency, we initialize \\textbf{E}(w) from Word2Vec (Mikolovet al., 2013) embedding.Based on Eq.(7), we select the most relevant sentence \\textbf{s}^{*} in p to build the meta-graph for \\mathbf{q} and \\mathbf{p}.(2)Target entity recognition.Next, we select the entities in q and \\textbf{s}^{*} to construct the meta-graph. Specifically, we only consider the entities that exactly match in \\mathcal{E}. Meanwhile, we omit those entity phrases that are sub-sequences of other recognized entities.For example, in the query \"what causes low liver enzymes\", both \"liver\" and \"liver enzyme\" are entities, but the entity \"liver enzyme\" is more informative to be recognized as the target entity, and \"liver\" should be omitted.(3)Path discovery. Finally, given the target entities of q and \\textbf{s}^{*} (denoted as \\phi_{\\mathbf{q}} and \\phi_{\\mathbf{s}^{*}}, respectively), we perform Breadth First Search (BFS) on \\overline{\\mathcal{G}} to discover the paths within K-hop between \\phi_{\\mathbf{q}} and \\phi_{\\mathbf{s}^{*}}. Note that we only keep the within-K-hop paths that might be the most useful for the downstream re-ranking task. Meanwhile, the knowledge could be complemented from the K-hop paths.\n\n#### Entities that exactly match entities in E are selected from q and s* to construct the meta-graph. Also, entities that are sub-sequences of other recognized entities are omitted. This process assumes that entities are identified in the query and passage. The process for handling cases where no entities are identified cannot be answered in this paper.",
        "We use the traditional sparse retriever BM25 (Yanget al., 2017) as our first stage method. All experiments are conducted under the same BM25 setting with 1000 retrieved candidates. We conduct experiments with the deep learning framework PaddlePaddle (Maet al., 2019) on up to 4 NVIDIA Tesla A100 GPUs (with 40G RAM). For the GMN module, we use Paddle Graph Learning (PGL) 222https://github.com/PaddlePaddle/PGL, an efficient and flexible graph learning framework based on PaddlePaddle. For training, we used the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 1e-5 for text encoder and 1e-4 for knowledge injector. The model is trained up to 5 epochs with a batch size of 640 and 240 for base and large models respectively.In our experiments, the PLM small, base and large models have 6, 12 and 24 Transformer layers respectively.The text encoder has 9 layers and 21 layers for base and large model respectively, and the knowledge injector both has 3 layers in our experiment. The dropout rates are set to 0.1. The ratio of the positive to the hard negative is set to 1:19.All transformer layers in KERM’s backbone are initialized from ERNIE-2.0 base (Sunet al., 2020b), which is a BERT-like model pre-trained with a continual pre-training framework on multiple tasks. We perform Knowledge-enhanced pre-training on MARCO passage collection to warm up the parameters in knowledge injector, which has 60,000 iterations under the batch size of 256.For a fair comparison, the same pre-training without knowledge enhancement is also conducted on \\textrm{ERNIE}_{\\textrm{base}} re-ranker and all models in ablation studies.\n\n#### Through the experiments, this work demonstrated that the KERM model was able to significantly improve on the performance of its backbone model, ERNIE. The authors posit that this is due to how KERM explicitly introduces external knowledge which can improve semantic matching performance. This suggests that KERM models with other backbone models will be able to improve on the performance of their backbone models. However, the likelihood of performance improvements with other backbone models cannot be answered from this paper.",
        "Existing KE-PLMs can be categorized by the granularity of knowledge they incorporate from knowledge graph (KG), as text-based knowledge, entity knowledge and KG meta-graphs.To integrate text-based knowledge, RAG (Lewiset al., 2020) and KIF (Fanet al., 2020) first retrieve top-k documents from Wikipedia using KNN-based retrieval, and the PLM model is employed to generate the output conditioned on these retrieved documents. Entity-level information can be highly useful for a variety of natural language understanding tasks. Hence, many existing KE-PLMs target this type of simple yet powerful knowledge. ERNIE(BAIDU) (Sun et al., 2019) introduces a new pre-training strategy of language model which masking phrases or entities in order to implicitly learn both synaptic and semantic knowledge from these units. ERNIE(THU) (Zhanget al., 2019) integrates informative entity representations in the knowledge module into the underlying layers of the semantic module based on the alignments between text and entity to equip the model with the ability of knowledge awareness. As knowledge graphs provide richer information than simply entity, more and more researchers start to explore integration of more sophisticated knowledge, such as meta-graphs in KG. CokeBERT (Su et al., 2021) proposes a novel semantic-driven Graph Neural Network (GNN) to dynamically select contextual knowledge and embed knowledge context according to textual context for PLMs, which can avoid the effect of redundant and ambiguous knowledge in KGs that cannot match the input text.CoLake (Sunet al., 2020a) also uses GNN to aggregate information from the constructed meta-graph in both pre-training and inference. CoLake converts the meta-graph into token sequence and appends it to input sequence for PLMs, which is distinctive to CokeBERT. Although extensive research has been proposed up to now to address the knowledge-aware problem, none exists which constrained on how to use knowledge to empower PLMs particularly for re-ranking tasks.\n\n#### While approaches like CokeBERT and CoLake integrate sophisticated knowledge into PLMs through knowledge graphs, they did not focus specifically on using knowledge to empower PLMs for re-ranking tasks. The reasons for why CokeBERT or CoLake cannot be directly used in re-ranking cannot be answered from this paper.",
        "(1)Key sentence selection. The actual information need of a user usually concentrates on a small part of a relevant passage (Guo et al., 2020). To this end, we mimic human judgment and only focus on the sentence of each passage that is the most related to a query (Zou et al., 2021).In particular, we define the relevance score between a query q and a sentence \\textbf{s}_{i} as(7)Rel_{qs}(\\textbf{q},\\textbf{s}_{i})=\\frac{\\sum_{q=1}^{|\\textbf{q}|}\\textbf{E}(w_{q})}{|\\textbf{q}|}\\cdot\\frac{\\sum_{s=1}^{|\\textbf{s}_{i}|}\\textbf{E}(w_{s})}{|\\textbf{s}_{i}|}.For the sake of efficiency, we initialize \\textbf{E}(w) from Word2Vec (Mikolovet al., 2013) embedding.Based on Eq.(7), we select the most relevant sentence \\textbf{s}^{*} in p to build the meta-graph for \\mathbf{q} and \\mathbf{p}.(2)Target entity recognition.Next, we select the entities in q and \\textbf{s}^{*} to construct the meta-graph. Specifically, we only consider the entities that exactly match in \\mathcal{E}. Meanwhile, we omit those entity phrases that are sub-sequences of other recognized entities.For example, in the query \"what causes low liver enzymes\", both \"liver\" and \"liver enzyme\" are entities, but the entity \"liver enzyme\" is more informative to be recognized as the target entity, and \"liver\" should be omitted.(3)Path discovery. Finally, given the target entities of q and \\textbf{s}^{*} (denoted as \\phi_{\\mathbf{q}} and \\phi_{\\mathbf{s}^{*}}, respectively), we perform Breadth First Search (BFS) on \\overline{\\mathcal{G}} to discover the paths within K-hop between \\phi_{\\mathbf{q}} and \\phi_{\\mathbf{s}^{*}}. Note that we only keep the within-K-hop paths that might be the most useful for the downstream re-ranking task. Meanwhile, the knowledge could be complemented from the K-hop paths.\n\n#### This work’s approach aims at focusing mostly on informative factors. For example, the key sentence selection module focused on extracting only the most relevant sentences and the target entity recognition module focused on identifying only the most informative entities. Further, this work argues that, to use knowledge graphs for re-ranking tasks, it is important that the graphs contain triplets with substantial information gain. The effect on information gain from using IE models, instead of exact match, for target entity recognition cannot be answered from this paper.",
        "Given a global knowledge graph \\mathcal{G}, the first step is to eliminate those knowledge that might be noisy to be applied. To achieve this, we use TransE (Bordes et al., 2013) to measure the reliability of a given knowledge triplet. In particular, TransE is an unsupervised learning method that learns latent representations for a knowledge triplet (e_{h},r,e_{t}). Intuitively, it models the latent distribution of knowledge in a given knowledge graph, and those who are out of this distribution can be viewed as less informative knowledge, which should not be used. Based on this,we use the entity embeddings pre-trained by TransE to calculate a distance metric between two linked entities as(3)Rel_{e}(e_{h},r,e_{t})=\\mathbf{E}({e_{h}})\\cdot\\mathbf{E}(r)+\\mathbf{E}({e_{h}})\\cdot\\mathbf{E}({e_{t}})+\\mathbf{E}({r})\\cdot\\mathbf{E}({e_{t}}),(4)Dist(e_{h},e_{t})=\\frac{1}{Rel_{e}(e_{h},r,e_{t})},where \\mathbf{E}({e}) and \\mathbf{E}({r}) are the TransE embeddings of entity and relation, respectively, and the inner product measures the relevance between two vectors. As the objective of TranE is aligned with minimizing the distance shown in Eq.(4), we can consider those knowledge triplets with small distance values as informative knowledge.\n\n#### TransE is an unsupervised learning method that learns latent representations for a knowledge triplet. The method in which TransE learns these latent representations cannot be answered from this paper.",
        "Much of the recent research on deep convolutional neural networks (CNNs) has focused on increasing accuracy on computer vision datasets.For a given accuracy level, there typically exist multiple CNN architectures that achieve that accuracy level.Given equivalent accuracy, a CNN architecture with fewer parameters has several advantages:\\bulletMore efficient distributed training.Communication among servers is the limiting factor to the scalability of distributed CNN training.For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the model Iandola et al. (2016).In short, small models train faster due to requiring less communication.\\bulletLess overhead when exporting new models to clients. For autonomous driving, companies such as Tesla periodically copy new models from their servers to customers’ cars. This practice is often referred to as an over-the-air update. Consumer Reports has found that the safety of Tesla’s Autopilot semi-autonomous driving functionality has incrementally improved with recent over-the-air updates Consumer Reports (2016). However, over-the-air updates of today’s typical CNN/DNN models can require large data transfers. With AlexNet, this would require 240MB of communication from the server to the car. Smaller models require less communication, making frequent updates more feasible.\\bulletFeasible FPGA and embedded deployment. FPGAs often have less than 10MB111For example, the Xilinx Vertex-7 FPGA has a maximum of 8.5 MBytes (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory. of on-chip memory and no off-chip memory or storage. For inference, a sufficiently small model could be stored directly on the FPGA instead of being bottlenecked by memory bandwidth Qiu et al. (2016), while video frames stream through the FPGA in real time.Further, when deploying CNNs on Application-Specific Integrated Circuits (ASICs), a sufficiently small model could be stored directly on-chip, and smaller models may enable the ASIC to fit on a smaller die.\n\n#### Near 10 MB of on-chip memory and no off-chip memory or storage(For example, the Xilinx Vertex-7 FPGA has a maximum of 8.5 MB (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory)",
        "Much of the recent research on deep convolutional neural networks (CNNs) has focused on increasing accuracy on computer vision datasets.For a given accuracy level, there typically exist multiple CNN architectures that achieve that accuracy level.Given equivalent accuracy, a CNN architecture with fewer parameters has several advantages:\\bulletMore efficient distributed training.Communication among servers is the limiting factor to the scalability of distributed CNN training.For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the model Iandola et al. (2016).In short, small models train faster due to requiring less communication.\\bulletLess overhead when exporting new models to clients. For autonomous driving, companies such as Tesla periodically copy new models from their servers to customers’ cars. This practice is often referred to as an over-the-air update. Consumer Reports has found that the safety of Tesla’s Autopilot semi-autonomous driving functionality has incrementally improved with recent over-the-air updates Consumer Reports (2016). However, over-the-air updates of today’s typical CNN/DNN models can require large data transfers. With AlexNet, this would require 240MB of communication from the server to the car. Smaller models require less communication, making frequent updates more feasible.\\bulletFeasible FPGA and embedded deployment. FPGAs often have less than 10MB111For example, the Xilinx Vertex-7 FPGA has a maximum of 8.5 MBytes (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory. of on-chip memory and no off-chip memory or storage. For inference, a sufficiently small model could be stored directly on the FPGA instead of being bottlenecked by memory bandwidth Qiu et al. (2016), while video frames stream through the FPGA in real time.Further, when deploying CNNs on Application-Specific Integrated Circuits (ASICs), a sufficiently small model could be stored directly on-chip, and smaller models may enable the ASIC to fit on a smaller die.\n\n#### Tesla ( Model S for example ) autopilot system uses a convolutional neural network to detect objects on its way.",
        "Much of the recent research on deep convolutional neural networks (CNNs) has focused on increasing accuracy on computer vision datasets.For a given accuracy level, there typically exist multiple CNN architectures that achieve that accuracy level.Given equivalent accuracy, a CNN architecture with fewer parameters has several advantages:\\bulletMore efficient distributed training.Communication among servers is the limiting factor to the scalability of distributed CNN training.For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the model Iandola et al. (2016).In short, small models train faster due to requiring less communication.\\bulletLess overhead when exporting new models to clients. For autonomous driving, companies such as Tesla periodically copy new models from their servers to customers’ cars. This practice is often referred to as an over-the-air update. Consumer Reports has found that the safety of Tesla’s Autopilot semi-autonomous driving functionality has incrementally improved with recent over-the-air updates Consumer Reports (2016). However, over-the-air updates of today’s typical CNN/DNN models can require large data transfers. With AlexNet, this would require 240MB of communication from the server to the car. Smaller models require less communication, making frequent updates more feasible.\\bulletFeasible FPGA and embedded deployment. FPGAs often have less than 10MB111For example, the Xilinx Vertex-7 FPGA has a maximum of 8.5 MBytes (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory. of on-chip memory and no off-chip memory or storage. For inference, a sufficiently small model could be stored directly on the FPGA instead of being bottlenecked by memory bandwidth Qiu et al. (2016), while video frames stream through the FPGA in real time.Further, when deploying CNNs on Application-Specific Integrated Circuits (ASICs), a sufficiently small model could be stored directly on-chip, and smaller models may enable the ASIC to fit on a smaller die.\n\n#### Accuracy is crucial for safety but it's not only accuracy vs size relation. We should consider more aspects. For example, response time of a driving car system is very crucial for safety. Communication overhead between servers while model training increases with the size of the model so smaller models train faster. Updating models from company servers to the car or over-the-air updates based on AlexNet at that time would require 240MB of communication from the server to the car. Hence, smaller models require less communication, making frequent updates more feasible. Also, keeping in mind architectural designs such as adjusting some functionalities, introducing new ways of extracting features, or using different objectives and optimizers may make a small model achieve the same level of accuracy or even surpass the larger model; for instance, SqueezeNet is 50x smaller than AlexNet with equivalent accuracy.",
        "Much of the recent research on deep convolutional neural networks (CNNs) has focused on increasing accuracy on computer vision datasets.For a given accuracy level, there typically exist multiple CNN architectures that achieve that accuracy level.Given equivalent accuracy, a CNN architecture with fewer parameters has several advantages:\\bulletMore efficient distributed training.Communication among servers is the limiting factor to the scalability of distributed CNN training.For distributed data-parallel training, communication overhead is directly proportional to the number of parameters in the model Iandola et al. (2016).In short, small models train faster due to requiring less communication.\\bulletLess overhead when exporting new models to clients. For autonomous driving, companies such as Tesla periodically copy new models from their servers to customers’ cars. This practice is often referred to as an over-the-air update. Consumer Reports has found that the safety of Tesla’s Autopilot semi-autonomous driving functionality has incrementally improved with recent over-the-air updates Consumer Reports (2016). However, over-the-air updates of today’s typical CNN/DNN models can require large data transfers. With AlexNet, this would require 240MB of communication from the server to the car. Smaller models require less communication, making frequent updates more feasible.\\bulletFeasible FPGA and embedded deployment. FPGAs often have less than 10MB111For example, the Xilinx Vertex-7 FPGA has a maximum of 8.5 MBytes (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory. of on-chip memory and no off-chip memory or storage. For inference, a sufficiently small model could be stored directly on the FPGA instead of being bottlenecked by memory bandwidth Qiu et al. (2016), while video frames stream through the FPGA in real time.Further, when deploying CNNs on Application-Specific Integrated Circuits (ASICs), a sufficiently small model could be stored directly on-chip, and smaller models may enable the ASIC to fit on a smaller die.\n\n#### Xilinx Vertex-7 FPGA which has a maximum of 8.5 MB (i.e. 68 Mbits) of on-chip memory and does not provide off-chip memory.",
        "The overarching goal of our work is to identify a model that has very few parameters while preserving accuracy.To address this problem, a sensible approach is to take an existing CNN model and compress it in a lossy fashion.In fact, a research community has emerged around the topic of model compression, and several approaches have been reported.A fairly straightforward approach by Denton et al. is to apply singular value decomposition (SVD) to a pretrained CNN model Denton et al. (2014).Han et al. developed Network Pruning, which begins with a pretrained model, then replaces parameters that are below a certain threshold with zeros to form a sparse matrix, and finally performs a few iterations of training on the sparse CNN Han et al. (2015b).Recently, Han et al. extended their work by combining Network Pruning with quantization (to 8 bits or less) and huffman encoding to create an approach called Deep Compression Han et al. (2015a), and further designed a hardware accelerator called EIE Han et al. (2016a) that operates directly on the compressed model, achieving substantial speedups and energy savings.\n\n#### different examples can be: Applying SVD to a pretrained CNN model through which we can obtain most effective parameters or features of largest singular values of this factorization if we want. Information reconstruction of a matrix factorized with SVD  allow decreasing its rank, hence decreasing the memory allocated to save the vectors of these parameters . Also Network Pruning, which begins with a pretrained model, then replaces parameters that are below a certain threshold with zeros to form a sparse matrix, and finally performs a few iterations of training on the sparse CNN Maybe seen as another example . Deep compression -utilizing Huffman encoding, Network Pruning and quantization- yet is a third example.",
        "With the trend of designing very deep CNNs, it becomes cumbersome to manually select filter dimensions for each layer.To address this, various higher level building blocks, or modules, comprised of multiple convolution layers with a specific fixed organization have been proposed.For example, the GoogLeNet papers propose Inception modules, which are comprised of a number of different dimensionalities of filters, usually including 1x1 and 3x3, plus sometimes 5x5 Szegedy et al. (2014) and sometimes 1x3 and 3x1 Szegedy et al. (2015).Many such modules are then combined, perhaps with additional ad-hoc layers, to form a complete network.We use the term CNN microarchitecture to refer to the particular organization and dimensions of the individual modules.\n\n#### a module can be thought of as a block of some several layers may be of different filter sizes and dimensions to perform some specific functionality. Many such modules are then combined to form a complete network. For example, Inception modules, which are comprised of a number of different dimensionalities of filters, like 1x1 and 3x3, sometimes 5x5, 1x3 and 3x1.",
        "Neural networks (including deep and convolutional NNs) have a large design space, with numerous options for microarchitectures, macroarchitectures, solvers, and other hyperparameters.It seems natural that the community would want to gain intuition about how these factors impact a NN’s accuracy (i.e. the shape of the design space).Much of the work on design space exploration (DSE) of NNs has focused on developing automated approaches for finding NN architectures that deliver higher accuracy.These automated DSE approaches include bayesian optimization Snoek et al. (2012), simulated annealing Ludermir et al. (2006), randomized search Bergstra & Bengio (2012), and genetic algorithms Stanley & Miikkulainen (2002).To their credit, each of these papers provides a case in which the proposed DSE approach produces a NN architecture that achieves higher accuracy compared to a representative baseline.However, these papers make no attempt to provide intuition about the shape of the NN design space.Later in this paper, we eschew automated approaches – instead, we refactor CNNs in such a way that we can do principled A/B comparisons to investigate how CNN architectural decisions influence model size and accuracy.\n\n#### An example of DSE approach can be  Bayesian optimization, simulated annealing, randomized search or genetic algorithms and all tend to develop automated approaches to find NN architectures exhibiting higher accuracy.",
        "We define the Fire module as follows.A Fire module is comprised of: a squeeze convolution layer (which has only 1x1 filters), feeding into an expand layer that has a mix of 1x1 and 3x3 convolution filters; we illustrate this in Figure 1.The liberal use of 1x1 filters in Fire modules is an application of Strategy 1 from Section 3.1.We expose three tunable dimensions (hyperparameters) in a Fire module: s_{1x1}, e_{1x1}, and e_{3x3}.In a Fire module, s_{1x1} is the number of filters in the squeeze layer (all 1x1), e_{1x1} is the number of 1x1 filters in the expand layer, and e_{3x3} is the number of 3x3 filters in the expand layer.When we use Fire modules we set s_{1x1} to be less than (e_{1x1} + e_{3x3}), so the squeeze layer helps to limit the number of input channels to the 3x3 filters, as per Strategy 2 from Section 3.1.\n\n#### The question needs to be related to some certain context but if we consider asking about the ratio of 1*1 filters in each fire module then the answer would be as follows: for a fire module ratio of 1*1 filters w.r.t. all filters can be calculated as (s1x1+e1x1)/(s1x1+e1x1+e3x3) where; s1x1 is the number of filters in the squeeze layer,e1x1 is the number of 1x1 filters in the expand layer, and e3x3 is the number of 3x3 filters in the expand layer. It is also worth to mention that s1x1 is to be less than (e1x1 + e3x3), so the squeeze layer helps to limit the number of input channels to the 3x3 filters.",
        "Strategy 3. Downsample late in the network so that convolution layers have large activation maps.In a convolutional network, each convolution layer produces an output activation map with a spatial resolution that is at least 1x1 and often much larger than 1x1.The height and width of these activation maps are controlled by: (1) the size of the input data (e.g. 256x256 images) and (2) the choice of layers in which to downsample in the CNN architecture.Most commonly, downsampling is engineered into CNN architectures by setting the (stride > 1) in some of the convolution or pooling layers (e.g. Szegedy et al. (2014); Simonyan & Zisserman (2014); Krizhevsky et al. (2012)).If early333In our terminology, an “early” layer is close to the input data. layers in the network have large strides, then most layers will have small activation maps.Conversely, if most layers in the network have a stride of 1, and the strides greater than 1 are concentrated toward the end444In our terminology, the “end” of the network is the classifier. of the network, then many layers in the network will have large activation maps.Our intuition is that large activation maps (due to delayed downsampling) can lead to higher classification accuracy, with all else held equal.Indeed, K. He and H. Sun applied delayed downsampling to four different CNN architectures, and in each case delayed downsampling led to higher classification accuracy He & Sun (2015).\n\n#### As we can see, downsampling aim to collect summary about statistics of different regions of some feature map, and this can be addressed with stride >1 in convolution or pooling layers which affects the size of activation map. If early layers  have large strides, then most layers will have small activation maps and if most layers in the network have a stride of 1, and the strides greater than 1 are later in the network, then many layers in the network will have large activation maps.",
        "Strategy 2. Decrease the number of input channels to 3x3 filters.Consider a convolution layer that is comprised entirely of 3x3 filters.The total quantity of parameters in this layer is (number of input channels) * (number of filters) * (3*3).So, to maintain a small total number of parameters in a CNN, it is important not only to decrease the number of 3x3 filters (see Strategy 1 above), but also to decrease the number of input channels to the 3x3 filters.We decrease the number of input channels to 3x3 filters using squeeze layers, which we describe in the next section. \n\n#### Authors used a mix of 1x1 and 3x3 filters in the expand layer of the fire module to reduce the number of parameters while still getting benefits from the desired properties of having reasonable scope of the input receptive field and extracting correlations and useful information by applying the 3*3 filters of the CNN. To have a small number of parameters in a CNN, we need to decrease the number of input channels to the 3x3 filters and here comes the role of 1*1 filters, while the 3x3 filters are used to capture larger spatial features (Assuming only 3*3 and 1*1 kernels). This way, the model get its wide fame of achieving a high level of accuracy with fewer parameters than other networks.",
        "We define the Fire module as follows.A Fire module is comprised of: a squeeze convolution layer (which has only 1x1 filters), feeding into an expand layer that has a mix of 1x1 and 3x3 convolution filters; we illustrate this in Figure 1.The liberal use of 1x1 filters in Fire modules is an application of Strategy 1 from Section 3.1.We expose three tunable dimensions (hyperparameters) in a Fire module: s_{1x1}, e_{1x1}, and e_{3x3}.In a Fire module, s_{1x1} is the number of filters in the squeeze layer (all 1x1), e_{1x1} is the number of 1x1 filters in the expand layer, and e_{3x3} is the number of 3x3 filters in the expand layer.When we use Fire modules we set s_{1x1} to be less than (e_{1x1} + e_{3x3}), so the squeeze layer helps to limit the number of input channels to the 3x3 filters, as per Strategy 2 from Section 3.1.\n\n#### s1x1 is the number of filters in the squeeze layer and it is set s1x1 to be less than (e1x1 + e3x3) -the total number of filters in expand layer of the fire module- to limit the number of input channels to the 3x3 filters.",
        "\\bulletSo that the output activations from 1x1 and 3x3 filters have the same height and width, we add a 1-pixel border of zero-padding in the input data to 3x3 filters of expand modules.\\bulletReLU Nair & Hinton (2010) is applied to activations from squeeze and expand layers.\\bulletDropout Srivastava et al. (2014) with a ratio of 50% is applied after the fire9 module.\\bulletNote the lack of fully-connected layers in SqueezeNet; this design choice was inspired by the NiN Lin et al. (2013) architecture.\\bulletWhen training SqueezeNet, we begin with a learning rate of 0.04, and we linearly decrease the learning rate throughout training, as described in Mishkin et al. (2016).For details on the training protocol (e.g. batch size, learning rate, parameter initialization), please refer to our Caffe-compatible configuration files located here: https://github.com/DeepScale/SqueezeNet.\\bulletThe Caffe framework does not natively support a convolution layer that contains multiple filter resolutions (e.g. 1x1 and 3x3) Jia et al. (2014). To get around this, we implement our expand layer with two separate convolution layers: a layer with 1x1 filters, and a layer with 3x3 filters. Then, we concatenate the outputs of these layers together in the channel dimension. This is numerically equivalent to implementing one layer that contains both 1x1 and 3x3 filters.\n\n#### The additional cost of using 2 convolutional layers may be that the parameters of the 2 layers are now trained separately; they are not benefiting from each other being jointly optimized to perform some task and share useful information between each other while training, but output shape is still not affected by the separation i.e.,this is numerically equivalent to have one layer that contains both 1x1 and 3x3 filters.",
        "We now turn our attention to evaluating SqueezeNet.In each of the CNN model compression papers reviewed in Section 2.1, the goal was to compress an AlexNet Krizhevsky et al. (2012) model that was trained to classify images using the ImageNet Deng et al. (2009) (ILSVRC 2012) dataset.Therefore, we use AlexNet555Our baseline is bvlc_alexnet from the Caffe codebase Jia et al. (2014). and the associated model compression results as a basis for comparison when evaluating SqueezeNet.\n\n#### Yes, as told by authors that they used AlexNet and the associated model compression results as a basis for comparison when evaluating SqueezeNet.",
        "In addition, these results demonstrate that Deep Compression Han et al. (2015a) not only works well on CNN architectures with many parameters (e.g. AlexNet and VGG), but it is also able to compress the already compact, fully convolutional SqueezeNet architecture.Deep Compression compressed SqueezeNet by 10×10\\times10 × while preserving the baseline accuracy.In summary: by combining CNN architectural innovation (SqueezeNet) with state-of-the-art compression techniques (Deep Compression), we achieved a 510×510\\times510 × reduction in model size with no decrease in accuracy compared to the baseline.\n\n#### by combining CNN architectural innovation (SqueezeNet) with state-of-the-art compression techniques (Deep Compression), we achieved a 510× reduction in model size with no decrease in accuracy compared\nto the baseline.",
        "It appears that we have surpassed the state-of-the-art results from the model compression community:even when using uncompressed 32-bit values to represent the model, SqueezeNet has a 1.4×1.4\\times1.4 × smaller model size than the best efforts from the model compression community while maintaining or exceeding the baseline accuracy.Until now, an open question has been: are small models amenable to compression, or do small models “need” all of the representational power afforded by dense floating-point values?To find out, we applied Deep Compression Han et al. (2015a) to SqueezeNet, using 33% sparsity666Note that, due to the storage overhead of storing sparse matrix indices, 33% sparsity leads to somewhat less than a 3×3\\times3 × decrease in model size. and 8-bit quantization.This yields a 0.66 MB model (363×363\\times363 × smaller than 32-bit AlexNet) with equivalent accuracy to AlexNet.Further, applying Deep Compression with 6-bit quantization and 33% sparsity on SqueezeNet, we produce a 0.47MB model (510×510\\times510 × smaller than 32-bit AlexNet) with equivalent accuracy.Our small model is indeed amenable to compression.\n\n#### size after taking these considerations would be a 0.66 MB model 363× smaller than 32-bit AlexNet with equivalent accuracy to AlexNet.",
        "In these experiments, we use SqueezeNet (Figure 2) as a starting point.As in SqueezeNet, these experiments use the following metaparameters: base_{e}=128, incr_{e}=128, pct_{3x3}=0.5, and freq=2.We train multiple models, where each model has a different squeeze ratio (SR)777Note that, for a given model, all Fire layers share the same squeeze ratio. in the range [0.125, 1.0].In Figure 3(a), we show the results of this experiment, where each point on the graph is an independent model that was trained from scratch.SqueezeNet is the SR=0.125 point in this figure.888Note that we named it SqueezeNet because it has a low squeeze ratio (SR). That is, the squeeze layers in SqueezeNet have 0.125x the number of filters as the expand layers.From this figure, we learn that increasing SR beyond 0.125 can further increase ImageNet top-5 accuracy from 80.3% (i.e. AlexNet-level) with a 4.8MB model to 86.0% with a 19MB model.Accuracy plateaus at 86.0% with SR=0.75 (a 19MB model), and setting SR=1.0 further increases model size without improving accuracy.\n\n#### To investigate the effect of the squeeze ratio on model size, models were trained from scratch so that one can make comparisons for these separate models.",
        "One limitation is that, in the straightforward case, the number of input channels and number of output channels has to be the same; as a result, only half of the Fire modules can have simple bypass connections, as shown in the middle diagram of Fig 2.When the “same number of channels” requirement can’t be met, we use a complex bypass connection, as illustrated on the right of Figure 2.While a simple bypass is “just a wire,” we define a complex bypass as a bypass that includes a 1x1 convolution layer with the number of filters set equal to the number of output channels that are needed.Note that complex bypass connections add extra parameters to the model, while simple bypass connections do not.\n\n#### Yes, complex bypass connections add extra parameters to the model as we add 1x1 convolution layer with the number of filters set equal to the number of output channels.",
        "In Table 2, we review SqueezeNet in the context of recent model compression results.The SVD-based approach is able to compress a pretrained AlexNet model by a factor of 5x, while diminishing top-1 accuracy to 56.0% Denton et al. (2014).Network Pruning achieves a 9x reduction in model size while maintaining the baseline of 57.2% top-1 and 80.3% top-5 accuracy on ImageNet Han et al. (2015b).Deep Compression achieves a 35x reduction in model size while still maintaining the baseline accuracy level Han et al. (2015a).Now, with SqueezeNet, we achieve a 50X reduction in model size compared to AlexNet, while meeting or exceeding the top-1 and top-5 accuracy of AlexNet.We summarize all of the aforementioned results in Table 2.\n\n#### It is the same as AlexNet and SqueezeNet maybe,exceed it for some experimental cases.",
        "The choice of connections across multiple layers or modules is an emerging area of CNN macroarchitectural research.Residual Networks (ResNet) He et al. (2015b) and Highway Networks Srivastava et al. (2015) each propose the use of connections that skip over multiple layers, for example additively connecting the activations from layer 3 to the activations from layer 6.We refer to these connections as bypass connections.The authors of ResNet provide an A/B comparison of a 34-layer CNN with and without bypass connections; adding bypass connections delivers a 2 percentage-point improvement on Top-5 ImageNet accuracy.\n\n#### This was one of the experimental investigations that was interesting. We can see the answer in simple bypass (wire) as it resemble residual connections which help in keeping considerable gradient values needed for precise learning specially while going deeper. Also, complex bypass adds more parameters which increases the number of parameters trained for the same task on the same data(it may have some small overfitting side effect ).",
        "As you can see, there are several advantages of smaller CNN architectures.With this in mind, we focus directly on the problem of identifying a CNN architecture with fewer parameters but equivalent accuracy compared to a well-known model.We have discovered such an architecture, which we call SqueezeNet.In addition, we present our attempt at a more disciplined approach to searching the design space for novel CNN architectures.\n\n#### They come to an impact that the size of the model can be reduced while still obtaining same or higher accuracy with fewer parameters through manipulating architectural design strategies as is the case in their architecture -SqueezeNet. Although the authors rather design and execute experiments with the goal of providing intuitions about the shape of the microarchitectural design space with respect to the design strategies they proposed, SqueezeNet and other models reside in a broad and largely unexplored design\nspace of CNN architectures that need more investigations",
        "Anchor box x,y offset predictions. We tried using the normal anchor box prediction mechanism where you predict the x,y offset as a multiple of the box width or height using a linear activation. We found this formulation decreased model stability and didn’t work very well.\n\n#### The authors they tried multiples of the initial anchor sizes specified by the 9 clusters. The clusters as specified at the cell D58.",
        "YOLOv3 predicts boxes at 3 different scales. Our system extracts features from those scales using a similar concept to feature pyramid networks [8]. From our base feature extractor we add several convolutional layers. The last of these predicts a 3-d tensor encoding bounding box, objectness, and class predictions. In our experiments with COCO [10] we predict 3 boxes at each scale so the tensor is N\\times N\\times[3*(4+1+80)] for the 4 bounding box offsets, 1 objectness prediction, and 80 class predictions.\n\n#### The answer is nine as there are three predictions for three different scales.",
        "Following YOLO9000 our system predicts bounding boxes using dimension clusters as anchor boxes [15]. The network predicts 4 coordinates for each bounding box, t_{x}, t_{y}, t_{w}, t_{h}. If the cell is offset from the top left corner of the image by (c_{x},c_{y}) and the bounding box prior has width and height p_{w}, p_{h}, then the predictions correspond to:\n\n#### The question is partially answered as \"If the cell is offset from the top left corner of the image by (c_{x},c_{y}) and the bounding box prior has width and height p_{w}, p_{h}, then the predictions correspond to:\", but is completely answered in the continuation of the paper (in the expression).",
        "We still train on full images with no hard negative mining or any of that stuff. We use multi-scale training, lots of data augmentation, batch normalization, all the standard stuff. We use the Darknet neural network framework for training and testing [14].\n\n#### They use augmentation, mention it only once in the paper, and this is the place. No additional details about data augmentation.",
        "We use a new network for performing feature extraction. Our new network is a hybrid approach between the network used in YOLOv2, Darknet-19, and that newfangled residual network stuff. Our network uses successive 3\\times 3 and 1\\times 1 convolutional layers but now has some shortcut connections as well and is significantly larger. It has 53 convolutional layers so we call it…. wait for it….. Darknet-53!\n\n#### \"residuals\" = skip connections, which means that DarkNet-53 uses skip connections.",
        "However, when we look at the “old” detection metric of mAP at IOU=.5 (or AP{}_{50} in the chart) YOLOv3 is very strong. It is almost on par with RetinaNet and far above the SSD variants. This indicates that YOLOv3 is a very strong detector that excels at producing decent boxes for objects. However, performance drops significantly as the IOU threshold increases indicating YOLOv3 struggles to get the boxes perfectly aligned with the object.\n\n#### YOLOv3 performs poorly because ot struggles to get the perfect bounding box alignment with the objects.",
        "Focal loss. We tried using focal loss. It dropped our mAP about 2 points. YOLOv3 may already be robust to the problem focal loss is trying to solve because it has separate objectness predictions and conditional class predictions. Thus for most examples there is no loss from the class predictions? Or something? We aren’t totally sure.\n\n#### The authors hypothesize that YOLOv3 may already be robust to the problem which the focal loss is tryin to solve because it has spearate objectness predictions and conditional class predictions. That is why adding the focal loss did not improve the performance of YOLOv3.",
        "But maybe a better question is: “What are we going to do with these detectors now that we have them?” A lot of the people doing this research are at Google and Facebook. I guess at least we know the technology is in good hands and definitely won’t be used to harvest your personal information and sell it to…. wait, you’re saying that’s exactly what it will be used for?? Oh.\n\n#### A sarcastic comment means a concern for authors that Google, Facebook, and similar corporations use these kind of models to harvest and use our personal information. A similar sarcastic comment regarding military. The authors should be responsible for their work and consider possible consequences to the world.",
        "YOLOv3 is pretty good! See table 3. In terms of COCOs weird average mean AP metric it is on par with the SSD variants but is 3×3\\times3 × faster. It is still quite a bit behind other models like RetinaNet in this metric though.\n\n#### Some of the limitations of YOLOv3, based on the information given in the paper are: it is still quite a bit behind other models like RetinaNet in the \"COCO's weired average mAP\" metric (COCO average AP between 95 IOU metric), performance drops significantly as the IOU threshold increases indicating YOLOv3 struggles to get the boxes perfectly aligned with the object, it has comparatively worse performance on medium and larger size objects.",
        "Each network is trained with identical settings and tested at 256\\times 256, single crop accuracy. Run times are measured on a Titan X at 256\\times 256. Thus Darknet-53 performs on par with state-of-the-art classifiers but with fewer floating point operations and more speed. Darknet-53 is better than ResNet-101 and 1.5×1.5\\times1.5 × faster. Darknet-53 has similar performance to ResNet-152 and is 2×2\\times2 × faster.\n\n#### Darknet-53 is better than ResNet-101 and 1.5×1.5\\times1.5 × faster.",
        "Each box predicts the classes the bounding box may contain using multilabel classification. We do not use a softmax as we have found it is unnecessary for good performance, instead we simply use independent logistic classifiers. During training we use binary cross-entropy loss for the class predictions.\n\n#### The authors use binary cross-entropy loss.",
        "In the past YOLO struggled with small objects. However, now we see a reversal in that trend. With the new multi-scale predictions we see YOLOv3 has relatively high AP{}_{S} performance. However, it has comparatively worse performance on medium and larger size objects. More investigation is needed to get to the bottom of this.\n\n#### YOLOv3 now struggles more with medium and larger size objects, i.e., performs worse than before. On the other hand, it is more succesful for smaller objects.",
        "We use a new network for performing feature extraction. Our new network is a hybrid approach between the network used in YOLOv2, Darknet-19, and that newfangled residual network stuff. Our network uses successive 3\\times 3 and 1\\times 1 convolutional layers but now has some shortcut connections as well and is significantly larger. It has 53 convolutional layers so we call it…. wait for it….. Darknet-53!\n\n#### YOLOv3 is faster and better than YOLO. It has more layers. The authors also tried some small tricks and experiments which further improved the overall performance.",
        "We perform the same design one more time to predict boxes for the final scale. Thus our predictions for the 3rd scale benefit from all the prior computation as well as fine-grained features from early on in the network.\n\n#### By using multi-scaled prediction, YOLOv3 has improved performance for small objects. Also, the subsequent scales benefit from previous scales and the previous features from earlier layers.",
        "Linear x,y predictions instead of logistic. We tried using a linear activation to directly predict the x,y offset instead of the logistic activation. This led to a couple point drop in mAP.\n\n#### Binary cross-entropy is used for the class predictions. Logistic activation is used and is better than the linear activation.",
        "Generalization over time scalesIn the next experiment, we test if the model can work at time scales that aredifferent than what it was trained on. We take a one hidden layer unconditionedComposite Model trained on moving MNIST digits. The model has 2048 LSTM unitsand looks at a 64 \\times 64 input. It was trained on input sequences of 10frames to reconstruct those 10 frames as well as predict 10 frames into thefuture. In order to test if the future predictor is able to generalize beyond 10frames, we let the model run for 100 steps into the future.Fig. 7(a) shows the pattern of activity in the LSTM units of thefuture predictorpathway for a randomly chosen test input. It shows the activity at each of thethree sigmoidal gates (input, forget, output), the input (after the tanhnon-linearity, before being multiplied by the input gate), the cell state andthe final output (after being multiplied by the output gate). Even though theunits are ordered randomly along the vertical axis, we can see that the dynamicshas a periodic quality to it. The model is able to generate persistent motionfor long periods of time. In terms of reconstruction, the model only outputsblobs after the first 15 frames, but the motion is relatively well preserved.More results, including long range future predictions over hundreds of time steps can see been athttp://www.cs.toronto.edu/~nitish/unsupervised_video.To show that setting up a periodic behaviour is not trivial,Fig. 7(b) shows the activity from a randomly initialized futurepredictor. Here, the LSTM state quickly converges and the outputs blur completely.\n\n#### 5 different types of experiments are performed to test the proposed models. They are Generalization over time scales, Experiments on MNIST, Experiments on Natural Image Patches, Out-of-domain Inputs, and Visualizing Features.",
        "Another natural unsupervised learning task for sequences is predicting thefuture. This is the approach used in language models for modeling sequences ofwords. The design of the Future Predictor Model is same as that of theAutoencoder Model, except that the decoder LSTM in this case predicts frames ofthe video that come after the input sequence (Fig. 3).Ranzato et al. (2014) use a similar model but predict only the next frame at eachtime step. This model, on the other hand, predicts a long sequence into thefuture. Here again we can consider two variants of the decoder – conditionaland unconditioned.\n\n#### Future Predictor, Composite Model, Conditional Future Predictor, Composite Model with Conditional Future Predictor are the variants of LSTM encoder-decoder models are used in this study.",
        "In order to evaluate the learned representations we qualitatively analyze thereconstructions and predictions made by the model. For a more quantitativeevaluation, we use these LSTMs as initializations for the supervised task ofaction recognition. If the unsupervised learning model comes up with usefulrepresentations then the classifier should be able to perform better, especiallywhen there are only a few labelled examples. We find that this is indeed thecase.\n\n#### The supervised task is action recognition and unsupervised tasks are representation reconstruction, which can be inferred from P4.",
        "Understanding temporal sequences is important for solving many problems in theAI-set. Recently, recurrent neural networks using the Long Short Term Memory(LSTM) architecture (Hochreiter & Schmidhuber, 1997) have been used successfully to perform various supervisedsequence learning tasks, such as speech recognition (Graves & Jaitly, 2014), machinetranslation (Sutskever et al., 2014; Cho et al., 2014), and caption generation for images(Vinyals et al., 2014). They have also been applied on videos for recognizingactions and generating natural language descriptions (Donahue et al., 2014). Ageneral sequence to sequence learning framework was described by Sutskever et al. (2014)in which a recurrent network is used to encode a sequence into a fixed lengthrepresentation, and then another recurrent network is used to decode a sequenceout of that representation. In this work, we apply and extend this framework tolearn representations of sequences of images. We choose to work in theunsupervised setting where we only have access to a dataset of unlabelledvideos.\n\n#### Recurrent neural networks using the Long Short Term Memory(LSTM) architectures have been used for supervised sequence learning tasks.",
        "Understanding temporal sequences is important for solving many problems in theAI-set. Recently, recurrent neural networks using the Long Short Term Memory(LSTM) architecture (Hochreiter & Schmidhuber, 1997) have been used successfully to perform various supervisedsequence learning tasks, such as speech recognition (Graves & Jaitly, 2014), machinetranslation (Sutskever et al., 2014; Cho et al., 2014), and caption generation for images(Vinyals et al., 2014). They have also been applied on videos for recognizingactions and generating natural language descriptions (Donahue et al., 2014). Ageneral sequence to sequence learning framework was described by Sutskever et al. (2014)in which a recurrent network is used to encode a sequence into a fixed lengthrepresentation, and then another recurrent network is used to decode a sequenceout of that representation. In this work, we apply and extend this framework tolearn representations of sequences of images. We choose to work in theunsupervised setting where we only have access to a dataset of unlabelledvideos.\n\n#### Since LSTM based encoder/decoder method successfully worked for real time sequential nature application, it is a good method.",
        "The baseline for comparing these models is an identical LSTM classifier but with randomly initialized weights. All classifiers used dropout regularization, where we dropped activations as they were communicated across layers but not through time within the same LSTM as proposed in Zaremba et al. (2014). We emphasize that this is a very strong baseline and does significantly better than just using single frames. Using dropout was crucial in order to train good baseline models especially with very few training examples.\n\n#### The authors extended identical LSTM classifier framework as baseline to learn representation of image sequences.",
        "Supervised learning has been extremely successful in learning good visualrepresentations that not only produce good results at the task they are trainedfor, but also transfer well to other tasks and datasets. Therefore, it isnatural to extend the same approach to learning video representations. This hasled to research in 3D convolutional nets (Ji et al., 2013; Tran et al., 2014), different temporalfusion strategies (Karpathy et al., 2014) and exploring different ways ofpresenting visual information to convolutional nets (Simonyan & Zisserman, 2014a).However, videos are much higher dimensional entities compared to single images.Therefore, it becomes increasingly difficult to do credit assignment and learn longrange structure, unless we collect much more labelled data or do a lot offeature engineering (for example computing the right kinds of flow features) tokeep the dimensionality low. The costly work of collecting more labelled dataand the tedious work of doing more clever engineering can go a long way insolving particular problems, but this is ultimately unsatisfying as a machinelearning solution. This highlights the need for using unsupervised learning tofind and represent structure in videos. Moreover, videos have a lot ofstructure in them (spatial and temporal regularities) which makes themparticularly well suited as a domain for building unsupervised learning models.\n\n#### Labelling videos is a tedious job and that makes supervise training very expensive. Compare to that unsupervised model can take advantage of all videos available that doesn't need labelling. That's why the authors prefer to learn video representations through unsupervised models.",
        "In this section, we describe a model that uses Recurrent Neural Nets (RNNs) madeof LSTM units to do unsupervised learning. The model consists of two RNNs –the encoder LSTM and the decoder LSTM as shown in Fig. 2. Theinput to the model is a sequence of vectors (image patches or features). Theencoder LSTM reads in this sequence. After the last input has been read, thedecoder LSTM takes over and outputs a prediction for the target sequence. Thetarget sequence is same as the input sequence, but in reverse order. Reversingthe target sequence makes the optimization easier because the model can get offthe ground by looking at low range correlations. This is also inspired by howlists are represented in LISP. The encoder can be seen as creating a list byapplying the cons function on the previously constructed list and the newinput. The decoder essentially unrolls this list, with the hidden to outputweights extracting the element at the top of the list (car function) andthe hidden to hidden weights extracting the rest of the list (cdrfunction). Therefore, the first element out is the last element in.\n\n#### From P0 and P1, It is directly answered that, through encoder-decoder the target sequence is produced.",
        "The inputs to the model can, in principle, be any representation of individualvideo frames. However, for the purposes of this work, we limit our attention totwo kinds of inputs. The first is image patches. For this we use natural imagepatches as well as a dataset of moving MNIST digits. The second ishigh-level “percepts” extracted by applying a convolutional net trained onImageNet. These percepts are the states of last (and/or second-to-last) layers ofrectified linear hidden states from a convolutional neural net model.\n\n#### Image patches and high-level percepts are the two types of inputs used in the proposed model.",
        "Why should this learn good features?The state of the encoder LSTM after the last input has been read is therepresentation of the input video. The decoder LSTM is being asked toreconstruct back the input sequence from this representation. In order to do so,the representation must retain information about the appearance of the objectsand the background as well as the motion contained in the video.However, an important question for any autoencoder-style model is what preventsit from learning an identity mapping and effectively copying the input to theoutput. In that case all the information about the input would still be presentbut the representation will be no better than the input. There are two factorsthat control this behaviour. First, the fact that there are only a fixed numberof hidden units makes it unlikely that the model can learn trivial mappings forarbitrary length input sequences. Second, the same LSTM operation is used todecode the representation recursively. This means that the same dynamics must beapplied on the representation at any stage of decoding. This further preventsthe model from learning an identity mapping.\n\n#### Since LSTM based auto-encoder models control the learning an identity mapping, it forced learn good features.",
        "Why should this learn good features?The state of the encoder LSTM after the last input has been read is therepresentation of the input video. The decoder LSTM is being asked toreconstruct back the input sequence from this representation. In order to do so,the representation must retain information about the appearance of the objectsand the background as well as the motion contained in the video.However, an important question for any autoencoder-style model is what preventsit from learning an identity mapping and effectively copying the input to theoutput. In that case all the information about the input would still be presentbut the representation will be no better than the input. There are two factorsthat control this behaviour. First, the fact that there are only a fixed numberof hidden units makes it unlikely that the model can learn trivial mappings forarbitrary length input sequences. Second, the same LSTM operation is used todecode the representation recursively. This means that the same dynamics must beapplied on the representation at any stage of decoding. This further preventsthe model from learning an identity mapping.\n\n#### The two factors that control the model from learning an identity mapping or prevent overfitting are fixed number of hidden units and forceful decode of the input representation recursively.",
        "Generalization over time scalesIn the next experiment, we test if the model can work at time scales that aredifferent than what it was trained on. We take a one hidden layer unconditionedComposite Model trained on moving MNIST digits. The model has 2048 LSTM unitsand looks at a 64 \\times 64 input. It was trained on input sequences of 10frames to reconstruct those 10 frames as well as predict 10 frames into thefuture. In order to test if the future predictor is able to generalize beyond 10frames, we let the model run for 100 steps into the future.Fig. 7(a) shows the pattern of activity in the LSTM units of thefuture predictorpathway for a randomly chosen test input. It shows the activity at each of thethree sigmoidal gates (input, forget, output), the input (after the tanhnon-linearity, before being multiplied by the input gate), the cell state andthe final output (after being multiplied by the output gate). Even though theunits are ordered randomly along the vertical axis, we can see that the dynamicshas a periodic quality to it. The model is able to generate persistent motionfor long periods of time. In terms of reconstruction, the model only outputsblobs after the first 15 frames, but the motion is relatively well preserved.More results, including long range future predictions over hundreds of time steps can see been athttp://www.cs.toronto.edu/~nitish/unsupervised_video.To show that setting up a periodic behaviour is not trivial,Fig. 7(b) shows the activity from a randomly initialized futurepredictor. Here, the LSTM state quickly converges and the outputs blur completely.\n\n#### It is directly answered that 10  future frames can be predicted by the proposed LSTM Future Predictor Model.",
        "Another natural unsupervised learning task for sequences is predicting thefuture. This is the approach used in language models for modeling sequences ofwords. The design of the Future Predictor Model is same as that of theAutoencoder Model, except that the decoder LSTM in this case predicts frames ofthe video that come after the input sequence (Fig. 3).Ranzato et al. (2014) use a similar model but predict only the next frame at eachtime step. This model, on the other hand, predicts a long sequence into thefuture. Here again we can consider two variants of the decoder – conditionaland unconditioned.\n\n#### Ranzato model predict only the next frame but LSTM future predictor model predicts a long sequence into the future. Directly answerable from the paragraph.",
        "When designing any unsupervised learning model, it is crucial to have the right inductive biases and choose the right objective function so that the learning signal points the model towards learning useful features. In this paper, we use the LSTM Encoder-Decoder framework to learn video representations. The key inductive bias here is that the same operation must be applied at each time step to propagate information to the next step. This enforces the fact that the physics of the world remains the same, irrespective of input. The same physics acting on any state, at any time, must produce the next state. Our model works as follows. The Encoder LSTM runs through a sequence of frames to come up with a representation. This representation is then decoded through another LSTM to produce a target sequence. We consider different choices of the target sequence. One choice is to predict the same sequence as the input. The motivation is similar to that of autoencoders – we wish to capture all that is needed to reproduce the input but at the same time go through the inductive biases imposed by the model. Another option is to predict the future frames. Here the motivation is to learn a representation that extracts all that is needed to extrapolate the motion and appearance beyond what has been observed. These two natural choices can also be combined. In this case, there are two decoder LSTMs – one that decodes the representation into the input sequence and another that decodes the same representation to predict the future.\n\n#### Since representation is another form of input, that's why it doesn't need label for any purpose.",
        "There is also an argument against using a conditional decoder from theoptimization point-of-view. There are strong short-range correlations invideo data, for example, most of the content of a frame is same as the previousone. If the decoder was given access to the last few frames while generating aparticular frame at training time, it would find it easy to pick up on thesecorrelations. There would only be a very small gradient that tries to fix up theextremely subtle errors that require long term knowledge about the inputsequence. In an unconditioned decoder, this input is removed and the model isforced to look for information deep inside the encoder.\n\n#### Since in conditional decoder have access to last few frames, often it find a easy way to pick up a correlated frame but not necessary an optimized one. That is why it is difficult to optimize.",
        "For each of these two models, we can consider two possibilities - one in whichthe decoder LSTM is conditioned on the last generated frame and the other inwhich it is not. In the experimental section, we explore these choicesquantitatively. Here we briefly discuss arguments for and against a conditionaldecoder. A strong argument in favour of using a conditional decoder is that itallows the decoder to model multiple modes in the target sequence distribution.Without that, we would end up averaging the multiple modes in the low-levelinput space. However, this is an issue only if we expect multiple modes in thetarget sequence distribution. For the LSTM Autoencoder, there is only onecorrect target and hence a unimodal target distribution. But for the LSTM FuturePredictor there is a possibility of multiple targets given an input because evenif we assume a deterministic universe, everything needed to predict the futurewill not necessarily be observed in the input.\n\n#### The author talk both advantage and disadvantage of conditional and unconditional decoder blocks. They also provided a strong argument in favor of using a conditional decoder but clearly no winner is mentioned. The question does not have any clear answer in this paper.",
        "We use the UCF-101 and HMDB-51 datasets for supervised tasks.The UCF-101 dataset (Soomro et al., 2012) contains 13,320 videos with an average length of6.2 seconds belonging to 101 different action categories. The dataset has 3standard train/test splits with the training set containing around 9,500 videosin each split (the rest are test).The HMDB-51 dataset (Kuehne et al., 2011) contains 5100 videos belonging to 51 differentaction categories. Mean length of the videos is 3.2 seconds. This also has 3train/test splits with 3570 videos in the training set and rest in test.\n\n#### UCF-101 and HMDB-51 datasets are used for supervised learning.",
        "To train the unsupervised models, we used a subset of the Sports-1M dataset(Karpathy et al., 2014), that contains 1 million YouTube clips.Even though this dataset is labelled for actions, we didnot do any supervised experiments on it because of logistical constraints withworking with such a huge dataset. We instead collected 300 hours of video byrandomly sampling 10 second clips from the dataset. It is possible to collectbetter samples if instead of choosing randomly, we extracted videos where a lot ofmotion is happening and where there are no shot boundaries. However, we did notdo so in the spirit of unsupervised learning, and because we did not want tointroduce any unnatural bias in the samples. We also used the superviseddatasets (UCF-101 and HMDB-51) for unsupervised training. However, we found thatusing them did not give any significant advantage over just using the YouTubevideos.\n\n#### UCF-101, HMDB-51 and YouTube videos datasets are used for supervised learning.",
        "We use the UCF-101 and HMDB-51 datasets for supervised tasks.The UCF-101 dataset (Soomro et al., 2012) contains 13,320 videos with an average length of6.2 seconds belonging to 101 different action categories. The dataset has 3standard train/test splits with the training set containing around 9,500 videosin each split (the rest are test).The HMDB-51 dataset (Kuehne et al., 2011) contains 5100 videos belonging to 51 differentaction categories. Mean length of the videos is 3.2 seconds. This also has 3train/test splits with 3570 videos in the training set and rest in test.\n\n#### The UCF-101 dataset contains 13,320 videos with an average length of 6.2 seconds. The HMDB-51 dataset contains 5100 videos with mean length of the videos is 3.2 seconds.",
        "Fig. 12 compares three models - single frame classifier(logistic regression), baseline LSTM classifier and the LSTM classifierinitialized with weights from the Composite Model as the number of labelledvideos per class is varied. Note that having one labelled video means havingmany labelled 16 frame blocks. We can see that for the case of very fewtraining examples, unsupervised learning gives a substantial improvement. Forexample, for UCF-101, the performance improves from 29.6% to 34.3% whentraining on only one labelled video. As the size of the labelled dataset grows,the improvement becomes smaller. Even for the full UCF-101 dataset we still get aconsiderable improvement from 74.5% to 75.8%. On HMDB-51, the improvement isfrom 42.8% to 44.0% for the full dataset (70 videos per class) and 14.4% to19.1% for one video per class. Although, the improvement in classification byusing unsupervised learning was not as big as we expected, we still managed toyield an additional improvement over a strong baseline. We discuss some avenuesfor improvements later.\n\n#### The improvement in classification by using unsupervised learning was not as big as we expected, we still managed to yield an additional improvement over a strong baseline. If the unsupervised learning model comes up with useful representations then the classifier perform better, especially when there are only a few labelled examples. Based on the above evidence, it can be safely said that features learned by unsupervised learning improved the performance of supervised learning tasks.",
        "Fig. 12 compares three models - single frame classifier(logistic regression), baseline LSTM classifier and the LSTM classifierinitialized with weights from the Composite Model as the number of labelledvideos per class is varied. Note that having one labelled video means havingmany labelled 16 frame blocks. We can see that for the case of very fewtraining examples, unsupervised learning gives a substantial improvement. Forexample, for UCF-101, the performance improves from 29.6% to 34.3% whentraining on only one labelled video. As the size of the labelled dataset grows,the improvement becomes smaller. Even for the full UCF-101 dataset we still get aconsiderable improvement from 74.5% to 75.8%. On HMDB-51, the improvement isfrom 42.8% to 44.0% for the full dataset (70 videos per class) and 14.4% to19.1% for one video per class. Although, the improvement in classification byusing unsupervised learning was not as big as we expected, we still managed toyield an additional improvement over a strong baseline. We discuss some avenuesfor improvements later.\n\n#### As the number of training videos increases the performance of supervised and unsupervised tasks increases.",
        "Finally, we compare our models to the state-of-the-art action recognitionresults. The performance is summarized in Table 4. The table isdivided into three sets. The first set compares models that use only RGB data(single or multiple frames). The second set compares models that use explicitlycomputed flow features only. Models in the third set use both.\n\n#### Evaluation criteria are measure on RGB data(single or multiple frames) and flow features.",
        "The aim of this set of experiments is to compare the different variants of themodel proposed in this paper. Since it is always possible to get lowerreconstruction error by copying the inputs, we cannot use input reconstructionerror as a measure of how good a model is doing. However, we can use the errorin predicting the future as a reasonable measure of how good the model isdoing. Besides, we can use the performance on supervised tasks as a proxy forhow good the unsupervised model is doing. In this section, we present results fromthese two analyses.\n\n#### Error in predicting the future and the performance on supervised tasks are the metrics  used to compare different unsupervised models.",
        "To further get improvements for supervised tasks, we believe that the model canbe extended by applying it convolutionally across patches of the video andstacking multiple layers of such models. Applying this model in the lower layersof a convolutional net could help extract motion information that wouldotherwise be lost across max-pooling layers. In our future work, we plan tobuild models based on these autoencoders from the bottom up instead of applyingthem only to percepts.\n\n#### To extract motion information it is a good idea to apply the convolutions across patches of the video instead of whole frames.",
        "We draw inspiration of our encoder-decoder type architectures from probabilistic auto-encoders used to build generative models [24] and unsupervised learning of feature hierarchies [27]. Our main contribution is to learn an encoder-decoder stack trained in a modular and fully supervised manner for pixel-wise labelling. The addition of each deeper encoder-decoder pair results in an increased spatial context i.e., a 4 layer SegNet with 7\\times 7 kernels and 2\\times 2 non-overlapping max pooling in each layer has a spatial context of 106\\times 106 pixels when a feature-map is backtracked to the input image. The SegNet predictions get smoother as more layers are added and demonstrate high accuracy, comparable to or even exceeding methods which use CRFs [36]. SegNet maintains a constant number of features per layer which is typically set to 64. This has a practical advantage that the computational cost successively decreases for each additional/deeper encoder-decoder pair.\n\n#### The kernel size used in each layer of SegNet is 7*7.",
        "We presented SegNet, a fully trainable deep architecture for joint feature learning and mapping an input image in a feed-forward manner to its pixel-wise semantic labels. A highlight of the proposed architecture is its ability to produce smooth segment labels when compared with local patch based classifiers. This is due to deep layers of feature encoding that employ a large spatial context for pixel-wise labelling. To the best of our knowledge this is the first deep learning method to learn to map low resolution encoder feature maps to semantic labels. Both qualitative and numerical accuracy of the SegNet for outdoor and indoor scenes is very competitive, even without use of any CRF post-processing. We have also demonstrated the use of pre-trained SegNet for obtaining good performance on other datasets with a small extra computational effort. The encoder-decoder architecture of the SegNet can also be trained unsupervised and to handle missing data in the input during test time.\n\n#### SegNet performs feed-forward computation to obtain pixel-wise labelling.",
        "Semantic segmentation is an important step towards understanding and inferring different objects and their arrangements observed in a scene. This has wide array of applications ranging from estimating scene geometry, inferring support-relationships among objects to autonomous vehicle driving. Early methods that relied on low-level vision cues have fast been superseded by popular machine learning algorithms. In particular, deep learning has seen huge success lately in handwritten digit recognition, speech, categorising whole images and detecting objects in images [37, 34] also seen growing interest in semantic pixel-wise labelling problems [7, 14, 35]. However, these recent approaches have tried to directly adopt deep architectures designed for category prediction to pixel-wise labelling. The results, although very encouraging, have not been quite satisfactory. Primarily, the deepest layer representations/feature maps are of a small resolution as compared to input image dimensions due to several pooling layers e.g. if 2\\times 2 non-overlapping max-pooling-subsampling layers are used three times, the resulting feature map is 1/8^{th} of the input dimension. Therefore, an ad hoc technique is used to upsample the deepest layer feature map to match the input image dimensions by replicating features within a block i.e. all pixels within a block (8\\times 8 in our example) have the same features. This often results in predictions that appear blocky222see http://david.grangier.info/scene_parsing/. This is exactly what we improve using our proposed SegNet architecture, wherein the decoders learn to map the deepest layer features to full image dimensions. Learning to decode has two other advantages.First, deeper layers each with pooling-subsampling can be introduced which increases the spatial context for pixel labelling. This results in smooth predictions unlike patch based classifiers [36, 2]. Second, ablation studies to understand the effects of features such as in [41] can be performed using the decoder stack.\n\n#### Stacking encoders and decoders architecture produce smooth segment labels.",
        "Semantic segmentation is an important step towards understanding and inferring different objects and their arrangements observed in a scene. This has wide array of applications ranging from estimating scene geometry, inferring support-relationships among objects to autonomous vehicle driving. Early methods that relied on low-level vision cues have fast been superseded by popular machine learning algorithms. In particular, deep learning has seen huge success lately in handwritten digit recognition, speech, categorising whole images and detecting objects in images [37, 34] also seen growing interest in semantic pixel-wise labelling problems [7, 14, 35]. However, these recent approaches have tried to directly adopt deep architectures designed for category prediction to pixel-wise labelling. The results, although very encouraging, have not been quite satisfactory. Primarily, the deepest layer representations/feature maps are of a small resolution as compared to input image dimensions due to several pooling layers e.g. if 2\\times 2 non-overlapping max-pooling-subsampling layers are used three times, the resulting feature map is 1/8^{th} of the input dimension. Therefore, an ad hoc technique is used to upsample the deepest layer feature map to match the input image dimensions by replicating features within a block i.e. all pixels within a block (8\\times 8 in our example) have the same features. This often results in predictions that appear blocky222see http://david.grangier.info/scene_parsing/. This is exactly what we improve using our proposed SegNet architecture, wherein the decoders learn to map the deepest layer features to full image dimensions. Learning to decode has two other advantages.First, deeper layers each with pooling-subsampling can be introduced which increases the spatial context for pixel labelling. This results in smooth predictions unlike patch based classifiers [36, 2]. Second, ablation studies to understand the effects of features such as in [41] can be performed using the decoder stack.\n\n#### Due to the use of non-overlapping max-pooling-subsampling layers, the resulting feature map is reduced compare to the input dimension. Ad hoc technique then used to make the feature map same as input dimention by replication same pixel. This generates a blocky predictions, which is a major drawback of deep learning approaches adapting networks designed for object categorization to pixel wise labeling.",
        "Semantic pixel-wise segmentation is an ongoing topic of research, fuelled by challenging datasets [1, 33, 9]. Current best performing methods all mostly rely on hand engineered features generally used for per-pixel independent classification. Typically, a patch is fed into a classifier e.g. Random Forest [32, 2] or Boosting [36, 20] to predict the class probabilities of the center pixel. Features based on appearance [32], SfM and appearance [2, 36, 20] have been explored for the CamVid test. These per-pixel noisy predictions (often called unary terms) from the classifiers are then smoothed by using a pair-wise or higher order CRF [36, 20] to improve the accuracy. More recent approaches have aimed to produce high quality unaries by trying to predict the labels for all the pixels in a patch as opposed to only the center pixel. This improves the results of Random Forest based unaries [18] but thin structured classes are classfied poorly. Dense depth maps computed from the CamVid video have also been used as input for classification using Random Forests [43]. Another approach argues for the use of a combination of popular hand designed features and spatio temporal super-pixelization to obtain higher accuracy [39]. Recent top performing technique on the CamVid test [20] addresses the imbalance among label frequencies by using additional training data from the PASCAL VOC dataset to learn object detectors. The result of all these techniques indicates the need for improved classification as increases in accuracy have mostly come from adding new features or modalities to the classifier. Post-processing using CRF models of various orders [36] has mainly resulted in improving the accuracy of dominant classes such as sky, road, buildings with little effect on the accuracy of thin structured but equally important classes such as signs, poles, pedestrians. This highlights the need for better pixel-wise classification when imbalanced label frequencies exist.Meanwhile, indoor RGBD pixel-wise semantic segmentation has also gained popularity since the release of the NYU dataset [33] which showed the usefulness of the depth channel to improve segmentation. Their approach used features such as RGB-SIFT, depth-SIFT, location as input to a neural network classifier to predict pixel unaries. The noisy unaries are then smoothed using a CRF. Improvements were made using a richer feature set including LBP and region segmentation to obtain higher accuracy [28] followed by a CRF. In more recent work [33], both class segmentation and support relationships are inferred together using a combination of RGB and depth based cues. Another approach focusses on real-time joint reconstruction and semantic segmentation, where Random Forests are used as the classifier [13]. Gupta et al. [12] use boundary detection and hierarchical grouping before performing category segmentation. The common attribute along all these approaches is the use of hand engineered features for pixel-wise classifiction of either RGB or RGBD images. The application of deep learning for scene segmentation has only just begun. There have also been a few attempts to apply networks designed for categorization to segmentation, particularly by replicating the deepest layer features in blocks to match image dimensions [7, 6, 11, 8]. However, the resulting classification is blocky [11]. Another approach using recurrent neural networks [26] merges several low resolution predictions to create input image resolution predictions. On the whole, although some of these techniques already present improvements over hand engineered features [7].\n\n#### Since a patch is fed into a classifier to predict the class probabilities of the center pixel, it is evident that image classification models for semantic segmentation.",
        "We draw inspiration of our encoder-decoder type architectures from probabilistic auto-encoders used to build generative models [24] and unsupervised learning of feature hierarchies [27]. Our main contribution is to learn an encoder-decoder stack trained in a modular and fully supervised manner for pixel-wise labelling. The addition of each deeper encoder-decoder pair results in an increased spatial context i.e., a 4 layer SegNet with 7\\times 7 kernels and 2\\times 2 non-overlapping max pooling in each layer has a spatial context of 106\\times 106 pixels when a feature-map is backtracked to the input image. The SegNet predictions get smoother as more layers are added and demonstrate high accuracy, comparable to or even exceeding methods which use CRFs [36]. SegNet maintains a constant number of features per layer which is typically set to 64. This has a practical advantage that the computational cost successively decreases for each additional/deeper encoder-decoder pair.\n\n#### SegNet architecture is inspired from generative models and unsupervised learning.",
        "We draw inspiration of our encoder-decoder type architectures from probabilistic auto-encoders used to build generative models [24] and unsupervised learning of feature hierarchies [27]. Our main contribution is to learn an encoder-decoder stack trained in a modular and fully supervised manner for pixel-wise labelling. The addition of each deeper encoder-decoder pair results in an increased spatial context i.e., a 4 layer SegNet with 7\\times 7 kernels and 2\\times 2 non-overlapping max pooling in each layer has a spatial context of 106\\times 106 pixels when a feature-map is backtracked to the input image. The SegNet predictions get smoother as more layers are added and demonstrate high accuracy, comparable to or even exceeding methods which use CRFs [36]. SegNet maintains a constant number of features per layer which is typically set to 64. This has a practical advantage that the computational cost successively decreases for each additional/deeper encoder-decoder pair.\n\n#### 4 encoders and 4 decoders are used in SegNet.",
        "We draw inspiration of our encoder-decoder type architectures from probabilistic auto-encoders used to build generative models [24] and unsupervised learning of feature hierarchies [27]. Our main contribution is to learn an encoder-decoder stack trained in a modular and fully supervised manner for pixel-wise labelling. The addition of each deeper encoder-decoder pair results in an increased spatial context i.e., a 4 layer SegNet with 7\\times 7 kernels and 2\\times 2 non-overlapping max pooling in each layer has a spatial context of 106\\times 106 pixels when a feature-map is backtracked to the input image. The SegNet predictions get smoother as more layers are added and demonstrate high accuracy, comparable to or even exceeding methods which use CRFs [36]. SegNet maintains a constant number of features per layer which is typically set to 64. This has a practical advantage that the computational cost successively decreases for each additional/deeper encoder-decoder pair.\n\n#### 64 features are used in each layer of SegNet.",
        "SegNet uses a “flat” architecture, i.e, the number of features in each layer remains the same (64 in our case) but with full connectivity. This choice is motivated by two reasons. First, it avoids parameter explosion, unlike an expanding deep encoder network with full feature connectivity (same for decoder). Second, the training time remains the same (in our experiments it slightly decreases) for each additional/deeper encoder-decoder pair as the feature map resolution is smaller which makes convolutions faster. Note that the decoder corresponding to the first encoder (closest to the input image) produces a multi-channel feature map although the encoder input is either 3 or 4 channels (RGB or RGBD) (see Fig. 1). This high dimensional feature representation is fed to the soft-max classifier. This is unlike the other decoders which produce feature maps the same size as their encoder inputs. A fixed pooling window of 2\\times 2 with a stride of non-overlapping 2 pixels is used. This small size preserves thin structures in the scene. Further, a constant kernel size of 7\\times 7 over all the layers was chosen to provide a wide context for smooth labelling i.e. a pixel in the deepest layer feature map can be traced back to a context window in the input image of 106\\times 106 pixels. The trade-off here is between the size of the context window and retaining thin structures. Smaller kernels decrease context and larger ones potentially destroy thin structures.\n\n#### The flat architecture avoids parameter explosion, unlike an expanding deep encoder network with full feature connectivity (same for decoder) and the training time remains almost same for each additional/deeper encoder-decoder pair.",
        "The input to the SegNet can be any arbitrary multi-channel image or feature map(s), e.g., RGB, RGBD, map of normals, depth etc. We perform local contrast normalization (LCN) as a pre-processing step to the input [23, 15]. The advantage of this step are many, (i) to correct for non-uniform scene illumination thus reducing the dynamic range (increases contrast in shadowed parts). (ii) highlighting edges which leads the network to learn category shape, (iii) improves convergence as it decorrelates the input dimensions [23]. LCN is performed independently for each modality, i.e., RGB is contrast normalized as a three channel input and depth as a single channel for RGBD inputs. This avoids highlighting pseudo depth edges due to RGB edges and vice-versa.\n\n#### Local Contrast Normalization (LCN) is a pre-processing step that normalize the input to a non-uniform scene illumination, highlight edges, and decorrelates the input dimensions. This normalization performed on each channel of an input image. It improves convergence and helps to learn category shape.",
        "In 2014 teams were allowed to use outside data for training their models in the competition, so there were six tracks: provided and outside data tracks in each of image classification, single-object localization, and object detection tasks.\n\n#### Yes, test images are released to the public after the competition is finished in 2014.\n\ncomposition:False",
        "Image collection for ILSVRC classification task is the same as the strategy employed for constructingImageNet (Deng et al.,, 2009). Training images are taken directly from ImageNet. Additionalimages are collected for the ILSVRC using this strategy and randomly partitioned into the validation and test sets.\n\n#### Training images are taken directly from ImageNet. Additional images are collected for the ILSVRC using this strategy and randomly partitioned into the validation and test sets.",
        "This paper has three key goals:1.To discuss the challenges of creating this large-scale object recognition benchmark dataset,2.To highlightthe developments in object classification and detection that have resulted from this effort, and3.To take a closer look at the current state of the fieldof categorical object recognition.The paper may be of interest to researchers working on creating large-scale datasets, as well as to anybody interested in better understanding the history and the current state of large-scale object recognition.\n\n#### Yes, the challenge include discussion on challenges of creating this large-scale object recognition benchmark dataset.",
        "The key lesson of collecting the datasets and running the challenges for five years is this: All human intelligence tasks need to be exceptionally well-designed. We learned this lesson both when annotating the dataset using Amazon Mechanical Turk workers (Section 3) and evenwhen trying to evaluate human-level image classification accuracy using expert labelers (Section 6.4). The first iteration of the labeling interface was always bad – generally meaning completely unusable. If there was any inherent ambiguity in the questions posed (and there almost always was), workers found it and accuracy suffered. If there is one piece of advice we can offer to future research, it is to very carefully design, continuously monitor, and extensively sanity-check all crowdsourcing tasks.\n\n#### The challenge has been running for past 5 years.",
        "There are several datasets with standardized online evaluationsimilar to ILSVRC: the aforementioned PASCAL VOC (Everingham et al.,, 2012), Labeled Faces in the Wild (Huang et al.,, 2007) for unconstrained face recognition,Reconstruction meets Recognition (Urtasun et al.,, 2014) for 3D reconstruction and KITTI (Geiger et al.,, 2013) for computer vision in autonomous driving. These datasets along with ILSVRC help benchmark progress in different areas of computer vision.Works such as (Torralba and Efros,, 2011) emphasize the importance of examining the bias inherent in any standardized dataset.\n\n#### It emphasizes the importance of examining the bias inherent in any standardized dataset.",
        "Recall that for the image classification task every image was annotated with one object class label, corresponding toone object that is present in an image. For the single-object localization task, every validation and test image and a subset of the training imagesare annotated with axis-aligned bounding boxes around every instance of this object.\n\n#### For the image classification task every image was annotated with one object class label, corresponding toone object that is present in an image. For the single-object localization task, every validation and test image and a subset of the training images were annotated  with axis-aligned bounding boxes around every instance of this object.",
        "Using the image collection and annotation procedure described in previous sections, we collected a large-scale datasetused for ILSVRC classification task. There are 1000 object classes and approximately 1.2 million training images, 50 thousand validation images and 100 thousand test images. Table 2 (top) documents the size of the dataset over the years of the challenge.\n\n#### ILSVRC dataset has 1.2 million training images, 50 thousand validation images and 100 thousand test images.",
        "Using the image collection and annotation procedure described in previous sections, we collected a large-scale datasetused for ILSVRC classification task. There are 1000 object classes and approximately 1.2 million training images, 50 thousand validation images and 100 thousand test images. Table 2 (top) documents the size of the dataset over the years of the challenge.\n\n#### It's divided into 1000 classes.",
        "The ILSVRC dataset and the competition has allowed significant algorithmic advances in large-scale image recognition and retrieval.\n\n#### Images from the ILSVRC2012 single-object localization validation set are compared to images from the PASCAL VOC benchmark for object recognition. They have also analyzed the level of difficulty of object localization in these images compared to those of objects from the PASCAL VOC benchmark. The level of difficulty of object localization is also analyzed.",
        "This paper has three key goals:1.To discuss the challenges of creating this large-scale object recognition benchmark dataset,2.To highlightthe developments in object classification and detection that have resulted from this effort, and3.To take a closer look at the current state of the fieldof categorical object recognition.The paper may be of interest to researchers working on creating large-scale datasets, as well as to anybody interested in better understanding the history and the current state of large-scale object recognition.\n\n#### This paper has three primary goals: 1.To address the difficulty of producing this large-scale object identification benchmark dataset, 2.To highlightthe improvements in object categorization and detection that have emerged from this work, and3.To take a deeper look at the present status of the fieldof categorical object identification.",
        "First, YOLO is extremely fast. Since we frame detection as a regression problem we don’t need a complex pipeline. We simply run our neural network on a new image at test time to predict detections. Our base network runs at 45 frames per second with no batch processing on a Titan X GPU and a fast version runs at more than 150 fps. This means we can process streaming video in real-time with less than 25 milliseconds of latency. Furthermore, YOLO achieves more than twice the mean average precision of other real-time systems. For a demo of our system running in real-time on a webcam please see our project webpage: http://pjreddie.com/yolo/.\n\n#### The baseline YOLO model shows 63.4% mAP at 45fps on the Pascal VOC dataset, while Fast YOLO is on 52.7 mAP at 150fps. Still, they are more than twice more accurate compared to other real-time detectors. However, the YOLO network was observed to struggle with small objects but is generalizable well to other domains.",
        "First we compare YOLO with other real-time detection systems on Pascal VOC 2007. To understand the differences between YOLO and R-CNN variants we explore the errors on VOC 2007 made by YOLO and Fast R-CNN, one of the highest performing versions of R-CNN [14]. Based on the different error profiles we show that YOLO can be used to rescore Fast R-CNN detections and reduce the errors from background false positives, giving a significant performance boost. We also present VOC 2012 results and compare mAP to current state-of-the-art methods. Finally, we show that YOLO generalizes to new domains better than other detectors on two artwork datasets.\n\n#### Different approaches to evaluating object detection models are presented in the paper where they mostly use mean average precision (mAP) and frames per second (fps) for accuracy and speed respectively. Qualitatively, the YOLO's errors are compared to R-CNN, and mAP on different classes of objects is shown. Moreover, YOLO was shown to boost the performance of R-CNN, and better generalize for new domains.",
        "YOLO is refreshingly simple: see Figure 1. A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes. YOLO trains on full images and directly optimizes detection performance. This unified model has several benefits over traditional methods of object detection.\n\n#### Since YOLO is trained on full images and end-to-end it can encode contextual information about each class and its appearance. Moreover, it can learn shapes, sizes, and the relationship between objects. Thus it was shown to be generalizable to artwork, although pixel-wise they are different from natural images, and it makes twice as less mistakes with background objects compared to R-CNN.",
        "Humans glance at an image and instantly know what objects are in the image, where they are, and how they interact. The human visual system is fast and accurate, allowing us to perform complex tasks like driving with little conscious thought. Fast, accurate algorithms for object detection would allow computers to drive cars without specialized sensors, enable assistive devices to convey real-time scene information to human users, and unlock the potential for general purpose, responsive robotic systems.\n\n#### Theoretically, if the detection algorithms were as fast and accurate as the human visual system, they could drive an autonomous car, but no further discussion is included in the paper. At the time of the writing of the paper, even YOLO was still inferior to other detectors in terms of accuracy. Thus, it is difficult to answer the question precisely.",
        "Current detection systems repurpose classifiers to perform detection. To detect an object, these systems take a classifier for that object and evaluate it at various locations and scales in a test image. Systems like deformable parts models (DPM) use a sliding window approach where the classifier is run at evenly spaced locations over the entire image [10].\n\n#### Reframing object detection as a simple regression problem means predicting bounding boxes and class probabilities directly from image pixels avoiding complex pipelines and steps which most of the existing (classifier-based) methods do. YOLO can be trained end-to-end and can predict bounding boxes and respective class probabilities directly from an entire image. Also, its loss function directly corresponds to detection performance, which makes optimizing it more intuitive and easier.",
        "First we compare YOLO with other real-time detection systems on Pascal VOC 2007. To understand the differences between YOLO and R-CNN variants we explore the errors on VOC 2007 made by YOLO and Fast R-CNN, one of the highest performing versions of R-CNN [14]. Based on the different error profiles we show that YOLO can be used to rescore Fast R-CNN detections and reduce the errors from background false positives, giving a significant performance boost. We also present VOC 2012 results and compare mAP to current state-of-the-art methods. Finally, we show that YOLO generalizes to new domains better than other detectors on two artwork datasets.\n\n#### YOLO is 3 times less likely to make background mistakes compared to Fast R-CNN (it has 13.6% false positives) as it can reason about the entire image and see the larger context. On top of that, combining YOLO and Fast R-CNN can give a 2.3% improvement in terms of accuracy.",
        "YOLO imposes strong spatial constraints on bounding box predictions since each grid cell only predicts two boxes and can only have one class. This spatial constraint limits the number of nearby objects that our model can predict. Our model struggles with small objects that appear in groups, such as flocks of birds.\n\n#### The paper discusses both advantages and disadvantages of looking at the image as a whole. Processing the entire image, let YOLO be end-to-end, thus predicting bounding boxes and class probabilities directly. Also, it shows good generalizability to other domains and it copes with background objects much better compared to Fast R-CNN due to looking at the image as a whole. However, to make the entire image consumable to the model, dividing the image into grids and limiting the number of bounding boxes are performed. Because of these and other design decisions, YOLO shows inferior accuracy compared to state-of-the-art detectors. Especially it struggles with localizing objects, small objects, and objects close to each other.",
        "First we compare YOLO with other real-time detection systems on Pascal VOC 2007. To understand the differences between YOLO and R-CNN variants we explore the errors on VOC 2007 made by YOLO and Fast R-CNN, one of the highest performing versions of R-CNN [14]. Based on the different error profiles we show that YOLO can be used to rescore Fast R-CNN detections and reduce the errors from background false positives, giving a significant performance boost. We also present VOC 2012 results and compare mAP to current state-of-the-art methods. Finally, we show that YOLO generalizes to new domains better than other detectors on two artwork datasets.\n\n#### The generalizability of YOLO to unseen data is evaluated by training it on natural images and testing with artwork from Picasso and People-Art datasets. Since YOLO can reason about the entire image and learn the contextual information about the class and its appearance, it shows much better generalizability compared to other state-of-the-art techniques. Generalizability to other domains besides artwork is not mentioned in the paper.",
        "First, YOLO is extremely fast. Since we frame detection as a regression problem we don’t need a complex pipeline. We simply run our neural network on a new image at test time to predict detections. Our base network runs at 45 frames per second with no batch processing on a Titan X GPU and a fast version runs at more than 150 fps. This means we can process streaming video in real-time with less than 25 milliseconds of latency. Furthermore, YOLO achieves more than twice the mean average precision of other real-time systems. For a demo of our system running in real-time on a webcam please see our project webpage: http://pjreddie.com/yolo/.\n\n#### When the basic YOLO model reaches 63.4% mAP on the Pascal dataset, it can run at 45 fps. On the other hand, Fast YOLO can show 53.7% mAP but run at more than 150 fps.",
        "The recent Faster R-CNN replaces selective search with a neural network to propose bounding boxes, similar to Szegedy et al. [8] In our tests, their most accurate model achieves 7 fps while a smaller, less accurate one runs at 18 fps. The VGG-16 version of Faster R-CNN is 10 mAP higher but is also 6 times slower than YOLO. The Zeiler-Fergus Faster R-CNN is only 2.5 times slower than YOLO but is also less accurate.\n\n#### Table 1 reveals that the actual speed of Faster R-CNN with VGG-16 is 7fps with 73.2% mAP. At the same time, YOLO has more than 6 times the higher speed of 45 fps with 63.4% mAP on Pascal VOC 2007.",
        "First we compare YOLO with other real-time detection systems on Pascal VOC 2007. To understand the differences between YOLO and R-CNN variants we explore the errors on VOC 2007 made by YOLO and Fast R-CNN, one of the highest performing versions of R-CNN [14]. Based on the different error profiles we show that YOLO can be used to rescore Fast R-CNN detections and reduce the errors from background false positives, giving a significant performance boost. We also present VOC 2012 results and compare mAP to current state-of-the-art methods. Finally, we show that YOLO generalizes to new domains better than other detectors on two artwork datasets.\n\n#### Although the paper does not give explicit reasons why Pascal VOC 2007 dataset was chosen for comparison, we can make an educated guess. It seems like Pascal VOC 2007 is one of the popular datasets for object detection. Also, many other existing methods had been evaluated on it, including Fast R-CNN models (the detections are also publicly available for Fast R-CNN). Additionally, the paper uses VOC 2012 and some other datasets for comparison too.",
        "•Correct: correct class and \\textrm{IOU}>.5•Localization: correct class, .1<\\textrm{IOU}<.5•Similar: class is similar, \\textrm{IOU}>.1•Other: class is wrong, \\textrm{IOU}>.1•Background: \\textrm{IOU}<.1 for any object\n\n#### The paper does not include explicit discussion regarding using the IOU metric or Dice coefficient, so it is difficult to answer the question just by the information in the paper. In general, the IOU method is used for object detection, while the Dice coefficient is used for image segmentation.",
        "First we compare YOLO with other real-time detection systems on Pascal VOC 2007. To understand the differences between YOLO and R-CNN variants we explore the errors on VOC 2007 made by YOLO and Fast R-CNN, one of the highest performing versions of R-CNN [14]. Based on the different error profiles we show that YOLO can be used to rescore Fast R-CNN detections and reduce the errors from background false positives, giving a significant performance boost. We also present VOC 2012 results and compare mAP to current state-of-the-art methods. Finally, we show that YOLO generalizes to new domains better than other detectors on two artwork datasets.\n\n#### Due to YOLO's architecture, it can handle the background objects better as it has a larger context (it processes the entire image end-to-end) when predicting bounding boxes compared to other models. However, YOLO struggles with localizing objects, especially small ones. On the other hand, Fast R-CNN can localize objects much better, but it has 3 times more problems (13.6%) with background errors compared to YOLO's 4.75%. Thus, assisting the best Fast R-CNN model with YOLO can give a 3.2% boost of accuracy (71.8% to 75%), because it can handle the background objects better.",
        "YOLO imposes strong spatial constraints on bounding box predictions since each grid cell only predicts two boxes and can only have one class. This spatial constraint limits the number of nearby objects that our model can predict. Our model struggles with small objects that appear in groups, such as flocks of birds.\n\n#### Although YOLO is a really fast model, it usually struggles with localizing small objects in a group or objects near each other. In fact, localization errors take up more than half of all YOLO's errors. It happens because YOLO has only a limited number of bounding boxes per grid cell and the loss function penalizes the errors in the large and small bounding boxes the same. On top of that, the model uses coarse features to predict bounding boxes, and it may have problems with unusual aspect ratios and configurations of objects.",
        "We also train YOLO using VGG-16. This model is more accurate but also significantly slower than YOLO. It is useful for comparison to other detection systems that rely on VGG-16 but since it is slower than real-time the rest of the paper focuses on our faster models.\n\n#### In fact, the base YOLO model and Fast YOLO have used GoogLeNet-inspired architecture to VGG-16. The authors claim that they have trained it with VGG-16 and it had better accuracy, however, it was too slow to be real-time. The YOLO model is first pretrained on the ImageNet 1000-class competition dataset and later trained on training and validation data of the Pascal VOC 2007 dataset.",
        "Second, YOLO reasons globally about the image when making predictions. Unlike sliding window and region proposal-based techniques, YOLO sees the entire image during training and test time so it implicitly encodes contextual information about classes as well as their appearance. Fast R-CNN, a top detection method [14], mistakes background patches in an image for objects because it can’t see the larger context. YOLO makes less than half the number of background errors compared to Fast R-CNN.\n\n#### The paper does not specifically discuss why YOLO is better for cat and train categories in VOC 2012 dataset and worse for the bottle, sheep, and tv/monitor. Thus, it is difficult to answer this question with only the contents of the paper.",
        "Vector of Locally Aggregated Descriptors (VLAD) [29]is a popular descriptor pooling method for both instance level retrieval [29] and image classification [22].It captures information about the statisticsof local descriptors aggregated over the image. Whereas bag-of-visual-words [14, 74] aggregation keeps countsof visual words, VLAD stores the sum of residuals (difference vector betweenthe descriptor and its corresponding cluster centre) for each visual word.\n\n#### “Vector of Locally Aggregated Descriptors” image representation is a compact representation of an image created by the VLAD technique which is a popular descriptor pooling method that can extract statistical information of the local descriptors aggregated over the image. IT calculates the difference between the feature vectors of an image and a set of learned reference vectors, then summing up these differences to create the image representation vector.",
        "Furthermore we compare our CNN representations trained for place recognitionagainst the state-of-the-art local feature based compact descriptor, which consists ofVLAD pooling [29] with intra-normalization [3]on top of densely extracted RootSIFTs [43, 2].The descriptor is optionally reduced to 4096 dimensions usingPCA (learnt on the training set) combined with whitening and L2-normalization [25];this setup together with view synthesis yields the state-of-the-art results on the challenging Tokyo 24/7 dataset(c.f. [80]).\n\n#### Maybe authors found that PCA is  computationally less expensive and much memory and time saving in experiments than other methods. PCA is used to reduce the dimensions of the descriptor to 4096 learnt on the training set, which is discovered experimentally to help in achieving state-of-the-art results on the challenging Tokyo 24/7 dataset as comparisons show that the lower dimensional fVLAD performs similarly to the full size vector.",
        "contains 250kdatabase images downloaded from Google Street Viewand 24k test queries generated from Street View but taken at differenttimes, years apart.We divide this dataset into three roughly equal partsfor training, validation and testing,each containing around 83kdatabase images and 8k queries,where the division was done geographically to ensure the sets containindependent images.To facilitate faster training, for some experiments,a smaller subset (Pitts30k) is used, containing 10k database imagesin each of the train/val(idation)/test sets, which arealso geographically disjoint.\n\n#### They used Weak Supervision as a solution for the lack of labelled data. They gather a large dataset of multiple panoramic images depicting the same place from different viewpoints over time from the Google Street View Time Machine which is of weak supervision. They depended on Pitts250k which contains 250k database images downloaded from Google Street View and 24k test queries generated from Street View but taken at different times, years apart.\nAlso Using Tokyo 24/7 that contains 76k database images and 315 query images taken using mobile phone cameras. TokyoTM; Tokyo 24/7 (=test) and TokyoTM train/val are all geographically disjoint (Paper didn't mention the total number of images explicitly, it's some kind vague).",
        "While there have been many improvements in designing betterimage retrieval [2, 3, 12, 11, 17, 26, 27, 29, 25, 32, 48, 51, 52, 53, 54, 71, 78, 79, 82] and place recognition [4, 10, 15, 16, 24, 9, 35, 46, 44, 64, 65, 63, 75, 81, 80] systems, not many works have performedlearning for these tasks.All relevant learning-based approaches fall into one or both of the followingtwo categories:(i) learning for an auxiliary task (e.g. some form of distinctiveness of local features [4, 15, 30, 35, 58, 59, 90]), and (ii) learning on top of shallow hand-engineered descriptors that cannot be fine-tuned for the target task [2, 24, 9, 35, 57]. Both of these are in spirit opposite to the core idea behinddeep learning that has provided a major boost in performance in variousrecognition tasks: end-to-end learning. We will indeed show insection 5.2 that training representations directly for the end-task,place recognition, is crucial for obtaining good performance.\n\n#### Authors see that both approaches are\nend-to-end learning. Their approach -NetVLAD, shows that training representations directly for the end-task, place recognition, is crucial for obtaining good performance. Representations trained on the end-task of place recognition consistently outperform by a large margin off-the- shelf CNNs on benchmarks illustrating there approach can learn rich yet compact image representations for place recognition and that the popular idea of using pretrained networks “off-the-shelf” is sub-optimal as the networks trained for object or scene classification are not necessary suitable for the end-task of place recognition.",
        "We use our best performing network (VGG-16, f_{VLAD} with whitening down to 256-D)trained completely on Pittsburgh, to extract image representationsfor standard object and image retrieval benchmarks.Our representation sets the state-of-the-art for compact image representations (256-D)by a large margin on all three datasets, obtaining an mAP of63.5%, 73.5% and 79.9% onOxford 5k [53], Paris 6k [54], Holidays [26], respectively;for example, this is a +20% relative improvement on Oxford 5k.Appendix Ccontains more detailed results.\n\n#### Their architecture managed to improve over current state-of-the-art compact image representations on standard image retrieval benchmarks by large margin on available datasets, obtaining an mAP of 63.5%, 73.5% and 79.9% on Oxford 5k, Paris 6k, Holidays, respectively; which is a +20% relative improvement on Oxford 5k. Their proposed representations learnt end-to-end, outperformed the pretrained image representations and off-the-shelf CNN descriptors.",
        "Formally, given N D-dimensional local image descriptors \\{\\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf x$}}{\\mbox{\\boldmath$\\textstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf x$}}_{i}\\} as input,and K cluster centres (“visual words”) \\{\\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf c$}}{\\mbox{\\boldmath$\\textstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf c$}}_{k}\\} as VLAD parameters,the output VLAD image representation V is K\\times D-dimensional.For convenience we will write V as a K\\times D matrix, but this matrixis converted into a vector and, after normalization, used asthe image representation. The (j,k) element of V is computedas follows:V(j,k)=\\sum_{i=1}^{N}a_{k}(\\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf x$}}{\\mbox{\\boldmath$\\textstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf x$}}_{i})\\left(x_{i}(j)-c_{k}(j)\\right),(1)where x_{i}(j) and c_{k}(j) are the j-th dimensions of the i-th descriptor and k-th cluster centre, respectively.a_{k}(\\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf x$}}{\\mbox{\\boldmath$\\textstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf x$}}_{i}) denotes the membership ofthe descriptor \\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf x$}}{\\mbox{\\boldmath$\\textstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf x$}}_{i} to k-th visual word, i.e. it is 1 if cluster \\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf c$}}{\\mbox{\\boldmath$\\textstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf c$}}_{k}is the closest cluster to descriptor \\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf x$}}{\\mbox{\\boldmath$\\textstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf x$}}_{i} and 0 otherwise.Intuitively, each D-dimensional column k of V records the sum ofresiduals (\\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf x$}}{\\mbox{\\boldmath$\\textstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptstyle\\bf x$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf x$}}_{i}-\\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf c$}}{\\mbox{\\boldmath$\\textstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf c$}}_{k}) of descriptors which are assigned to cluster \\mathchoice{\\mbox{\\boldmath$\\displaystyle\\bf c$}}{\\mbox{\\boldmath$\\textstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptstyle\\bf c$}}{\\mbox{\\boldmath$\\scriptscriptstyle\\bf c$}}_{k}.The matrix V is then L2-normalized column-wise(intra-normalization [3]),converted into a vector,and finally L2-normalized in its entirety [29].\n\n#### L2-norm for each column of the representation matrix, converted into a vector, and finally L2-normalized over the new vector.",
        "In order to profit from years of wisdom produced in image retrieval,we propose to mimic VLAD in a CNN frameworkand design a trainable generalized VLAD layer, NetVLAD. The result is a powerful image representationtrainable end-to-end on the target task (in our case place recognition).To construct a layer amenable to training via backpropagation,it is required that the layer’s operation is differentiable withrespect to all its parameters and the input.Hence, the key challenge is to make the VLAD pooling differentiable, which we describe next.\n\n#### The original VLAD method uses hand-crafted features and applies the VLAD technique to them by concatenating multiple VLADs. On the other hand, NetVLAD layer uses a CNN to extract features and applies the VLAD technique in a single layer by learning the aggregation weights of the residuals (xi − ck) in different parts of the descriptor space. The NetVLAD layer has three independent sets of parameters, {wk}, {bk} and {ck}, that enables greater flexibility and adaptability to the CNN features than the original VLAD method which uses only {ck}.",
        "We have designed a new convolutional neural network architecture thatis trained for place recognition in an end-to-end manner from weaklysupervised Street View Time Machine data. Our trained representationsignificantly outperforms off-the-shelf CNN models and significantlyimproves over the state-of-the-art on the challenging 24/7 Tokyodataset, as well as on the Oxford and Paris image retrieval benchmarks.The two main components of our architecture– (i) the NetVLAD pooling layer and (ii) weakly supervised rankingloss – are generic CNN building blocks applicable beyond the placerecognition task. The NetVLAD layer offers a powerful poolingmechanism with learnable parameters that can be easily plugged intoany other CNN architecture. The weakly supervised ranking lossopens up the possibility of end-to-end learning for other rankingtasks where large amounts of weakly labelled data are available, forexample, images described with natural language [33].\n\n#### Yes, it is a generic building block and can be inserted into any other CNN architectures.",
        "contains 250kdatabase images downloaded from Google Street Viewand 24k test queries generated from Street View but taken at differenttimes, years apart.We divide this dataset into three roughly equal partsfor training, validation and testing,each containing around 83kdatabase images and 8k queries,where the division was done geographically to ensure the sets containindependent images.To facilitate faster training, for some experiments,a smaller subset (Pitts30k) is used, containing 10k database imagesin each of the train/val(idation)/test sets, which arealso geographically disjoint.\n\n#### They use the entire (Pitts30k) dataset and divide it into three equal parts for training, validation and testing, each containing around 83k database images and 8k queries which are geographically disjoint. However, for some experiments for the seek of facility and faster training, a smaller subset (Pitts30k) is used, containing 10k database images in each of the train/val/test sets, and also geographically disjoint.",
        "We propose to exploit a new source of data – Google Street View Time Machine –which provides multiple street-level panoramic images taken at different times at close-by spatial locations on the map.As will be seen in section 5.2,this novel data source is precious for learning an image representation for place recognition.As shown in figure 4, the same locations are depictedat different times and seasons, providing the learning algorithm with crucialinformation it can use to discover which features are useful or distracting,and what changes should the image representation be invariant to, in order to achievegood place recognition performance.\n\n#### As authors have considered : Google Street View Time Machine was a novel source (at that time) for learning an image representation for place recognition .",
        "By comparing f_{VLAD} (-o-) methods with their corresponding f_{max} (-x-) counterpartsit is clear that VLAD pooling is much better than Max pooling for both off-the-shelf and trained representations.NetVLAD performance decreases gracefullywith dimensionality: 128-D NetVLAD performs similarly to 512-D Max(42.9% vs 38.4% recall@1 on Tokyo 24/7),resulting in four timesmore compact representation for the same performance.Furthermore, NetVLAD+whitening outperforms Max pooling convincingly whenreduced to the same dimensionality (60%).See appendix C for more details.\n\n#### They use in comparison the recall@1 on Tokyo 24/7",
        "We use our best performing network (VGG-16, f_{VLAD} with whitening down to 256-D)trained completely on Pittsburgh, to extract image representationsfor standard object and image retrieval benchmarks.Our representation sets the state-of-the-art for compact image representations (256-D)by a large margin on all three datasets, obtaining an mAP of63.5%, 73.5% and 79.9% onOxford 5k [53], Paris 6k [54], Holidays [26], respectively;for example, this is a +20% relative improvement on Oxford 5k.Appendix Ccontains more detailed results.\n\n#### Authors reported of using mAP to compare their approach with image retrieval benchmark. Mean average precision is used in information retrieval and computer vision tasks to evaluate the performance of a model through its ability to retrieve relevant images from a dataset.",
        "In the following we discuss figure 5,which compares place recognition performance of our method to the baselines outlined aboveon the Pittsburgh and Tokyo 24/7 benchmarks.\n\n#### Pittsburgh(Pitts250k) and Tokyo 24/7 benchmarks",
        "In order to learn the representation end-to-end, we designa CNN architecture that mimics this standard retrieval pipeline in an unifiedand principled manner with differentiable modules.For step (i), we crop the CNNat the last convolutional layer and view itas a dense descriptor extractor.This has been observed to work well for instance retrieval[6, 7, 62] and texture recognition [13].Namely, the output of the last convolutional layer is aH\\times W\\times D map which can be considered as a set of D-dimensionaldescriptors extracted at H\\times W spatial locations.For step (ii) we design a new pooling layer inspired by the Vector of Locally Aggregated Descriptors (VLAD) [29]that pools extracted descriptors into a fixed image representation and its parameters are learnable via back-propagation.We call this new pooling layer “NetVLAD” layer and describe it in the next section.\n\n#### Authors mentioned that they have cropped the CNN at the last convolutional layer and view it as a dense descriptor extractor as they found it work well in experiments i.e.,instance retrieval and texture recognition. However, this point doesn't have enough discussion in the paper but generally speaking, cropping at the end, this way, may obtain good levels of abstraction and compact vector representations as going deeper and deeper, while cropping at middle may not extract the desired features and also, may not be  dense enough to complete this task with good performance.",
        "Both of our new networks are sensitive to shape orientation, i.e., they capture different information at different orientations. To capture a more holistic sense of a 3D object, we add an orientation pooling stage that aggregates information from different orientations.\n\n#### Multi-orientation pooling is a learning strategy in which the rotations around vertical axis are combined with the elevation rotations, although I am not sure what are elevation rotations.",
        "As shown in Fig 2, even with similar level of object detail, the volumetric CNN (green) is 4.8\\% worse than the multi-view CNN (blue). That is, there is still significant room to improve the architecture of volumetric CNNs. This discovery motivates our efforts in Sec 4 to improve volumetric CNNs. Additionally, low-frequency information in 3D seems to be quite discriminative for object classification—it is possible to achieve 89.5\\% accuracy (blue) at a resolution of only 30\\times 30\\times 30. This discovery motivates our efforts in Sec 5 to improve multi-view CNNs with a 3D multi-resolution approach.\n\n#### The reasoning is that low-frequency information in 3D seems to be quite discriminative, because the authors use the resolution of only 30x30x30, which is really low resolution in any case. The only explanation of why the method is still working is that low-frequency information is discriminative.",
        "We propose two network variations that significantly improve state-of-the-art CNNs on 3D volumetric data.The first network is designed to mitigate overfitting by introducing auxiliary training tasks, which are themselves challenging. These auxiliary tasks encourage the network to predict object class labels from partial subvolumes. Therefore, no additional annotation efforts are needed. The second network is designed to mimic multi-view CNNs, as they are strong in 3D shape classification. Instead of using rendering routines from computer graphics, our network projects a 3D shape to 2D by convolving its 3D volume with an anisotropic probing kernel. This kernel is capable of encoding long-range interactions between points. An image CNN is then appended to classify the 2D projection. Note that the training of the projection module and the image classification module is end-to-end. This emulation of multi-view CNNs achieves similar performance to them, using only standard layers in CNN.\n\n#### The auxiliary tasks are closely related to the main tasks but are difficult to overfit to keep the learning from early convergence even when the main task is overfitted. The property of the auxiliary tasks is that they are supposed to be challenging by using only only partial subvolumes for the predictions. The auxiliary tasks better exploit the discrimnative power of local regions because they do not use additional knowledge about the semantics of the object.",
        "We propose two network variations that significantly improve state-of-the-art CNNs on 3D volumetric data.The first network is designed to mitigate overfitting by introducing auxiliary training tasks, which are themselves challenging. These auxiliary tasks encourage the network to predict object class labels from partial subvolumes. Therefore, no additional annotation efforts are needed. The second network is designed to mimic multi-view CNNs, as they are strong in 3D shape classification. Instead of using rendering routines from computer graphics, our network projects a 3D shape to 2D by convolving its 3D volume with an anisotropic probing kernel. This kernel is capable of encoding long-range interactions between points. An image CNN is then appended to classify the 2D projection. Note that the training of the projection module and the image classification module is end-to-end. This emulation of multi-view CNNs achieves similar performance to them, using only standard layers in CNN.\n\n#### The anisotropic probing kernel is designed specifically to be able to capture long-range interactions between 3D points of the objects. In particular, the kernel is elongated and captures only voxels of the same height and along the probing direction.",
        "These auxiliary training tasks also predict the same object labels, but the predictions are made solely on a local subvolume of the input.Without complete knowledge of the object, the auxiliary tasks are more challenging, and can thus better exploit the discriminative power of local regions. This design is different from the classic multi-task learning setting of hetergenous auxiliary tasks, which inevitably requires collecting additional annotations (e.g., conducting both object classification and detection [9]).\n\n#### The purpose of the auxiliary tasks is twofold:\n1. To serve as a regularization mechanism (make learning more challening in order to prevent overfitting and early convergence).\n2. Exploit better discriminative power of local regions, which should improve learning and not negatively impact it.",
        "Both of our new networks are sensitive to shape orientation, i.e., they capture different information at different orientations. To capture a more holistic sense of a 3D object, we add an orientation pooling stage that aggregates information from different orientations.\n\n#### It is true that the probing mechanism has a relationship with the Radon transform, which is an integral transform whose inverse is used to reconstruct images from medical CT scans and other complex 3D structures such as a map of a planet's polar regions (https://mathworld.wolfram.com/RadonTransform.html#:~:text=The%20Radon%20transform%20is%20an,(Roulston%20and%20Muhleman%201997).). Additionally, orientation pooling aggragates information from different orientations, thus carrying only partial information about the object, which makes it robust to different objects and avoids overfitting to the objects from the training dataset.",
        "Although the multi-view CNN presented by [32] produces compelling results, we are able to improve its performance through a multi-resolution extension with improved data augmentation.We introduce multi-resolution 3D filtering to capture information at multiple scales. We perform sphere rendering (see Sec 3) at different volume resolutions. Note that we use spheres for this discretization as they are view-invariant. In particular, this helps regularize out potential noise or irregularities in real-world scanned data (relative to synthetic training data), enabling robust performance on real-world scans. Note that our 3D multi-resolution filtering is different from classical 2D multi-resolution approaches, since the 3D filtering respects the distance in 3D.\n\n#### Similar to 2D multi-resolution filtering approaches, the 3D multi-resolution approaches such as this one capture information at multiple scales. The main difference is that the 3D filtering approach respects the distances in 3D.",
        "We use ModelNet [33] for our training and testing datasets. ModelNet currently contains 127,915 3D CAD models from 662 categories. ModelNet40, a subset including 12,311 models from 40 categories, is well annotated and can be downloaded from the web. The authors also provide a training and testing split on the website, in which there are 9,843 training and 2,468 test models444VoxNet [24] uses the train/test split provided on the website and report average class accuracy on the 2,468 test split. 3DShapeNets [33] and MVCNN [32] use another train/test split comprising the first 80 shapes of each category in the “train” folder (or all shapes if there are fewer than 80) and the first 20 shapes of each category in the “test” folder, respectively.. We use this train/test split for our experiments.\n\n#### The authors follow previous works, such as VoxNet [24[, 3DShapeNets [33], and MVCNN [32] that also use ModelNet test set to evaluate their approaches. In order to be able to compare with them and provide more quantitative results, this paper also evaluates on ModelNet's test set. Additionally, as described in Table 1 (paragraph P7), the authors use ModelNet to provide additional evaluations and ablative analyses, which is more suitable to be done on synthetic data than RGB-D data.",
        "We provide a new real-world scanning dataset benchmark, comprising 243 objects of 12 categories; the geometry is captured with an ASUS Xtion Pro and a dense reconstruction is obtained using the publicly-available VoxelHashing framework [25].For each scan, we have performed a coarse, manual segmentation of the object of interest.In addition, each scan is aligned with the world-up vector.While there are existing datasets captured with commodity range sensors – e.g., [29, 34, 31] – this is the first containing hundreds of annotated models from dense 3D reconstructions.The goal of this dataset is to provide an example of modern real-time 3D reconstructions; i.e., structured representations more complete than a single RGB-D frame but still with many occlusions. This dataset is used as a test set.\n\n#### The reconstructions are not create by manual annotations. Instead, the authors use publicly-available VoxelHashing framework [25] to obtain dense 3D reconstructions. Additionally, the authors have performed a course, manual segmentation of the object of interest, but this is not related to the reconstruction.",
        "Compared with 2D image datasets, currently available 3D shape datasets are limited in scale and variation. To fully exploit the design of our networks, we augment the training data with different azimuth and elevation rotations.This allows the first network to cover local regions at different orientations, and the second network to relate distant points at different relative angles.\n\n#### The authors improve upon previous augmentation strategies and provide analyses to compare each combination of the augmentation strategy (azimuth rotation (AZ), AZ + translation, and AZ + elevation rotation), and conclude that the latter gives the best results. Please note that augmentations on 3D objects are not as trivial as the ones in 2D so providing novel insights w.r.t. data augmentation is quite valuable. I am not sure what would be the possible additional augmentation method in 3D that authors should have tried...",
        "Intuitively, a volumetric representation should encode as much information, if not more, than its multi-view counterpart. However, experiments indicate that multi-view CNNs produce superior performance in object classification. Fig 2 reports the classification accuracy on the ModelNet40 dataset by state-of-the-art volumetric/multi-view architectures111We train models by replicating the architecture of [33] for volumetric CNNs and [32] for multi-view CNNs. All networks are trained in an end-to-end fashion. All methods are trained/tested on the same split for fair comparison. The reported numbers are average instance accuracy. See Sec 6 for details.. A volumetric CNN based on voxel occupancy (green) is 7.3\\% worse than a multi-view CNN (yellow).\n\n#### The authors compare with previous works w.r.t. classification accuracy, in particular the average instance accuracy and average class accuracy. The general issue with introducing novel metrics that haven't been used by prior works is that, first, the motivation for using this metric has to be provided and, second, a significant additional work has to be done in order to evaluate previous works on this new metric.",
        "Two representations of generic 3D shapes are popularly used for object classification, volumetric and multi-view (Fig 1). The volumetric representation encodes a 3D shape as a 3D tensor of binary or real values. The multi-view representation encodes a 3D shape as a collection of renderings from multiple viewpoints. Stored as tensors, both representations can easily be used to train convolutional neural networks, i.e., volumetric CNNs and multi-view CNNs.\n\n#### The similarities between volumetric and multi-view representation are:\n- when stored as tensors, both representations can easily be used to train convolutional neural networks, i.e., volumetric CNNs and multi-view CNNs.\n- the multi-view CNN down-samples each rendered view to 227x227 pixels to maintain a similar computational cost, the volumetric CNN uses a 30x30x30 occupancy grid. Note that 30x30x30 is approximately 227x227. Therefore, the implementations have similar computational costs.\n\nOn the other hand, there are many differences:\n- a volumetric representation should encode as much information, if not more, than its multi-view counterpart (however, experiments indicate that multi-view CNNs produce superior performance in object classification)\n- the input to the multi-view CNN captures more detail.\n- the volumetric representation encodes a 3D shape as a 3D tensor of binary or real values, while the multi-view representation encodes a 3D shape as a collection of renderings from multiple viewpoints",
        "We provide a new real-world scanning dataset benchmark, comprising 243 objects of 12 categories; the geometry is captured with an ASUS Xtion Pro and a dense reconstruction is obtained using the publicly-available VoxelHashing framework [25].For each scan, we have performed a coarse, manual segmentation of the object of interest.In addition, each scan is aligned with the world-up vector.While there are existing datasets captured with commodity range sensors – e.g., [29, 34, 31] – this is the first containing hundreds of annotated models from dense 3D reconstructions.The goal of this dataset is to provide an example of modern real-time 3D reconstructions; i.e., structured representations more complete than a single RGB-D frame but still with many occlusions. This dataset is used as a test set.\n\n#### The authors choose CAD models and RGB-D data for several reasons. First, to demonstrate that, while learning only the synthetic CAD models they are still able to generalize to real-world RGB-D reconstructions. Second, the RGB-D dataset is exclusively proposed in this paper, and it is purposely difficult (contains occlusions and reconstruction noise). Third, by using multiple sources of data, they demonstrate that the model is robust to different data types.",
        "In addition to providing extensive experiments on 3D CAD model datasets, we also introduce a dataset of real-world 3D data, constructed using dense 3D reconstruction taken with [25]. Experiments show that our networks can better adapt from synthetic data to this real-world data than previous methods.\n\n#### The authors train on synthetic data for several reasons. Based on the evidential paragraph P0, one of the reasons is that the proposed method can better adapt from synthetic to real data than previous methods. Other than the evidential information, it is easier to collect a large amount of synthetic data compared to real data, especially for training purposes.",
        "Wu et al. [33] lift 2.5D to 3D with their 3DShapeNets approach by categorizing each voxel as free space, surface or occluded, depending on whether it is in front of, on, or behind the visible surface (i.e., the depthvalue) from the depth map.The resulting representation is a 3D binary voxel grid, which is the input to a CNN with 3D filter banks.Their method is particularly relevant in the context of this work, as they are the first to apply CNNs on a 3D representation.A similar approach is VoxNet [24], which also uses binary voxel grids and a corresponding 3D CNN architecture.The advantage of these approaches is that it can process different sources of 3D data, including LiDAR point clouds, RGB-D point clouds, and CAD models; we likewise follow this direction.\n\n#### 2.5D data is 2D information (image plane) plus the information about the relative depths of points, i.e., voxels - whether the points are behind or in front of the visible surface.",
        "Although the multi-view CNN presented by [32] produces compelling results, we are able to improve its performance through a multi-resolution extension with improved data augmentation.We introduce multi-resolution 3D filtering to capture information at multiple scales. We perform sphere rendering (see Sec 3) at different volume resolutions. Note that we use spheres for this discretization as they are view-invariant. In particular, this helps regularize out potential noise or irregularities in real-world scanned data (relative to synthetic training data), enabling robust performance on real-world scans. Note that our 3D multi-resolution filtering is different from classical 2D multi-resolution approaches, since the 3D filtering respects the distance in 3D.\n\n#### The reason is that, in the real data, it will not always be possible to do the pre-processing steps, especially if they require tedious manual noise removal which cannot be completely done automatically. Thus, by using the noisy dataset, the authors demonstrate that their model is robust to real-world noise and occlusions.",
        "We propose two network variations that significantly improve state-of-the-art CNNs on 3D volumetric data.The first network is designed to mitigate overfitting by introducing auxiliary training tasks, which are themselves challenging. These auxiliary tasks encourage the network to predict object class labels from partial subvolumes. Therefore, no additional annotation efforts are needed. The second network is designed to mimic multi-view CNNs, as they are strong in 3D shape classification. Instead of using rendering routines from computer graphics, our network projects a 3D shape to 2D by convolving its 3D volume with an anisotropic probing kernel. This kernel is capable of encoding long-range interactions between points. An image CNN is then appended to classify the 2D projection. Note that the training of the projection module and the image classification module is end-to-end. This emulation of multi-view CNNs achieves similar performance to them, using only standard layers in CNN.\n\n#### The anisotropic probing kernels can be seen as a special type of convolutional layer. These kernels are elongated in 3D and can thus encode long-range interactions between the points. They are an alternative to using standard computer graphics rendering. Using anisotropic probing kernels helps to capture the global structure of the 3D volume.",
        "We investigate this performance gap in order to ascertain how to improve volumetric CNNs. The gap seems to be caused by two factors: input resolution and network architecture differences. The multi-view CNN down-samples each rendered view to 227\\times 227 pixels (Multi-view Standard Rendering in Fig 1); to maintain a similar computational cost, the volumetric CNN uses a 30\\times 30\\times 30 occupancy grid (Volumetric Occupancy Grid in Fig 1)222Note that 30\\times 30\\times 30\\approx 227\\times 227.. As shown in Fig 1, the input to the multi-view CNN captures more detail.\n\n#### The volumetric representation is costly - in order to keep the same computational cost as multi-view representation of 227x227, the volumetric representation can only have 30x30x30 resolution. Probably using higher resolution in both cases causes other issues.",
        "Many recent empirical breakthroughs in supervised machine learning have been achieved through large and deep neural networks. Network depth (the number of successive computational layers) has played perhaps the most important role in these successes. For instance, within just a few years, the top-5 image classification accuracy on the 1000-class ImageNet dataset has increased from \\sim84% [1] to \\sim95% [2, 3] using deeper networks with rather small receptive fields [4, 5].Other results on practical machine learning problems have also underscored the superiority of deeper networks [6] in terms of accuracy and/or performance.\n\n#### As mentioned in many paragraphs, network depth is essential for expressing more complex functions, which is also essential for success.",
        "The last column of Figure 2 displays the block outputs and visualizes the concept of “information highways”.Most of the outputs stay constant over many layers forming a pattern of stripes.Most of the change in outputs happens in the early layers (\\approx 15 for MNIST and \\approx 40 for CIFAR-100).\n\n#### 'information highways' means that some information is not lost while passing through the layer.",
        "Many recent empirical breakthroughs in supervised machine learning have been achieved through large and deep neural networks. Network depth (the number of successive computational layers) has played perhaps the most important role in these successes. For instance, within just a few years, the top-5 image classification accuracy on the 1000-class ImageNet dataset has increased from \\sim84% [1] to \\sim95% [2, 3] using deeper networks with rather small receptive fields [4, 5].Other results on practical machine learning problems have also underscored the superiority of deeper networks [6] in terms of accuracy and/or performance.\n\n#### Deep architecture has made a lot of research and breakthroughs with this deep architecture, making it important that it can express many kinds of functions.",
        "The last column of Figure 2 displays the block outputs and visualizes the concept of “information highways”.Most of the outputs stay constant over many layers forming a pattern of stripes.Most of the change in outputs happens in the early layers (\\approx 15 for MNIST and \\approx 40 for CIFAR-100).\n\n#### Inspired by LSTM, the authors designed an information highway that adaptively passes information back, which is effective when there are many layers, so LSTM is also effective for many layers.",
        "Thus, depending on the output of the transform gates, a highway layer can smoothly vary its behavior between that of H and that of a layer which simply passes its inputs through. Just as a plain layer consists of multiple computing units such that the i^{th} unit computes y_{i}=H_{i}(\\mathbf{x}), a highway network consists of multiple blocks such that the i^{th} block computes a block state H_{i}(\\mathbf{x}) and transform gate output T_{i}(\\mathbf{x}). Finally, it produces the block output y_{i}=H_{i}(\\mathbf{x})*T_{i}(\\mathbf{x})+x_{i}*(1-T_{i}(\\mathbf{x})), which is connected to the next layer.222Our pilot experiments on training very deep networks were successful with a more complex block design closely resembling an LSTM block “unrolled in time”. Here we report results only for a much simplified form.\n\n#### A highway network is a layer that uses an information highway layer, and a plain network is a general layer. In highway networks, increasing layer depth does not affect performance, but in plain networks, it can. One layer of the plain network is made up of normal computation units, whereas the highway network is made up of block units.",
        "We refer to T as the transform gate and C as the carry gate, since they express how much of the output is produced by transforming the input and carrying it, respectively. For simplicity, in this paper we set C=1-T, giving\n\n#### By defining C = 1-T, the authors made it automatically learn how much information to change or leave as is.",
        "The training curves for the best performing networks for each depth are shown in Figure 1. As expected, 10 and 20-layer plain networks exhibit very good performance (mean loss <1e^{-4}), which significantly degrades as depth increases, even though network capacity increases.Highway networks do not suffer from an increase in depth, and 50/100 layer highway networks perform similar to 10/20 layer networks. The 100-layer highway network performed more than 2 orders of magnitude better compared to a similarly-sized plain network.It was also observed that highway networks consistently converged significantly faster than plain ones.\n\n#### Although highway networks do not perform well at best, they do not break down significantly when stacked deeply. Also, there is freedom in setting the number of depths, and it can be learned well with vanilla SGD. In addition, meaningful outputs come out from all layers and information can be handed over dynamically.",
        "All networks were trained using SGD with momentum. An exponentially decaying learning rate was used in Section 3.1. For the rest of the experiments, a simpler commonly used strategy was employed where the learning rate starts at a value \\lambda and decays according to a fixed schedule by a factor \\gamma. \\lambda, \\gamma and the schedule were selected once based on validation set performance on the CIFAR-10 dataset, and kept fixed for all experiments.All convolutional highway networks utilize the rectified linear activation function [16] to compute the block state H. To provide a better estimate of the variability of classification results due to random initialization, we report our results in the format Best (mean \\pm std.dev.) based on 5 runs wherever available. Experiments were conducted using Caffe [33] and Brainstorm (https://github.com/IDSIA/brainstorm) frameworks. Source code, hyperparameter search results and related scripts are publicly available at http://people.idsia.ch/~rupesh/very_deep_learning/.\n\n#### Both the plain network and the highway network set the best hyperparameters after 100 experiments.",
        "The transform gate biases of the two networks were initialized to -2 and -4 respectively.It is interesting to note that contrary to our expectations most biases decreased further during training.For the CIFAR-100 network the biases increase with depth forming a gradient.Curiously this gradient is inversely correlated with the average activity of the transform gates, as seen in the second column.This indicates that the strong negative biases at low depths are not used to shut down the gates, but to make them more selective.This behavior is also suggested by the fact that the transform gate activity for a single example (column 3) is very sparse.The effect is more pronounced for the CIFAR-100 network, but can also be observed to a lesser extent in the MNIST network.\n\n#### Contrary to the authors' expectations, most of the biases were said to be reduced during training. In CIFAR-100, it is said that the biases increase according to the depth of the gradient. Authors explain that this is because strong negative biases at low depths are not used to close the gate.",
        "We trained both plain and highway networks of varying varying depths on the MNIST digit classification dataset.All networks are thin: each layer has 50 blocks for highway networks and 71 units for plain networks, yielding roughly identical numbers of parameters (\\approx5000) per layer.In all networks, the first layer is a fully connected plain layer followed by 9, 19, 49, or 99 fully connected plain or highway layers. Finally, the network output is produced by a softmax layer.We performed a random search of 100 runs for both plain and highway networks to find good settings for the following hyperparameters: initial learning rate, momentum, learning rate exponential decay factor & activation function (either rectified linear or tanh). For highway networks, an additional hyperparameter was the initial value for the transform gate bias (between -1 and -10). Other weights were initialized using the same normalized initialization as plain networks.\n\n#### Although not explicitly stated, given that the authors selected the best hyperparameters out of 100 experiments, it is highly likely that the initial bias was also selected by these experiments.",
        "In image classification, top-down attention mechanism has been applied using different methods: sequential process, region proposal and control gates. Sequential process  [23, 12, 37, 7] models image classification as a sequential decision. Thus attention can be applied similarly with above. This formulation allows end-to-end optimization using RNN and LSTM and can capture different kinds of attention in a goal-driven way.\n\n#### The related works that the authors mention  do not use the same attention mechanism they use in this paper, but it is impossible to know just from this paper whether their claim that the attention method they used was never applied before to the image classification task is true.",
        "Not only a friendly face but also red color will draw our attention. The mixed nature of attention has been studied extensively in the previous literatures [34, 16, 23, 40]. Attention not only serves to select a focused location but also enhances different representations of objects at that location. Previous works formulate attention drift as a sequential process to capture different attended aspects. However, as far as we know, no attention mechanism has been applied to feedforward network structure to achieve state-of-art results in image classification task. Recent advances of image classification focus on training feedforward convolutional neural networks using “very deep” structure [27, 33, 10].\n\n#### The authors are talking about features that were learned using the attention mechanism. The model focuses on such features, which can include color, scale, or spatial information, when it processes an image for classification. For example, the attention mechanism can learn that blue pixels in the background of the image from the sky are not important for image classification, and the model will consequently reduce the contribution of those pixels to the final classification result.",
        "The Residual Attention Network alleviates above problems. In Attention Module, each trunk branch has its own mask branch to learn attention that is specialized for its features. As shown in Fig.1, in hot air balloon images, blue color features from bottom layer have corresponding sky mask to eliminate background, while part features from top layer are refined by balloon instance mask. Besides, the incremental nature of stacked network structure can gradually refine attention for complex images.\n\n#### The attention masks successfully learn meaningful information from the dataset and their usage resulted in state-of-the-art results, which indicates that the attention mechanism does learn more discriminative features.",
        "The experiment results are shown in Table 1, the mixed attention has the best performance. Previous works normally focus on only one type of attention, for example scale attention [3] or spatial attention [17], which puts additional constrain on soft mask by weight sharing or normalization. However, as supported by our experiments, making attention change adaptively with features without additional constraint leads to the best performance.\n\n#### The Top-1 and Top-5 error metrics are improved when increasing attention modules.",
        "In this section, we evaluate the performance of proposed Residual Attention Network on a series of benchmark datasets including CIFAR-10, CIFAR-100 [19], and ImageNet [5].Our experiments contain two parts. In the first part, we analyze the effectiveness of each component in the Residual Attention Network including attention residual learning mechanism and different architectures of soft mask branch in the Attention Module.After that, we explore the noise resistance property. Given limited computation resources, we choose CIFAR-10 and CIFAR-100 dataset to conduct these experiments. Finally, we compare our network with state-of-the-art results in CIFAR dataset.In the second part, we replace the Residual Unit with Inception Module and ResNeXt to demonstrate our Residual Attention Network surpasses origin networks both in parameter efficiency and final performance.We also compare image classification performance with state-of-the-art ResNet and Inception on ImageNet dataset.\n\n#### The main metrics used to compare different methods were Top-1 and Top-5 error, test error on the CIFAR datasets, the number of parameters and the number of FLOPs. The mean absolute response of output features of each stage was also used to compare their method with ResNet.",
        "However, naive stacking Attention Modules leads to the obvious performance drop. First, dot production with mask range from zero to one repeatedly will degrade the value of features in deep layers. Second, soft mask can potentially break good property of trunk branch, for example, the identical mapping of Residual Unit.\n\n#### If naive stacking, too many attention modules will cause a drastic performance drop as the mask values will converge to 0. However, the model in the paper uses their own stacking method, which avoids the downfall of naive stacking. The only consequence when using the paper's stacking method is that the model will require more parameters and FLOPs.",
        "However, naive stacking Attention Modules leads to the obvious performance drop. First, dot production with mask range from zero to one repeatedly will degrade the value of features in deep layers. Second, soft mask can potentially break good property of trunk branch, for example, the identical mapping of Residual Unit.\n\n#### Because of the mask values being between 0 and 1, and the fact that naive stacking attention modules means using a dot product on the resulting masks, naive stacking causes a performance drop as the dot product of several modules will converge towards 0. The attention residual learning mechanism changes this by making the lower bound of the mask values the original features instead of 0.",
        "However, recent advances of image classification focus on training feedforward convolutional neural networks using “very deep” structure [27, 33, 10]. The feedforward convolutional network mimics the bottom-up paths of human cortex. Various approaches have been proposed to further improve the discriminative ability of deep convolutional neural network. VGG [27], Inception [33] and residual learning [10] are proposed to train very deep neural networks. Stochastic depth [14], Batch Normalization [15] and Dropout [28] exploit regularization for convergence and avoiding overfitting and degradation.\n\n#### The bottom-up top-down feedforward structure is a combination of a bottom-up fast feedforward process that creates low resolution features maps to quickly collect global information, and a top-down attention feedback process that uses the global information along with the original feature maps to create features for inference.",
        "We compare our Residual Attention Network with state-of-the-art methods including ResNet [11] and Wide ResNet [39] on CIFAR-10 and CIFAR-100 datasets.The results are shown in Table 6.Our Attention-452 outperforms all the baseline methods on CIFAR-10 and CIFAR-100 datasets.Note that Attention-92 network achieves 4.99\\% test error on CIFAR-10 and 21.71\\% test error on CIFAR-100 compared with 5.46\\% and 24.33\\% test error on CIFAR-10 and CIFAR-100 for ResNet-164 network under similar parameter size.In addition, Attention-236 outperforms ResNet-1001 using only half of the parameters. It suggests that our Attention Module and attention residual learning scheme can effectively reduce the number of parameters in the network while improving the classification performance.\n\n#### ResNet was state-of-the-art at the time, according to the paper. Therefore, it makes sense to compare their method with ResNet.",
        "In this experiment, we evaluate the effectiveness of attention residual learning mechanism.Since the notion of attention residual learning (ARL) is new, no suitable previous methods are comparable therefore we use “naive attention learning” (NAL) as baseline.Specifically, “naive attention learning” uses Attention Module where features are directly dot product by soft mask without attention residual learning.We set the number of Attention Module in each stage m = {1, 2, 3, 4}. For Attention Module, this leads to Attention-56 (named by trunk layer depth), Attention-92, Attention-128 and Attention-164 respectively.\n\n#### As there was no other available comparison, NAL seems to be the only choice for the baseline.",
        "Table 6: Comparisons with state-of-the-art methods on CIFAR-10/100. †: the Attention-452 consists of Attention Module with hyper-parameters setting: {p = 2, t = 4, r = 3} and 6 Attention Modules per stage.\n\n#### It seems true as they also tried m = 5 and 6 and performance still improved, as seen in Table 6.",
        "We conduct experiments to validate the effectiveness of encoder-decoder structure by comparing with local convolutions without any down sampling or up sampling. The local convolutions soft mask consists of three Residual Units using the same number of FLOPs.The Attention-56 is used to construct Attention-Encoder-Decoder-56 and Attention-Local-Conv-56 respectively.Results are shown in Table 4.The Attention-Encoder-Decoder-56 network achieves lower test error 5.52\\% compared with Attention-Local-Conv-56 network 6.48\\% with a considerable margin 0.94\\%. The result suggests that the soft attention optimization process will benefit from multi-scale information.\n\n#### The local convolutions' soft mask only consists of three Residual units, which remain the same size. However, the encoder-decoder structure consists of downsampling and upsampling layers.",
        "In this experiment, we show our Residual Attention Network enjoys noise resistant property on CIFAR-10 dataset following the setting of paper [31].The confusion matrix Q in our experiment is set as follows:Q=\\left(\\begin{matrix}r&\\frac{1-r}{9}&\\cdots&\\frac{1-r}{9}\\\\\\frac{1-r}{9}&r&\\cdots&\\frac{1-r}{9}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\\\frac{1-r}{9}&\\frac{1-r}{9}&\\cdots&r\\\\\\end{matrix}\\right)_{10\\times 10}(7)\n\n#### The confusion matrix Q shows how many images were correctly labeled and how many images were purposely incorrectly labeled for the noise experiment.",
        "When the basic unit is ResNeXt, the AttentionNeXt-56 network performance is the same as ResNeXt-101 while the parameters and FLOPs are significantly fewer than ResNeXt-101. For Inception, The AttentionIncepiton-56 outperforms Inception-ResNet-v1 [32] by a margin with a 0.94% reduction on top-1 error and a 0.21% reduction on top-5 error. The results show that our method can be applied on different network structures.\n\n#### Proving generalization shows that the proposed method can be applied to multiple structures without a significant loss in performance.",
        "The quantitative analysis of lesions requires accurate lesion segmentation in multi-modal, three-dimensional images which is a challenging task for a number of reasons. The heterogeneous appearance of lesions including the large variability in location, size, shape and frequency make it difficult to devise effective segmentation rules.It is thus highly non-trivial to delineate contusions, edema and haemorrhages in TBI (Irimia et al. (2012)), or sub-components of brain tumors such as proliferating cells and necrotic core (Menze et al. (2015)). The arguably most accurate segmentation results can be obtained through manual delineation by a human expert which is tedious, expensive, time-consuming, impractical in larger studies, and introduces inter-observer variability. Additionally, for deciding whether a particular region is part of a lesion multiple image sequences with varying contrasts need to be considered, and the level of expert knowledge and experience are important factors that impact segmentation accuracy. Hence, in clinical routine often only qualitative, visual inspection, or at best crude measures like approximate lesion volume and number of lesions are used (Yuh et al. (2012); Wen et al. (2010)). In order to capture and better understand the complexity of brain pathologies it is important to conduct large studies with many subjects to gain the statistical power for drawing conclusions across a whole patient population. The development of accurate, automatic segmentation algorithms has therefore become a major research focus in medical image computing with the potential to offer objective, reproducible, and scalable approaches to quantitative assessment of brain lesions.\n\n#### Previous literature state the importance of understanding the sub-component layout of brain tumors for diagnosis and treatment. It can therefore be inferred that these sub-components are created in a hierarchical way as the brain tumor develops. It seems unlikely that the authors conducted additional experiments.",
        "The discriminative power of the learned features is indicated by the success of recent CNN-based systems in matching human performance in domains where it was previously considered too ambitious (He et al. (2015); Silver et al. (2016)). Analysis of the automatically extracted information could potentially provide novel insights and facilitate research on pathologies for which little prior knowledge is currently available. In an attempt to illustrate this, we explore what patterns have been learned automatically for the lesion segmentation tasks. We visualize the activations of DeepMedic’s FMs when processing a subject from our TBI database. Many appearing patterns are difficult to interpret, especially in deeper layers. In Fig. 14 we provide some examples that have an intuitive explanation. One of the most interesting findings is that the network learns to identify the ventricles, CSF, white and gray matter. This reveals that differentiation of tissue type is beneficial for lesion segmentation. This is in line with findings in the literature, where segmentation performance of traditional classifiers was significantly improved by incorporation of tissue priors (Van Leemput et al. (1999); Zikic et al. (2012)). It is intuitive that different types of lesions affect different parts of the brain depending on the underlying mechanisms of the pathology. A rigorous analysis of spatial cues extracted by the network may reveal correlations that are not well defined yet.\n\n#### Figure 14 shows that the network learns to identify the ventricles, CSF, white and gray matter, with each filter identifying different tissue types, indicating that learning the differences in the features of different tissue types is helpful for lesion segmentation.",
        "Table 3 shows the results of our method on the BRATS test data. Results of other submissions are not accessible. The decrease in performance is possibly due to the the inclusion of test images that vary significantly from the training data, such as cases acquired in clinical centers that did not provide any of the training images, something that was confirmed by the organisers. Note that performance gains obtained with the CRF are larger in this case. This indicates not only that its configuration has not overfitted to the training database but also that the CRF is robust to factors of variation between acquisition sites, which complements nicely the more sensitive CNN.\n\n#### The results show that the performance of the model drops when faced with testing data that was acquired by centers that did not provide any data in the training dataset. It can be inferred that having a more diverse dataset or utilizing techniques that can help make the CNN more robust to these differences can help generalization.",
        "Deeper networks have greater discriminative power due to the additional non-linearities and better quality of local optima (Choromanska et al. (2015)). However, convolutions with 3D kernels are computationally expensive in comparison to the 2D variants, which hampers the addition of more layers. Additionally, 3D architectures have a larger number of trainable parameters, with each layer adding C_{l}C_{l-1}\\prod_{i=\\{x,y,z\\}}{\\bm{\\kappa}_{l}^{(i)}} weights to the model. C_{l} is the number of FMs in layer l and \\bm{\\kappa}_{l}^{\\{x,y,z\\}} the size of its kernel in the respective spatial dimension. Overall this makes the network increasingly prone to over-fitting.\n\n#### Deeper networks exhibit better performance as they introduce more non-linearities and converge towards better local optima. But, adding more layers increase both computation time and the number of parameters. This could cause the network to be prone to overfitting. Therefore, kernel sizes were reduced such that the number of parameters were similar to the original shallow networks, helping with generalization by reducing overfitting while still receiving the positive effect of having more layers.",
        "Figure 8 shows the improvement DeepMedic achieves over the single pathway model Deep+. In Fig. 9 we show two representative visual examples of this improvement when using the multi-scale CNN. Finally, we confirm that the performance increase can be accounted to the additional context and not the additional capacity of DeepMedic. To this end, we build a big single-scale model by doubling the FMs at each of the 9-layers of Deep+ and adding two hidden layers. This 11-layers deep and wide model, referred to as “BigDeep+”, has the same number of parameters as DeepMedic. The performance of the model is not improved, while showing signs of over-fitting.\n\n#### As seen in Figure 8, despite BigDeep+ having a similar capacity to DeepMedic, the mean validation accuracy of BigDeep+ converges to a lower accuracy than that of DeepMedic. The same applies to the mean DSC for the two models. Therefore, it can be inferred that BigDeep+ is suffering from overfitting on the training data.",
        "Acquired brain MRI scans are often anisotropic. Such is the case for most sequences in our TBI dataset, which have been acquired with lower axial resolution, except for the isotropic MPRAGE. We perform a series of experiments to investigate the behaviour of 2D networks and assess the benefit of processing 3D context in this setting.\n\n#### The authors state that most of the sequences within their TBI dataset are anisotropic.",
        "Sixty-six patients with moderate-to-severe TBI who required admission to the Neurosciences Critical Care Unit at Addenbrooke’s Hospital, Cambridge, UK, underwent imaging using a 3-Tesla Siemens Magnetom TIM Trio within the first week of injury. Ethical approval was obtained from the Local Research Ethics Committee (LREC 97/290) and written assent via consultee agreement was obtained for all patients. The structural MRI sequences that are used in this work are isotropic MPRAGE (1mm×mm\\timesitalic_m italic_m ×1mm×mm\\timesitalic_m italic_m ×1mm), axial FLAIR, T2 and Proton Density (PD) (0.7mm×mm\\timesitalic_m italic_m ×0.7mm×mm\\timesitalic_m italic_m ×5mm), and Gradient-Echo (GE) (0.86mm×mm\\timesitalic_m italic_m ×0.86mm×mm\\timesitalic_m italic_m ×5mm). All visible lesions were manually annotated on the FLAIR and GE sequences with separate labeling for each lesion type. In nine patients the presence of hyperintense white matter lesions that were felt to be chronic in nature were also annotated. Artifacts, for example, signal loss secondary to intraparenchymal pressure probes, were also noted. For the purpose of this study we focus on binary segmentation of all abnormalities within the brain tissue. Thus, we merged all classes that correspond to intra-cerebral abnormalities into a single “lesion” label. Extra-cerebral pathologies such as epidural and subdural hematoma were treated as background. We excluded two datasets because of corrupted FLAIR images, two cases because no lesions were found and one case  because of a major scanning artifact corrupting the images. This results in a total of 61 cases used for quantitative evaluation. Brain masks were obtained using the ROBEX tool (Iglesias et al. (2011)). All images were resampled to an isotropic 1mm^{3} resolution, with dimensions 193\\times229\\times193 and affinely registered (Studholme et al. (1999)) to MNI space using the atlas by Grabner et al. (2006). No bias field correction was used as preliminary results showed that this can negatively affect lesion appearance. Image intensities were normalized to have zero-mean and unit variance, as it has been reported that this improves CNN results (Jarrett et al. (2009)).\n\n#### It is implied that the annotations were done by experts at the Neurosciences Critical Care Unit at Addenbrooke's Hospital, Cambridge, UK.",
        "Sixty-six patients with moderate-to-severe TBI who required admission to the Neurosciences Critical Care Unit at Addenbrooke’s Hospital, Cambridge, UK, underwent imaging using a 3-Tesla Siemens Magnetom TIM Trio within the first week of injury. Ethical approval was obtained from the Local Research Ethics Committee (LREC 97/290) and written assent via consultee agreement was obtained for all patients. The structural MRI sequences that are used in this work are isotropic MPRAGE (1mm×1mm×1mm), axial FLAIR, T2 and Proton Density (PD) (0.7mm×0.7mm×5mm), and Gradient-Echo (GE) (0.86mm×0.86mm×5mm). All visible lesions were manually annotated on the FLAIR and GE sequences with separate labeling for each lesion type. In nine patients the presence of hyperintense white matter lesions that were felt to be chronic in nature were also annotated. Artifacts, for example, signal loss secondary to intraparenchymal pressure probes, were also noted. For the purpose of this study we focus on binary segmentation of all abnormalities within the brain tissue. Thus, we merged all classes that correspond to intra-cerebral abnormalities into a single “lesion” label. Extra-cerebral pathologies such as epidural and subdural hematoma were treated as background. We excluded two datasets because of corrupted FLAIR images, two cases because no lesions were found and one case because of a major scanning artifact corrupting the images. This results in a total of 61 cases used for quantitative evaluation. Brain masks were obtained using the ROBEX tool (Iglesias et al. (2011)). All images were resampled to an isotropic 1mm3 resolution, with dimensions 193×229×193 and affinely registered (Studholme et al. (1999)) to MNI space using the atlas by Grabner et al. (2006). No bias field correction was used as preliminary results showed that this can negatively affect lesion appearance. Image intensities were normalized to have zero-mean and unit variance, as it has been reported that this improves CNN results (Jarrett et al. (2009)).\n\n#### The paper cites Jarrett et al. as the reason why they chose zero-mean normalization techniques. The benefits of normalization with zero-mean techniques therefore cannot be answered by the paper. It can be inferred that they did not test this claim themselves.",
        "Table 3 shows the results of our method on the BRATS test data. Results of other submissions are not accessible. The decrease in performance is possibly due to the the inclusion of test images that vary significantly from the training data, such as cases acquired in clinical centers that did not provide any of the training images, something that was confirmed by the organisers. Note that performance gains obtained with the CRF are larger in this case. This indicates not only that its configuration has not overfitted to the training database but also that the CRF is robust to factors of variation between acquisition sites, which complements nicely the more sensitive CNN.\n\n#### Through Tables 2 to 5, the authors have shown that the performance of DeepMedic in terms of DSC, precision, sensitivity, ASSD, and Haussdorf for the BRATS and ISLES test datasets are worse than the performance of DeepMedic when trained with the BRATS and ISLES training datasets.",
        "Quantitative results from the application of the DeepMedic, the CRF and an ensemble of three similar networks on the training data are presented in Table 2. The latter two offer an improvement, albeit fairly small since the performance of DeepMedic is already rather high in this task. Also shown are results from previous works, as reported on the online evaluation platform. Various settings may vary among submissions, such as the pre-processing pipeline or the number of folds used for cross-validation. Still it appears that our system performs favourably compared to previous state-of-the-art, including the semi-automatic system of Bakas et al. (2015) (bakas1) who won the latest challenge and the method of Pereira et al. (2015) (peres1), which is based on grade-specific 2D CNNs and requires visual inspection of the tumor and identification of the grade by the user prior to segmentation. Examples of segmentations obtained with our method are shown in Fig. 12. DeepMedic behaves very well in preserving the hierarchical structure of the tumor, which we account to the large context processed by our multi-scale network.\n\n#### Figure 12 shows successful cases of segmentation for the hierarchy of brain tumors. As seen in Figure 12, the model understands that the sequence of layers goes from oedema to non-enhancing core to enhancing core to necrotic core, preserving the hierarchical structure of tumors. They also show a relatively unsuccessful case where oversegmentation occurs, but even in this example, the hierarchy of the tumor is preserved.",
        "Network configuration and training: We modify the DeepMedic architecture to handle multi-class problems by extending the classification layer to five feature maps (four tumor classes plus background). The rest of the configuration remains unchanged. We enrich the dataset with sagittal reflections. Opposite to the experiments on TBI, we do not employ the intensity perturbation and dropout on convolutional layers, because the network should not require as much regularisation with this large database. The network is trained on image segments extracted with equal probability centred on the whole tumor and healthy tissue. The distribution of the classes captured by our training scheme is provided in C.\n\n#### The authors mention that they reduced the amount of regularization techniques as they consider the BRATS database to be large.",
        "Real Image Editing.Editing a real image requires finding an initial noise vector that produces the given input image when fed into the diffusion process. This process, known as inversion, has recently drawn considerable attention for GANs, e.g., zhu2016generative ; abdal2019image2stylegan ; alaluf2022hyperstyle ; roich2021pivotal ; zhu2020domain ; tov2021designing ; Wang2021HighFidelityGI ; xia2021gan , but has not yet been fully addressed for text-guided diffusion models.\n\n#### Detailed generated images using GANs depends on the initial noise vector and the interaction between pixels to text embedding. Unfortunately the reason that specifies why large and diverse datasets didn't succeed isn't mentioned in this paper, and neither the embedding size nor any related information can be exploited to complete the answer.",
        "Let DM(z_{t},\\mathcal{P},t,s) be the computation of a single step t of the diffusion process, which outputs the noisy image z_{t-1}, and the attention map M_{t} (omitted if not used). We denote by DM(z_{t},\\mathcal{P},t,s)\\{M\\leftarrow\\widehat{M}\\} the diffusion step where we override the attention map M with an additional given map \\widehat{M}, but keep the values V from the supplied prompt. We also denote by M_{t}^{*} the produced attention map using the edited prompt \\mathcal{P}^{*}.Lastly, we define Edit(M_{t},M_{t}^{*},t) to be a general edit function, receiving as input the t’th attention maps of the original and edited images during their generation.\n\n#### A noisy image is the output image of a diffusion step, and the features of a noisy image can’t be answered using this paper only as it’s assumed to be a basic knowledge to the reader background in Machine Learning “And this question is repeated”.",
        "Recently, large-scale language-image (LLI) models, such as Imagen saharia2022photorealistic , DALL·E 2 ramesh2022hierarchical  and Parti yu2022scaling , have shown phenomenal generative semantic and compositional power, and gained unprecedented attention from the research community and the public eye.These LLI models are trained on extremely large language-image datasets and use state-of-the-art image generative models including auto-regressive and diffusion models.However, these models do not provide simple editing means, and generally lack control over specific semantic regions of a given image. In particular, even the slightest change in the textual prompt may lead to a completely different output image.\n\n#### Because trained large models on large dataset lack control over generated images as it really depends on the random seed and the interaction between pixels to text embedding through the diffusion process which results in the spatial information from the internal layers of the generative model.",
        "To circumvent this, LLI-based methods nichol2021glide ; avrahami2022blendedlatent ; ramesh2022hierarchical require the user to explicitly mask a part of the image to be inpainted, and drive the edited image to change in the masked area only, while matching the background of the original image. This approach has provided appealing results, however, the masking procedure is cumbersome, hampering quick and intuitive text-driven editing. Moreover, masking the image content removes important structural information, which is completely ignored in the inpainting process. Therefore, some editing capabilities are out of the inpainting scope, such as modifying the texture of a specific object.\n\n#### Examples such as modifying textures of specific objects or changing bicycles in an image to a car.",
        "We use the Imagen saharia2022photorealistic  text-guided synthesis model as a backbone. Since the composition and geometry are mostly determined at the 64\\times 64 resolution, we only adapt the text-to-image diffusion model, using the super-resolution process as is.Recall that each diffusion step t consists of predicting the noise \\epsilon from a noisy image z_{t} and text embedding \\psi(\\mathcal{P}) using a U-shaped network ronneberger2015u . At the final step, this process yields the generated image \\mathcal{I}=z_{0}.Most importantly, the interaction between the two modalities occurs during the noise prediction, where the embeddings of the visual and textual features are fused using Cross-attention layers that produce spatial attention maps for each textual token.\n\n#### To answer this question we need to recall the diffusion process, which is in order to predict the noise of an image we have two inputs 1- noisy image and 2- text embedding, and the interaction between the two inputs are fused using Cross-attention layers that produce spatial attention maps for each textual token. and that is what is meant by the interaction between pixels to text embedding.",
        "We use the Imagen saharia2022photorealistic  text-guided synthesis model as a backbone. Since the composition and geometry are mostly determined at the 64\\times 64 resolution, we only adapt the text-to-image diffusion model, using the super-resolution process as is.Recall that each diffusion step t consists of predicting the noise \\epsilon from a noisy image z_{t} and text embedding \\psi(\\mathcal{P}) using a U-shaped network ronneberger2015u . At the final step, this process yields the generated image \\mathcal{I}=z_{0}.Most importantly, the interaction between the two modalities occurs during the noise prediction, where the embeddings of the visual and textual features are fused using Cross-attention layers that produce spatial attention maps for each textual token.\n\n#### They are fused using Cross-attention layers, to illustrate more in Figure 3, the deep spatial features of noisy image φ(zt) are projected to a query matrix Q = lQ(φ(zt)), and the textual embedding is projected to a key matrix K = lK(ψ(P)) and a value matrix V = lV (ψ(P)), via learned linear projections lQ, lK, lV.",
        "To obtain more expressive generation capabilities, Crowson et al. crowson2022vqgan  use VQ-GAN esser2021taming , trained over diverse data, as a backbone.Other works avrahami2022blended ; kim2022diffusionclip  exploit the recent Diffusion models ho2020denoising ; sohl2015deep ; song2019generative ; ho2020denoising ; song2020denoising ; rombach2021highresolution , which achieve state-of-the-art generation quality over highly diverse datasets, often surpassing GANs dhariwal2021diffusion .Kim et al. kim2022diffusionclip  show how to perform global changes, whereas Avrahami et al. avrahami2022blended  successfully perform local manipulations using user-provided masks for guidance.\n\n#### (Kim et al.) Doesn't use user-provided masks and exploited recent Diffusion models to perform global changes as most editing works are limited to global editing if no masks were provided, While (Avrahami et al.) performed local manipulation using user-provided masks.",
        "To circumvent this, LLI-based methods nichol2021glide ; avrahami2022blendedlatent ; ramesh2022hierarchical require the user to explicitly mask a part of the image to be inpainted, and drive the edited image to change in the masked area only, while matching the background of the original image. This approach has provided appealing results, however, the masking procedure is cumbersome, hampering quick and intuitive text-driven editing. Moreover, masking the image content removes important structural information, which is completely ignored in the inpainting process. Therefore, some editing capabilities are out of the inpainting scope, such as modifying the texture of a specific object.\n\n#### No, a previous work by (Bau et al. [7]) demonstrated how to use user-provided masks for guidance of manipulation, as well as most LLI-based methods requires masks defined by the user.",
        "Let DM(z_{t},\\mathcal{P},t,s) be the computation of a single step t of the diffusion process, which outputs the noisy image z_{t-1}, and the attention map M_{t} (omitted if not used). We denote by DM(z_{t},\\mathcal{P},t,s)\\{M\\leftarrow\\widehat{M}\\} the diffusion step where we override the attention map M with an additional given map \\widehat{M}, but keep the values V from the supplied prompt. We also denote by M_{t}^{*} the produced attention map using the edited prompt \\mathcal{P}^{*}.Lastly, we define Edit(M_{t},M_{t}^{*},t) to be a general edit function, receiving as input the t’th attention maps of the original and edited images during their generation.\n\n#### A noisy image is the output image of a diffusion step, and the features of a noisy image can't be answered using this paper only.",
        "Let DM(z_{t},\\mathcal{P},t,s) be the computation of a single step t of the diffusion process, which outputs the noisy image z_{t-1}, and the attention map M_{t} (omitted if not used). We denote by DM(z_{t},\\mathcal{P},t,s)\\{M\\leftarrow\\widehat{M}\\} the diffusion step where we override the attention map M with an additional given map \\widehat{M}, but keep the values V from the supplied prompt. We also denote by M_{t}^{*} the produced attention map using the edited prompt \\mathcal{P}^{*}.Lastly, we define Edit(M_{t},M_{t}^{*},t) to be a general edit function, receiving as input the t’th attention maps of the original and edited images during their generation.\n\n#### The reason is in the diffusion process a noisy image outputted \"zt-1\" at a single time-step \"t\" can be computed as DM(zt,P,t,s).",
        "Fader Control using Attention Re-weighting.While controlling the image by editing the prompt is very effective, we find that it still does not allow full control over the generated image. Consider the prompt “snowy mountain”. A user may want to control the amount of snow on the mountain. However, it is quite difficult to describe the desired amount of snow through text. Instead, we suggest a fader control lample2017fader , where the user controls the magnitude of the effect induced by a specific word, as depicted in fig. 9. As described in section 3, we achieve such control by re-scaling the attention of the specified word. Additional results are in the appendix (fig. 15).\n\n#### Fader control allows users to control the magnitude of the effect induced by specific words. the answer to percentages numbers can't be answered within this paper as authors only suggested fader control and didn't deep dive into other methods to control the magnitude of words.",
        "Real Image Editing.Editing a real image requires finding an initial noise vector that produces the given input image when fed into the diffusion process. This process, known as inversion, has recently drawn considerable attention for GANs, e.g., zhu2016generative ; abdal2019image2stylegan ; alaluf2022hyperstyle ; roich2021pivotal ; zhu2020domain ; tov2021designing ; Wang2021HighFidelityGI ; xia2021gan , but has not yet been fully addressed for text-guided diffusion models.\n\n#### Inversion of GANs requires finding the initial noise vector that produces the edit we want. Can't fully answer this question regarding the text guided as it's not fully addressed for text-guided diffusion models yet.",
        "This inversion process often produces satisfying results, as presented in fig. 10.However, the inversion is not sufficiently accurate in many other cases, as in fig. 11.This is partially due to a distortion-editability tradeoff tov2021designing , where we recognize that reducing the classifier-free guidance ho2021classifier  parameter (i.e., reducing the prompt influence) improves reconstruction but constrains our ability to perform significant manipulations.\n\n#### In order to fully answer this question we have to review reference [43].",
        "This inversion process often produces satisfying results, as presented in fig. 10.However, the inversion is not sufficiently accurate in many other cases, as in fig. 11.This is partially due to a distortion-editability tradeoff tov2021designing , where we recognize that reducing the classifier-free guidance ho2021classifier  parameter (i.e., reducing the prompt influence) improves reconstruction but constrains our ability to perform significant manipulations.\n\n#### By observed that in the referenced [18] work shop \"Generative models and downstream applications, 2021\".",
        "To alleviate this limitation, we propose to restore the unedited regions of the original image using a mask, directly extracted from the attention maps. Note that here the mask is generated with no guidance from the user. As presented in fig. 12, this approach works well even using the naïve DDPM inversion scheme (adding noise followed by denoising). Note that the cat’s identity is well-preserved under various editing operations, while the mask is produced only from the prompt itself.\n\n#### Extracted masks directly from the attention maps can restore the unedited regions of the original image.",
        "We use the Imagen saharia2022photorealistic  text-guided synthesis model as a backbone. Since the composition and geometry are mostly determined at the 64\\times 64 resolution, we only adapt the text-to-image diffusion model, using the super-resolution process as is.Recall that each diffusion step t consists of predicting the noise \\epsilon from a noisy image z_{t} and text embedding \\psi(\\mathcal{P}) using a U-shaped network ronneberger2015u . At the final step, this process yields the generated image \\mathcal{I}=z_{0}.Most importantly, the interaction between the two modalities occurs during the noise prediction, where the embeddings of the visual and textual features are fused using Cross-attention layers that produce spatial attention maps for each textual token.\n\n#### True, as attention maps are calculated by using deep spatial features of a noisy image which is projected to a \"Query Matrix\" and the textual embedding is projected to a \"Key Matrix\" and a \"Value Matrix\", then finally attentions maps calculated by learned linear projections of Query Matrix, Key Matrix and Value Matrix.",
        "Our key observation is that the structure and appearances of the generated image depend not only on the random seed, but also on the interaction between the pixels to the text embedding through the diffusion process. By modifying the pixel-to-text interaction that occurs in cross-attention layers, we provide Prompt-to-Prompt image editing capabilities. More specifically, injecting the cross-attention maps of the input image \\mathcal{I} enables us to preserve the original composition and structure. In section 3.1, we review how cross-attention is used, and in section 3.2 we describe how to exploit the cross-attention for editing. For additional background on diffusion models, please refer to appendix A.\n\n#### Injecting the cross-attention maps of the input image enabled the authors to preserve the original composition and structure, and as illustrated in Figure. 4, The average attention maps are plotted, and pixels are more attracted to words that describe them, e.g. pixels of the bear in the image are correlated with the word \"bear\".\n\nComposite: True",
        "Since the attention reflects the overall composition, we can inject the attention maps M that were obtained from the generation with the original prompt \\mathcal{P}, into a second generation with the modified prompt \\mathcal{P}^{*}. This allows the synthesis of an edited image \\mathcal{I}^{*} that is not only manipulated according to the edited prompt, but also preserves the structure of the input image \\mathcal{I}. This example is a specific instance of a broader set of attention-based manipulations leading to different types of intuitive editing. We, therefore, start by proposing a general framework, followed by the details of the specific editing operations.\n\n#### The overall composition is reflected by the attenion maps, which can be injected during the diffusion process at controled time-step, which allows the necessary freedom for adapting the new prompt. \n\nComposite: True",
        "To circumvent this, LLI-based methods nichol2021glide ; avrahami2022blendedlatent ; ramesh2022hierarchical require the user to explicitly mask a part of the image to be inpainted, and drive the edited image to change in the masked area only, while matching the background of the original image. This approach has provided appealing results, however, the masking procedure is cumbersome, hampering quick and intuitive text-driven editing. Moreover, masking the image content removes important structural information, which is completely ignored in the inpainting process. Therefore, some editing capabilities are out of the inpainting scope, such as modifying the texture of a specific object.\n\n#### Yes their method did perform better than mask editing methods, as authors demonstrated by examples that their method is more intuitive for users using only prompt, and doesn't require to explicitly mask parts of the image which results to remove important structural information and doesn't modify complex structures information. And their work enables local or global modifications as well and besides their method doesn't require a training network.",
        "To alleviate this limitation, we propose to restore the unedited regions of the original image using a mask,\n\n#### Examples of inversion with prompts can be found in Figure12, where they used mask-based editing to limit inversion distortion.",
        "More formally, as illustrated in fig. 3(Top), the deep spatial features of the noisy image \\phi(z_{t}) are projected to a query matrix Q=\\ell_{Q}(\\phi(z_{t})), and the textual embedding is projected to a key matrix K=\\ell_{K}(\\psi(\\mathcal{P})) and a value matrix V=\\ell_{V}(\\psi(\\mathcal{P})), via learned linear projections \\ell_{Q},\\ell_{K},\\ell_{V}.The attention maps are thenM=\\text{Softmax}\\left(\\frac{QK^{T}}{\\sqrt{d}}\\right),(1)where the cell M_{ij} defines the weight of the value of the j-th token on the pixel i, and where d is the latent projection dimension of the keys and queries. Finally, the cross-attention output is defined to be \\widehat{\\phi}\\left(z_{t}\\right)=MV, which is then used to update the spatial features \\phi(z_{t}).\n\n#### True, It's correlated to the similarity between a query matrix of projected noisy image \"Q\" and a key matrix of a projected textual embedding \"K\".",
        "Image captioning, \\ie, generating fluent and meaningful descriptions to summarize the salient contents of an image, is a classic proxy task for comprehensive scene understanding [21]. With the release of several large scale datasets and advanced encoder-decoder frameworks, current captioning models plausibly have already achieved “super-human” performance in all accuracy-based evaluation metrics. However, many studies have indicated that these models tend to produce generic descriptions, and fail to control the caption generation process as humans, \\eg, referring to different contents of interest or descriptive patterns. In order to endow the captioning models with human-like controllability, a recent surge of efforts [16, 10, 19, 78, 48, 77, 27, 20] resort to introducing extra control signals as constraints of the generated captions, called Controllable Image Captioning (CIC). As a byproduct, the CIC models can easily generate diverse descriptions by feeding different control signals.\n\n#### control signal is designated by each author in their work. as the authors of this paper proposed a \"verb-specific semantic role\" \"VSR\" as control signal for customized captions. while a recent surge of efforts by other works introduced extra control signals as constrains of the generated captions [16, 10, 19, 78, 48, 77, 27, 20].",
        "Nevertheless, all existing objective control signals (\\ie, both content-controlled and structure-controlled) have overlooked two indispensable characteristics of an ideal control signal towards “human-like” controllable image captioning: 1) Event-compatible: all visual contents referred to in a single sentence should be compatible with the described activity. Imaging how humans describe images — our brains always quickly structure a descriptive pattern like “sth do sth at someplace” first, and then fill in the detailed description [56, 46, 30, 71], \\ie, we have subconsciously made sure that all the mentioned entities are event-compatible (\\eg, man, wave, surfboard are all involved in activity riding in Figure 1 (a)). To further see the negative impact of dissatisfying this requirement, suppose that we deliberately utilize two more objects (hand and sky, \\ie, ) as part of the control signal, and the model generates an incoherent and illogical caption. 2) Sample-suitable: the control signals should be suitable for the specific image sample. By “suitable”, we mean that there do exist reasonable descriptions satisfying the control signals, \\eg, a large length-level may not be suitable for an image with a very simple scene. Unfortunately, it is always very difficult to decide whether a control signal is sample-suitable in advance. For example in Figure 1 (b), although the two control signals (\\ie, length-levels 3 and 4) are quite close, the quality of respectively generated captions varies greatly.\n\n#### Figure 1 (a) and Figure 1 (b), are examples of two indispensable characteristics ideal control signal, as Figure 1 (a) elaborates the \"Event Compatibility\" characteristic as \"man, wave, surfboard\" are all involved in activity riding. and Figure 1 (b) elaborates the \"Sample-suitability\" characteristic as the two control signal (length-levels 3 and 4) are quite close, but the quality of respectively generated captions varies greatly.",
        "Given the semantic structure sequence \\mathcal{S}=(s^{b}_{1},...,s^{b}_{K}) and corresponding proposal feature sequence \\mathcal{R}=(\\bm{r}_{1},...,\\bm{r}_{K}), we utilize a two-layer LSTM to generate the final caption \\bm{y}. At each time step, the model fouces on one specific sub-role \\bm{s}^{b}_{t} and its grounded region set \\bm{r}_{t}, and then generates the word y_{t}. Therefore, we take inspirations from previous CIC methods [16, 10], and predict two distributions simultaneously: p(g_{t}|\\mathcal{S},\\mathcal{R}) for controlling the shift of sub-roles, and p(y_{t}|\\mathcal{S},\\mathcal{R}) to predict the distribution of a word.\n\n#### By using RNN-based-role-shift caption model consists of two LSTM layers. the model generates the word \"yt\", by taking two inputs to the model which are 1- Semantic structure sequence, and 2- corresponding proposal feature sequence. then at each time step the model focus on one specific sub-role and its grounded region set.",
        "Settings. To evaluate the controllability of proposed framework, we followed the conventions of prior CIC works [16, 10, 78], and utilized the VSR aligned with ground truth captions as the control signals. Specifically, we compared the proposed framework with several carefully designed baselines666All baselines use the same visual regions as models with VSRs.: 1) C-LSTM: It is a Controllable LSTM model [63]. Given the features of all grounded visual regions, it first averages all region features, and then uses an LSTM to generate the captions. 2) C-UpDn: It is a Controllable UpDn model [3], which uses an adaptive attention to generate the captions. 3) SCT [16]: It regards the set of visual regions as a control signal, and utilizes a chunk-shift captioning model to generate the captions. 4) Ours w/o verb: We ablate our model by removing the verb information in both the SSP and captioning model. 5) Ours (oracle verb): It is an ideal situation, where the captioning model directly outputs the oracle format of the verb when the attending role is the verb.\n\n#### Authors verify their work using a conventions evaluation metrics in prior CIC works. As their quantitative results report in Table 1, you can observe that author's framework can achieve the best performance over almost all metrics and benchmarks. and as for the visualized evaluation, you can observe in Figure 5 that the author's framework always learns a human-like semantic structure based on the VSR and grounded visual regions. and according to the semantic structures, the captioning model can generate near-perfect descriptions.",
        "Image captioning, \\ie, generating fluent and meaningful descriptions to summarize the salient contents of an image, is a classic proxy task for comprehensive scene understanding [21]. With the release of several large scale datasets and advanced encoder-decoder frameworks, current captioning models plausibly have already achieved “super-human” performance in all accuracy-based evaluation metrics. However, many studies have indicated that these models tend to produce generic descriptions, and fail to control the caption generation process as humans, \\eg, referring to different contents of interest or descriptive patterns. In order to endow the captioning models with human-like controllability, a recent surge of efforts [16, 10, 19, 78, 48, 77, 27, 20] resort to introducing extra control signals as constraints of the generated captions, called Controllable Image Captioning (CIC). As a byproduct, the CIC models can easily generate diverse descriptions by feeding different control signals.\n\n#### No, as it doesn't affect training, and it's more of an input to model, as you can generate a diversity of captions by feeding the model different control signals.",
        "Early CIC works mainly focus on subjective control signals, such as sentiments [41], emotions [42, 22], and personality [14, 54], \\ie, the linguistic styles of sentences. Although these stylized captioning models can eventually produce style-related captions, they remain hard to control the generation process effectively and precisely. To further improve the controllability, recent CIC works gradually put a more emphasis on objective control signals. More specifically, they can be coarsely classified into two categories: 1) Content-controlled: the control signals are about the contents of interest which need to be described. As the example shown in Figure 1 (a), given the region set () as a control signal, we hope that the generated caption can cover all regions (\\ie, man, wave, and surfboard). So far, various types of content-controlled signals have been proposed, such as visual relations [27], object regions [16, 35], scene graphs [10, 78], and mouse trace [48]. 2) Structure-controlled: the control signals are about the semantic structures of sentences. For instance, the length-level [19], part-of-speech tags [20], or attributes [79] of the sentence (cf. Figure 1 (b)) are some typical structure-controlled signals.\n\n#### Subjective control signals are harder to control the generation process effectively and precisely.",
        "Nevertheless, all existing objective control signals (\\ie, both content-controlled and structure-controlled) have overlooked two indispensable characteristics of an ideal control signal towards “human-like” controllable image captioning: 1) Event-compatible: all visual contents referred to in a single sentence should be compatible with the described activity. Imaging how humans describe images — our brains always quickly structure a descriptive pattern like “sth do sth at someplace” first, and then fill in the detailed description [56, 46, 30, 71], \\ie, we have subconsciously made sure that all the mentioned entities are event-compatible (\\eg, man, wave, surfboard are all involved in activity riding in Figure 1 (a)). To further see the negative impact of dissatisfying this requirement, suppose that we deliberately utilize two more objects (hand and sky, \\ie, ) as part of the control signal, and the model generates an incoherent and illogical caption. 2) Sample-suitable: the control signals should be suitable for the specific image sample. By “suitable”, we mean that there do exist reasonable descriptions satisfying the control signals, \\eg, a large length-level may not be suitable for an image with a very simple scene. Unfortunately, it is always very difficult to decide whether a control signal is sample-suitable in advance. For example in Figure 1 (b), although the two control signals (\\ie, length-levels 3 and 4) are quite close, the quality of respectively generated captions varies greatly.\n\n#### Because it must be a reasonable description for the specific image sample. however, can't elaborate more details as authors didn't elaborate more about the specific reason for it in this paper.",
        "Evaluation Metrics. To evaluate the quality of the generated captions, we use five accuracy-based metrics, including BLEU-4 (B4) [45], METEOR (M) [5], ROUGE (R) [34], CIDEr-D (C) [61], and SPICE (S) [2]. Particularly, we evaluate the generated captions against the single ground truth caption. We also propose a new recall-based metric to evaluate whether the roles of the generated sentence are consistent with the ground truth caption (\\ie, VSR). It measures the recall rate of the verb, semantic roles, and ordered role pairs, which are denoted as R{}_{\\text{V}}, R{}_{\\text{SR1}} and R{}_{\\text{SR2}}, respectively.\n\n#### Authors used BlEU, METOR, ROUGE, CIDEr, and SPICE to evaluate quality based generated captions, And used Accuracy-based,  Diversity-based metrics to evaluate diversity based generation captions.",
        "R-level SSP. The role-level (R-level) SSP is a fine-grained structure model which aims to rank all sub-roles within the same semantic role (\\eg, LOC-1 and LOC-2 are two sub-roles of role Loc in Figure 3). Since the only differences among these sub-roles are the grounded visual regions, we borrow ideas from the Sinkhorn networks [43, 16], which use a differentiable Sinkhorn operation to learn a soft permutation matrix \\bm{P}. Specifically, for each role s_{i} with multiple sub-roles (\\ie, n_{i}>1), we first select all the corresponding grounded proposal sets for these sub-roles, denoted as \\mathcal{\\hat{B}}=\\{\\mathcal{\\hat{B}}_{1},...,\\mathcal{\\hat{B}}_{n_{i}}\\}. And for each proposal \\bm{b}_{*}\\in\\mathcal{\\hat{B}}, we encode a feature vector \\bm{z}_{*}=[\\bm{z}^{v}_{*};\\bm{z}^{s_{i}}_{*};\\bm{z}^{l}_{*}], where \\bm{z}^{v}_{*} is a transformation of its visual feature \\bm{f}_{*}, \\bm{z}^{s_{i}}_{*} is the word embedding feature of the semantic role s_{i}, and \\bm{z}^{l}_{*} is a 4-d encoding of the spatial position of proposal \\bm{b}_{*}. Then, we transform each feature \\bm{z}_{*} into n_{i}-d, and average-pooled all features among the same proposal set, \\ie, we can obtain an n_{i}-d feature for each \\mathcal{\\hat{B}}_{i}. We concatenate all these features to get an n_{i}\\times n_{i} matrix \\bm{Z}. Finally, we use the Sinkhorn operation to obtain the soft permutation matrix \\bm{P}4:\\displaystyle\\bm{P}=\\text{Sinkhorn}(\\bm{Z}).(6)\n\n#### LOC-1 and LOC-2 in Figure 3.",
        "Further, we utilize two sequences \\mathcal{S}=(s^{b}_{1},...,s^{b}_{K}) and \\mathcal{R}=(\\bm{r}_{1},...,\\bm{r}_{K}) to model the descriptive patterns. Specifically, \\mathcal{S} is a semantic structure of the sentence and each s^{b}_{i}\\in\\mathcal{S} is a sub-role. By “sub-role”, we mean that each role s_{i}\\in\\mathcal{VSR} can be divided into n_{i} sub-roles, and when n_{i}=1, role s_{i} itself is a sub-role. Thus, VSR in Figure 3 can be rewritten as Arg0, Arg1, LOC-1, and LOC-2. \\mathcal{R} is a sequence of visual features of the corresponding grounded entities for each sub-role in \\mathcal{S} (\\eg, \\bm{r}_{i} is the features of visual regions referring to s^{b}_{i}). Particularly, for presentation conciseness, we regard the verb in \\mathcal{VSR} as a special type of sub-role, and since there are no grounded visual regions referring to the verb, we use the global image feature as the grounded region feature in \\mathcal{R}. Meanwhile, we use \\mathcal{\\tilde{R}} to denote a set of all elements in the sequence \\mathcal{R}. Thus, we further decompose this task into three components:\\displaystyle p(\\bm{y}|\\bm{I},\\mathcal{VSR})=\\underbrace{p(\\bm{y}|\\mathcal{S},\\mathcal{R})}_{\\text{Captioner}}\\underbrace{p(\\mathcal{S},\\mathcal{R}|\\mathcal{\\tilde{R}},\\mathcal{VSR})}_{\\text{SSP}}\\underbrace{p(\\mathcal{\\tilde{R}}|\\bm{I},\\mathcal{VSR})}_{\\text{GSRL}}.(3)\n\n#### ^b refer to a sub-role in the semantic structure of the sentence. as S is the semantic structure of the sentence, i is specific to a number of sub-role of a sequence of sub-roles in the semantic structure of a sentence. and ^b is a general sub-role.",
        "Given an image \\bm{I}, we first utilize an object detector [50] to extract a set of object proposals \\mathcal{B}. Each proposal \\bm{b}_{i}\\in\\mathcal{B} is associated with a visual feature \\bm{f}_{i} and a class label c_{i}\\in\\mathcal{C}. Then, we group all these proposals into N disjoint sets, \\ie, \\mathcal{B}=\\{\\mathcal{B}_{1},...,\\mathcal{B}_{N}\\}333Due to different annotation natures of specific CIC datasets, we group proposals by different principles. Details are shown in Section 4.2., and each proposal set \\mathcal{B}_{i} consists of one or more proposals. In this GSRL step, we need to refer each sub-role in the \\mathcal{VSR} to a proposal set in \\mathcal{B}. Specifically, we calculate the similarity score a_{ij} between semantic role s_{i} and proposal set \\mathcal{B}_{j} by:\\displaystyle\\bm{q}_{i}=\\left[\\bm{e}^{g}_{v};\\bm{e}^{g}_{s_{i}};\\bm{\\bar{f}}\\right],\\quad a_{ij}=F_{a}(\\bm{q}_{i},\\bm{\\bar{f}_{j}}),(4)where \\bm{e}^{g}_{v} and \\bm{e}^{g}_{s_{i}} are the word embedding features of verb v and semantic role s_{i}, \\bm{\\bar{f}} and \\bm{\\bar{f}_{j}} represent the average-pooled visual features of proposal set \\mathcal{B} and \\mathcal{B}_{j}, [;] is a concatenation operation, and F_{a} is a learnable similarity function444For conciseness, we leave the details in the supplementary material. .\n\n#### A set of object proposals is extracted with an object detector from an image. as authors utilized a Faster R-NN with ResNet-101 to obtain all proposals for each image. noting that for COCO Entities, authors group the proposals by their detected class labels, and for FLickr30K Entities, they directly regard each proposal as a proposal set.",
        "Early CIC works mainly focus on subjective control signals, such as sentiments [41], emotions [42, 22], and personality [14, 54], \\ie, the linguistic styles of sentences. Although these stylized captioning models can eventually produce style-related captions, they remain hard to control the generation process effectively and precisely. To further improve the controllability, recent CIC works gradually put a more emphasis on objective control signals. More specifically, they can be coarsely classified into two categories: 1) Content-controlled: the control signals are about the contents of interest which need to be described. As the example shown in Figure 1 (a), given the region set () as a control signal, we hope that the generated caption can cover all regions (\\ie, man, wave, and surfboard). So far, various types of content-controlled signals have been proposed, such as visual relations [27], object regions [16, 35], scene graphs [10, 78], and mouse trace [48]. 2) Structure-controlled: the control signals are about the semantic structures of sentences. For instance, the length-level [19], part-of-speech tags [20], or attributes [79] of the sentence (cf. Figure 1 (b)) are some typical structure-controlled signals.\n\n#### Objective control signal, and Objective control singals types are the only type mentioned in this paper. thereby can't give a full answer within this paper information.",
        "We use beam search during decoding to find the sequence Ythat maximizes a score function s(Y,X) given a trained model. Weintroduce two important refinements to the pure max-probability based beamsearch algorithm: a coverage penalty [42] and lengthnormalization. With length normalization, we aim to account for thefact that we have to compare hypotheses of different length. Withoutsome form of length-normalization regular beam search will favorshorter results over longer ones on average since a negativelog-probability is added at each step, yielding lower (more negative) scores forlonger sentences. We first tried to simply divideby the length to normalize. We then improved on that original heuristic by dividing bylength^{\\alpha}, with 0<\\alpha<1 where \\alpha is optimized ona development set (\\alpha\\in[0.6-0.7] was usually found to bebest). Eventually we designed the empirically-better scoring functionbelow, which also includes a coverage penalty to favor translationsthat fully cover the source sentence according to the attentionmodule.\n\n#### Yes, Authors found that \"α\" which represents the strength of length normalization and \"β\" which represents coverage penalty are less effective for models with RLrefinment, and improved the original heuristic  by dividing length to the power of α with 0 < α < 1 where α ∈ [0.6 − 0.7] on development set which usually found to be best.",
        "Model parallelism places certain constraints on the modelarchitectures we can use. For example, we cannot afford to havebi-directional LSTM layers for all the encoder layers, since doing sowould reduce parallelism among subsequent layers, as each layer wouldhave to wait until both forward and backward directions of the previouslayer have finished. This would effectively constrain us to make use ofonly 2 GPUs in parallel (one for the forward direction and one for thebackward direction). For the attention portion of the model, we chose to align thebottom decoder output to the top encoder output to maximizeparallelism when running the decoder network. Had we aligned the top decoderlayer to the top encoder layer, we would have removed all parallelismin the decoder network and would not benefit from using more than oneGPU for decoding.\n\n#### First we have to establish that LSTM layers reduces parallelism as each layer would have to wait until both forward and backward directions of the previous layer to finish. Then notice in Figure 1, the model architecture consists of 8 LSTM encoder layers (1 bi-directional and 7 uni-directional layers), and 8 decoder layers. During training the bottom bi-directional encoder layers compute in parallelism first, then the uni-directional encoder layers. So to retain retain and much possible parallelism during the decoder layers, the bottom layers of the decoder output only for obtaining the recurrent attention context which is sent directly to all the remaining decoder layers.",
        "Table 2 shows the impact of \\alpha and \\beta onthe BLEU score when decoding the WMT’14 English-to-French development set.The model used here for experiments is trained using the ML objectiveonly (without RL refinement). As can be seen from the results, havingsome length normalization and coverage penalty improves BLEU scoreconsiderably (from 30.3 to 31.4).\n\n#### It was found that models with RL refinement are less affected by length normalization \"α\" and coverage penalty \"β\", authors explain this to the fact that during RL refinement, models already learn to pay attention to the full source sentence to not under-translate or over-translate. The authors also found an overlap between the wins from RL refinement and decoder fine-tuning, and the win from RL on a less fine-tuned decoder would have been bigger. The impact of length normalization \"α\" and coverage penalty \"β\" on RL-based and non-RL-based models can be found in Tables 2 and 3.",
        "Neural Machine Translation(NMT) [41, 2] has recently beenintroduced as a promising approach with the potential of addressingmany shortcomings of traditional machine translation systems.The strength of NMT lies in its ability to learn directly, in anend-to-end fashion, the mapping from input text to associated output text.Its architecture typically consists of two recurrent neural networks (RNNs), oneto consume the input text sequence and one to generate translated output text.NMT is often accompanied by an attention mechanism [2]which helps it cope effectively with long input sequences.\n\n#### The weakness of conventional phrase-based translation systems over Neural Machine Translation are their brittle design choices especially when it's trained on very large-scale datasets, large scale, production quality and it lacks the ability to learn directly in an end-to-end fashion.",
        "This work presents the design and implementation of GNMT, a production NMTsystem at Google, that aims toprovide solutions to the above problems. In our implementation, therecurrent networks are Long Short-Term Memory (LSTM)RNNs [23, 17]. Our LSTM RNNs have 8layers, with residual connections between layers to encourage gradientflow [21]. For parallelism, we connect the attention fromthe bottom layer of the decoder network to the top layer of theencoder network. To improve inference time, we employ low-precisionarithmetic for inference, which is further accelerated by specialhardware (Google’s Tensor Processing Unit, or TPU). To effectivelydeal with rare words, we use sub-word units (also known as“wordpieces”) [35] for inputs and outputs inour system. Using wordpieces gives a good balance between theflexibility of single characters and the efficiency of full words fordecoding, and also sidesteps the need for special treatment of unknownwords. Our beam search technique includes a length normalization procedure todeal efficiently with the problem of comparing hypotheses of differentlengths during decoding, and a coverage penalty to encourage the modelto translate all of the provided input.\n\n#### Attentions connections improve parallelism allowing to decrease training time and allows the decoder to focus on different regions of the source sentence.",
        "A second approach we use is the mixed word/character model.As in a word model, we keep a fixed-size word vocabulary.However, unlike in a conventional word model where OOV words are collapsedinto a single UNK symbol, we convert OOV words into the sequence of itsconstituent characters.Special prefixes are prepended to the characters, to 1) show the location ofthe characters in a word, and 2) to distinguish them from normal in-vocabularycharacters. There are threeprefixes: <B>,<M>, and <E>, indicating beginning of the word, middleof the word and end of the word, respectively. For example, let’s assume theword Miki is not in the vocabulary. It will be preprocessed into asequence of special tokens: <B>M <M>i <M>k <E>i. The process isdone on both the source and the target sentences. During decoding, theoutput may also contain sequences of special tokens. With theprefixes, it is trivial to reverse the tokenization to the original words aspart of a post-processing step.\n\n#### character-delimited models takes characters as input and outputs characters, the words spitted into constituent characters, resulting typically in a few hundred basic characters including special characters appeared in the data. While in word-delimited models OOv words are collapsed into a single UNK symbols.",
        "Wordpieces achieve a balance between the flexibility of characters andefficiency of words.We also find that our models get better overall BLEU scores when usingwordpieces – possibly due to the fact that our models now dealefficiently with an essentially infinite vocabulary without resorting tocharacters only. The latter would make the average lengths of the input and outputsequences much longer, and therefore would require more computation.\n\n#### Authors assume that's due to the fact that it deals efficiently with an essentially infinite vocabulary without restoring to characters only.",
        "Our beam search technique includes a length normalization procedure to deal efficiently with the problem of comparing hypotheses of different lengths during decoding, and a coverage penalty to encourage the model to translate all of the provided input.\n\n#### Authors implemented a coverage penalty to encourage the model to translate all of the provided input, however, it's not clear why sometimes NMT systems fail to translate all parts of the input.",
        "In this section, we present our approach to speed up inference withquantized arithmetic. Our solution is tailored towards the hardwareoptions available at Google. To reduce quantization errors, additionalconstraints are added to our model during training so that it is quantizablewith minimal impact on the output of the model. That is, once amodel is trained with these additional constraints, it can be subsequentlyquantized without loss to translation quality. Our experimental results suggestthat those additional constraints do not hurt model convergence nor the qualityof a model once it has converged.\n\n#### Quantization models can perform slightly have lower results on neural network models, however in this paper authors performed some constraints during training so that's quantizable with minimal impact on the output of the model, the quantized model even performed slightly better than none-quantized training and they suggest it could be due to regularization roles those constraints had during training.",
        "Our attention module is similar to [2]. Morespecifically, let \\mathbf{y}_{i-1} be the decoder-RNN output fromthe past decoding time step (in our implementation, we use the output fromthe bottom decoder layer). Attention context \\mathbf{a}_{i}for the current time step is computed according to the following formulas:st=A⁢t⁢t⁢e⁢n⁢t⁢i⁢o⁢n⁢F⁢u⁢n⁢c⁢t⁢i⁢o⁢n⁢(𝐲i−1,𝐱t)∀t,1≤t≤Mpt=exp⁡(st)/∑t=1Mexp⁡(st)∀t,1≤t≤M𝐚i=∑t=1Mpt.𝐱t\\begin{split}s_{t}&=AttentionFunction(\\mathbf{y}_{i-1},\\mathbf{x}_{t})\\quad\\forall t,\\quad 1\\leq t\\leq M\\\\p_{t}&=\\exp(s_{t})/\\sum_{t=1}^{M}\\exp(s_{t})\\quad\\quad\\forall t,\\quad 1\\leq t\\leq M\\\\\\mathbf{a}_{i}&=\\sum_{t=1}^{M}p_{t}.\\mathbf{x}_{t}\\end{split}start_ROW start_CELL italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_CELL start_CELL = italic_A italic_t italic_t italic_e italic_n italic_t italic_i italic_o italic_n italic_F italic_u italic_n italic_c italic_t italic_i italic_o italic_n ( bold_y start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ∀ italic_t , 1 ≤ italic_t ≤ italic_M end_CELL end_ROW start_ROW start_CELL italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_CELL start_CELL = roman_exp ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) / ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT roman_exp ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ∀ italic_t , 1 ≤ italic_t ≤ italic_M end_CELL end_ROW start_ROW start_CELL bold_a start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_CELL start_CELL = ∑ start_POSTSUBSCRIPT italic_t = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT . bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_CELL end_ROW(4)where AttentionFunction in our implementation is a feed forward network withone hidden layer.\n\n#### Authors used only the decoder-RNN output from the past decoding time step in the bottom decoder layer to obtain recurrent attention context which is sent directly to all the remaining decoder layers.",
        "This work presents the design and implementation of GNMT, a production NMTsystem at Google, that aims toprovide solutions to the above problems. In our implementation, therecurrent networks are Long Short-Term Memory (LSTM)RNNs [23, 17]. Our LSTM RNNs have 8layers, with residual connections between layers to encourage gradientflow [21]. For parallelism, we connect the attention fromthe bottom layer of the decoder network to the top layer of theencoder network. To improve inference time, we employ low-precisionarithmetic for inference, which is further accelerated by specialhardware (Google’s Tensor Processing Unit, or TPU). To effectivelydeal with rare words, we use sub-word units (also known as“wordpieces”) [35] for inputs and outputs inour system. Using wordpieces gives a good balance between theflexibility of single characters and the efficiency of full words fordecoding, and also sidesteps the need for special treatment of unknownwords. Our beam search technique includes a length normalization procedure todeal efficiently with the problem of comparing hypotheses of differentlengths during decoding, and a coverage penalty to encourage the modelto translate all of the provided input.\n\n#### Authors used 8 LSTM layers for the encoder, and 8 LSTM layers for the decoder with residual connections for both networks, each layer has 1024 node. though it's not very clear how many residual connections are but a possible answer is 16384.",
        "Our most successful approach falls into the second category (sub-word units), and weadopt the wordpiece model (WPM) implementation initially developed tosolve a Japanese/Korean segmentation problem for the Google speechrecognition system [35]. This approach is completelydata-driven and guaranteed to generate a deterministic segmentationfor any possible sequence of characters. It is similar tothe method used in [38] to deal with rare words inNeural Machine Translation.\n\n#### Yes, the word piece model was initially developed to solve a Japanese/Korean segmentation problem.",
        "The wordpiece model is generated using a data-driven approach tomaximize the language-model likelihood of the training data, given anevolving word definition. Given a training corpus and a number ofdesired tokens D, the optimization problem is to select Dwordpieces such that the resulting corpus is minimal in the number ofwordpieces when segmented according to the chosen wordpiece model. Ourgreedy algorithm to this optimization problem is similarto [38] and is described in more detail in[35]. Compared to the original implementation used in[35], we use a special symbol only at thebeginning of the words and not at both ends. We also cut the numberof basic characters to a manageable number depending on the data(roughly 500 for Western languages, more for Asian languages) and mapthe rest to a special unknown character to avoid polluting the givenwordpiece vocabulary with very rare characters. We find that using a total vocabulary of between 8k and 32k wordpieces achievesboth good accuracy (BLEU scores) and fast decodingspeed across all pairs of language pairs we have tried.\n\n#### The number of basic characters depends on the data, and the answer to this question is not within the limit of this paper.",
        "Given a dataset of parallel text containing N input-output sequencepairs, denoted \\mathcal{D}\\equiv\\left\\{(X^{(i)},Y^{*(i)})\\right\\}_{i=1}^{N},standard maximum-likelihood training aims at maximizing the sum of logprobabilities of the ground-truth outputs given the correspondinginputs,\\mathcal{O}_{\\mathrm{ML}}(\\bm{\\mathbf{\\theta}})=\\sum_{i=1}^{N}\\log{P}_{\\theta}(Y^{*(i)}\\mid X^{(i)})~{}.(7)The main problem with this objective is that it does not reflect thetask reward function as measured by the BLEU score in translation. Further,this objective does not explicitly encourage a ranking among incorrectoutput sequences – where outputs with higher BLEU scores should still obtainhigher probabilities under the model – since incorrect outputs are neverobserved during training. In other words, using maximum-likelihoodtraining only, the model will not learn to be robust to errors made duringdecoding since they are never observed, which is quite a mismatch betweenthe training and testing procedure.\n\n#### Yes, author's concerns are translation tasks.",
        "Recall from equation 6 that in an LSTM stackwith residual connections there are two accumulators: \\mathbf{c}_{t}^{i}along the time axis and \\mathbf{x}_{t}^{i} along the depth axis. Intheory, both of the accumulators are unbounded, but in practice, wenoticed their values remain quite small. For quantized inference, weexplicitly constrain the values of these accumulators to be within[-\\delta, \\delta] to guarantee a certain range that can be used forquantization later. The forward computation of an LSTM stack withresidual connections is modified to the following:\n\n#### Yes it's hyper-parameter, as it's within fixed range during training noting that it's fixed within this range during inference.",
        "\\begin{split}\\mathbf{v_{t}}&=\\mathbf{W_{s}}*\\mathbf{y_{t}}\\\\\\mathbf{v_{t}^{\\prime}}&=\\max(-\\gamma,\\min(\\gamma,\\mathbf{v_{t}}))\\\\\\mathbf{p_{t}}&=softmax(\\mathbf{v_{t}^{\\prime}})\\end{split}(13)In equation 13, \\mathbf{W_{s}} is the weightmatrix for the linear layer, which has the same number of rows as thenumber of symbols in the target vocabulary with each row correspondingto one unique target symbol. \\mathbf{v} represents the raw logits, which arefirst clipped to be between -\\gamma and \\gamma and then normalizedinto a probability vector \\mathbf{p}. Input \\mathbf{y_{t}} isguaranteed to be between -\\delta and \\delta due to thequantization scheme we applied to the decoder RNN. The clipping range\\gamma for the logits \\mathbf{v} is determined empirically, and inour case, it is set to 25. In quantized inference, the weight matrix\\mathbf{W_{s}} is quantized into 8 bits as inequation 12, and the matrix multiplication is done using8 bit arithmetic. The calculations within the softmax function and theattention model are not quantized during inference.\n\n#### Yes they are separated, as [-δ,δ] is a clipping range to input yt while [−γ, γ] is the clipping range for raw logits.",
        "Neural Machine Translation (NMT) achieved state-of-the-art performances in large-scale translation tasks such as from English to French (Luong et al., 2015) and English to German (Jean et al., 2015). NMT is appealing since it requires minimal domain knowledge and is conceptually simple. The model by Luong et al. (2015) reads through all the source words until the end-of-sentence symbol <eos> is reached. It then starts emitting one target word at a time, as illustrated in Figure 1.\n\n#### Authors refer to translation domain knowledge, as they refer to Luong's et al. (2015) Neural Machine Translation as it reads through all source words until the end of a sentence, then starts translation by emitting one target word at a time as illustrated in Figure 1.",
        "Neural Machine Translation (NMT) achieved state-of-the-art performances inlarge-scale translation tasks such as from English to French [Luong et al., 2015] andEnglish to German [Jean et al., 2015]. NMT is appealing since it requires minimaldomain knowledge and is conceptually simple. The model by ?) reads through all the source words until the end-of-sentence symbol <eos> is reached. It then starts emitting one target word at a time, as illustrated in Figure 1. NMT is often a large neural network that is trained in an end-to-end fashion and has the ability to generalize well to very long word sequences. This means the model does not have to explicitly store gigantic phrase tables and language models as in the case of standard MT; hence, NMT has a small memory footprint. Lastly, implementing NMT decoders is easy unlike the highly intricate decoders in standard MT [Koehn et al., 2003].\n\n#### Large Neural network NMT has the ability to generalize well to very long word sequences so that it doesn't have to store gigantic phrase tables and language models, which results to having a small memory footprint.",
        "The global attention has a drawback that it has to attend to all words on thesource side for each target word, which is expensive and can potentially render it impractical totranslate longer sequences, e.g., paragraphs or documents.To address this deficiency, we propose a local attentional mechanism thatchooses to focus only on a small subset of the source positions per target word.\n\n#### A drawback of the global attention is it had to attend to all words on the source side for each target word, which is expensive and potentially will render it impractical to translate longer sequences, and despite that global attention gives a significant boost of +2.8 BLEU making it better than the base attention system, but the local approach gave further improvement of +0.9 BLEU on top of the global attention model. Also the local approach achieved lower AERs. Not to mention that the local approach is simpler, easier to implement and train, and computationally less expensive. as it focus only on a small subset of the source positions per target word.",
        "This model takes inspiration from the tradeoff between the soft and hard attentional models proposed by ?) to tackle the image captiongeneration task. In their work, soft attention refers to the global attentionapproach in which weights are placed “softly” over all patches in the sourceimage. The hard attention, on the other hand, selects one patchof the image to attend to at a time. While less expensive at inference time, thehard attention model is non-differentiable and requires more complicatedtechniques such as variance reduction or reinforcement learning to train.\n\n#### Soft attention model's weights are placed \"softly\" over all patches in the source image. while Hard attention models selects one patch of the image to attend at a time. it's also, none-differentiable, requires more complicated techniques and less expensive at inference time.",
        "We examine different attention models (global, local-m, local-p) and differentalignment functions (location, dot, general, concat) as described inSection 3. Due to limitedresources, we cannot run all the possible combinations.However, results in Table 4 do give us some idea aboutdifferent choices.The location-based function does not learn goodalignments: the global (location) model can only obtain a smallgain when performing unknown word replacement compared to using other alignmentfunctions.141414There is a subtle difference in how we retrieve alignmentsfor the different alignment functions. At time step t in which we receivey_{t-1} as input and then compute \\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$a$}}_{t},\\mbox{\\boldmath{$c$}}_{t}, and \\mbox{\\boldmath{$\\tilde{h}$}}_{t} beforepredicting y_{t}, the alignment vector \\mbox{\\boldmath{$a$}}_{t} is used as alignmentweights for (a) the predicted word y_{t} in the location-basedalignment functions and (b) the input word y_{t-1} in the content-basedfunctions.For content-based functions, our implementation concat does not yield good performancesand more analysis should be done to understand thereason.151515With concat, the perplexities achieved by different models are 6.7 (global), 7.1(local-m), and 7.1 (local-p). Such high perplexities could be due to the factthat we simplify the matrix W_{a} to set the part that corresponds to \\mbox{\\boldmath{$\\bar{h}$}}_{s}to identity. It is interesting to observe that dot workswell for the global attention and general is better for the localattention.Among the different models, the local attention model with predictive alignments (local-p) is best, both in terms of perplexities and BLEU.\n\n#### Authors used location, dot, general and concat alignment functions in their experiments.",
        "Common to these two types of models is the fact that at each time step t in the decoding phase, both approaches first take as input the hidden state \\mbox{\\boldmath{$h$}}_{t} at the top layer of a stacking LSTM. The goal is then to derive a context vector \\mbox{\\boldmath{$c$}}_{t} that captures relevant source-side information to help predict the current target word y_{t}. While these models differ in how the context vector \\mbox{\\boldmath{$c$}}_{t} is derived, they share the same subsequent steps.\n\n#### Previous work included vanilla RNN, LSTM and GRU in the decoder architecture. as Sutskever and Luon stacked multiple layers of RNN with LSTM hidden unit for the decoder and encoder. and Cho, Bahdanau and Jeal all adopted GRU.",
        "?) used an RNN with the standard hidden unit for the decoder and aconvolutional neural network for encoding the source sentence representation. Onthe other hand, both ?) and ?) stackedmultiple layers of an RNN with a Long Short-Term Memory (LSTM) hidden unit forboth the encoder and the decoder. ?), ?), and?) all adopted a different version of the RNN with anLSTM-inspired hidden unit, the gated recurrent unit (GRU), for bothcomponents.444They all used a single RNN layer except for the latter twoworks which utilized a bidirectional RNN for the encoder.\n\n#### Kalchbrenner and Blunsom used a standard RNN hidden unit for the decoder. and Sutskever and Luong stacked multiple layers of RNN with Long Short-Term Memory (LSTM) hidden unit for the encoder and the decoder. on the other hand, Cho, Bahdanau and Jean all adopted different RNN architecture, with Gated Recurrent Unit (GRU) for encoder and decoder.",
        "The idea of a global attentional model is to consider all the hidden states ofthe encoder when deriving the context vector c_{t}. In this model type, avariable-length alignment vector \\mbox{\\boldmath{$a$}}_{t}, whose size equals the number of timesteps on the source side, is derived by comparing the current target hiddenstate \\mbox{\\boldmath{$h$}}_{t} with each source hidden state \\mbox{\\boldmath{$\\bar{h}$}}_{s}:\\displaystyle\\mbox{\\boldmath{$a$}}_{t}(s)\\displaystyle=\\operatorname{align}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s})(7)\\displaystyle=\\frac{\\exp\\left(\\operatorname{score}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s})\\right)}{\\sum_{s^{\\prime}}\\exp\\left(\\operatorname{score}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s^{\\prime}})\\right)}Here, \\operatorname{score} is referred as a content-based function for which we consider three differentalternatives:\\operatorname{score}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s})\\!=\\!\\begin{cases}\\mbox{\\boldmath{$h$}}_{t}^{\\top}\\mbox{\\boldmath{$\\bar{h}$}}_{s}&\\mbox{{\\it dot}}\\\\\\mbox{\\boldmath{$h$}}_{t}^{\\top}\\mbox{\\boldmath{$W_{a}$}}\\mbox{\\boldmath{$\\bar{h}$}}_{s}&\\mbox{{\\it general}}\\\\\\mbox{\\boldmath{$v$}}_{a}^{\\top}\\tanh\\left(\\mbox{\\boldmath{$W_{a}$}}[\\mbox{\\boldmath{$h$}}_{t};\\mbox{\\boldmath{$\\bar{h}$}}_{s}]\\right)&\\mbox{{\\it concat}}\\end{cases}\n\n#### A possible answer is yes as a global attention model considers all the hidden states of the encoder when deriving the context. However, it's not clear which sentence the questioner refers to and the question needs more elaboration.",
        "The idea of a global attentional model is to consider all the hidden states ofthe encoder when deriving the context vector c_{t}. In this model type, avariable-length alignment vector \\mbox{\\boldmath{$a$}}_{t}, whose size equals the number of timesteps on the source side, is derived by comparing the current target hiddenstate \\mbox{\\boldmath{$h$}}_{t} with each source hidden state \\mbox{\\boldmath{$\\bar{h}$}}_{s}:\\displaystyle\\mbox{\\boldmath{$a$}}_{t}(s)\\displaystyle=\\operatorname{align}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s})(7)\\displaystyle=\\frac{\\exp\\left(\\operatorname{score}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s})\\right)}{\\sum_{s^{\\prime}}\\exp\\left(\\operatorname{score}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s^{\\prime}})\\right)}Here, \\operatorname{score} is referred as a content-based function for which we consider three differentalternatives:\\operatorname{score}(\\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$\\bar{h}$}}_{s})\\!=\\!\\begin{cases}\\mbox{\\boldmath{$h$}}_{t}^{\\top}\\mbox{\\boldmath{$\\bar{h}$}}_{s}&\\mbox{{\\it dot}}\\\\\\mbox{\\boldmath{$h$}}_{t}^{\\top}\\mbox{\\boldmath{$W_{a}$}}\\mbox{\\boldmath{$\\bar{h}$}}_{s}&\\mbox{{\\it general}}\\\\\\mbox{\\boldmath{$v$}}_{a}^{\\top}\\tanh\\left(\\mbox{\\boldmath{$W_{a}$}}[\\mbox{\\boldmath{$h$}}_{t};\\mbox{\\boldmath{$\\bar{h}$}}_{s}]\\right)&\\mbox{{\\it concat}}\\end{cases}\n\n#### a variable-length alignment is a vector derived by comparing the current target hidden state with each source hidden state, and the size of it equals the number of time steps on the source side as it's explained in Figure 2.",
        "Common to these two types of models is the fact that at each time step t in the decoding phase, both approaches first take as input the hidden state \\mbox{\\boldmath{$h$}}_{t} at the top layer of a stacking LSTM. The goal is then to derive a context vector \\mbox{\\boldmath{$c$}}_{t} that captures relevant source-side information to help predict the current target word y_{t}. While these models differ in how the context vector \\mbox{\\boldmath{$c$}}_{t} is derived, they share the same subsequent steps.\n\n#### To derive a context vector that captures relevant source-side informations that help predicting the current target word.",
        "This model takes inspiration from the tradeoff between the soft and hard attentional models proposed by ?) to tackle the image captiongeneration task. In their work, soft attention refers to the global attentionapproach in which weights are placed “softly” over all patches in the sourceimage. The hard attention, on the other hand, selects one patchof the image to attend to at a time. While less expensive at inference time, thehard attention model is non-differentiable and requires more complicatedtechniques such as variance reduction or reinforcement learning to train.\n\n#### Hard attention model selects patch of the image to attend at a time, however this question can't be fully answered within this paper limit.",
        "We evaluate the effectiveness of our models on the WMT translation tasks betweenEnglish and German in both directions. newstest2013 (3000 sentences) is used asa development set to select our hyperparameters. Translation performances arereported in case-sensitive BLEU [Papineni et al., 2002] on newstest2014 (2737 sentences) andnewstest2015 (2169 sentences). Following [Luong et al., 2015], we reporttranslation quality using two types of BLEU: (a) tokenized121212All texts are tokenized with tokenizer.perl and BLEUscores are computed with multi-bleu.perl. BLEU to be comparable withexisting NMT work and (b) NIST131313With the mteval-v13ascript as per WMT guideline. BLEU to be comparablewith WMT results.\n\n#### A tonkenized BLEU: all text are tokenized with tonkenizer.perl and BLEU scores are computed with multi-bleu.per. While NSIT BLEU: with meteval-v13a script as per WMT guideline. However a full detailed answer can't be answer within this paper limit.",
        "When training our NMT systems, following [Bahdanau et al., 2015, Jean et al., 2015], we filter outsentence pairs whose lengths exceed 50 words and shuffle mini-batches as weproceed. Our stacking LSTM models have 4 layers, each with 1000 cells, and1000-dimensional embeddings. We follow [Sutskever et al., 2014, Luong et al., 2015] in trainingNMT with similar settings: (a) our parameters are uniformly initialized in[-0.1,0.1], (b) we train for 10 epochs using plain SGD, (c) a simple learningrate schedule is employed – we start with a learning rate of 1; after 5 epochs,we begin to halve the learning rate every epoch, (d) our mini-batch size is 128,and (e) the normalized gradient is rescaled whenever its norm exceeds 5.Additionally, we also use dropout with probability 0.2 for our LSTMs as suggested by[Zaremba et al., 2015]. For dropout models, we train for 12 epochs and start halvingthe learning rate after 8 epochs. For localattention models, we empirically set the window size D=10.\n\n#### The author's model consists of 4 layers of LSTM, each has 100 cells, and 1000-dimensional embeddings. However, the authors didn't mention the number of parameters in their model to give more accurate answer.",
        "We follow [Bahdanau et al., 2015] to group sentences of similar lengths together andcompute a BLEU score per group. Figure 6 shows thatour attentional models are more effective than the non-attentional one inhandling long sentences: the quality does not degrade as sentencesbecome longer. Our best model (the blue + curve) outperforms all other systems in all length buckets.\n\n#### Author's model quality is more effective in handling long sentence as the quality doesn't degrade as sentences become longer. Noting that in Figure 6, only one more measurement point was taken after 40. Despite that, a full answer can't be given within the available information.",
        "We examine different attention models (global, local-m, local-p) and differentalignment functions (location, dot, general, concat) as described inSection 3. Due to limitedresources, we cannot run all the possible combinations.However, results in Table 4 do give us some idea aboutdifferent choices.The location-based function does not learn goodalignments: the global (location) model can only obtain a smallgain when performing unknown word replacement compared to using other alignmentfunctions.141414There is a subtle difference in how we retrieve alignmentsfor the different alignment functions. At time step t in which we receivey_{t-1} as input and then compute \\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$a$}}_{t},\\mbox{\\boldmath{$c$}}_{t}, and \\mbox{\\boldmath{$\\tilde{h}$}}_{t} beforepredicting y_{t}, the alignment vector \\mbox{\\boldmath{$a$}}_{t} is used as alignmentweights for (a) the predicted word y_{t} in the location-basedalignment functions and (b) the input word y_{t-1} in the content-basedfunctions.For content-based functions, our implementation concat does not yield good performancesand more analysis should be done to understand thereason.151515With concat, the perplexities achieved by different models are 6.7 (global), 7.1(local-m), and 7.1 (local-p). Such high perplexities could be due to the factthat we simplify the matrix W_{a} to set the part that corresponds to \\mbox{\\boldmath{$\\bar{h}$}}_{s}to identity. It is interesting to observe that dot workswell for the global attention and general is better for the localattention.Among the different models, the local attention model with predictive alignments (local-p) is best, both in terms of perplexities and BLEU.\n\n#### Authors thinks it's interesting to observe that \"dot\" works well for the global attention and \"general\" is better for local attention, however this question can't be answered within this paper information.",
        "We visualize the alignment weights produced by our different attention models in Figure 7. The visualization of the local attention model is much sharper than that of the global one. This contrast matches our expectation that local attention is designed to only focus on a subset of words each time.\n\n#### Local attention method had sharper alignment weights than global one, that's due to it's designed to only focus on a subset of words each time.",
        "We examine different attention models (global, local-m, local-p) and differentalignment functions (location, dot, general, concat) as described inSection 3. Due to limitedresources, we cannot run all the possible combinations.However, results in Table 4 do give us some idea aboutdifferent choices.The location-based function does not learn goodalignments: the global (location) model can only obtain a smallgain when performing unknown word replacement compared to using other alignmentfunctions.141414There is a subtle difference in how we retrieve alignmentsfor the different alignment functions. At time step t in which we receivey_{t-1} as input and then compute \\mbox{\\boldmath{$h$}}_{t},\\mbox{\\boldmath{$a$}}_{t},\\mbox{\\boldmath{$c$}}_{t}, and \\mbox{\\boldmath{$\\tilde{h}$}}_{t} beforepredicting y_{t}, the alignment vector \\mbox{\\boldmath{$a$}}_{t} is used as alignmentweights for (a) the predicted word y_{t} in the location-basedalignment functions and (b) the input word y_{t-1} in the content-basedfunctions.For content-based functions, our implementation concat does not yield good performancesand more analysis should be done to understand thereason.151515With concat, the perplexities achieved by different models are 6.7 (global), 7.1(local-m), and 7.1 (local-p). Such high perplexities could be due to the factthat we simplify the matrix W_{a} to set the part that corresponds to \\mbox{\\boldmath{$\\bar{h}$}}_{s}to identity. It is interesting to observe that dot workswell for the global attention and general is better for the localattention.Among the different models, the local attention model with predictive alignments (local-p) is best, both in terms of perplexities and BLEU.\n\n#### Yes, alignment functions refer to 4 distinct functions which are \"Location, dot, general and concat\".",
        "The Internet has fueled collecting billions of (alt-text, image) pairs from HTML pages (Schuhmann et al., 2022), enabling the recent breakthroughs in Text-to-Image (T2I) modeling. However, replicating this success for videos is limited since a similarly sized (text, video) dataset cannot be easily collected.It would be wasteful to train Text-to-Video (T2V) models from scratchwhen there already exist models that can generate images.Moreover, unsupervised learning enables networks to learn from orders of magnitude more data. This large quantity of data is important to learn representations of more subtle, less common concepts in the world. Unsupervised learning has long had great success in advancing the field of natural language processing (NLP) (Liu et al., 2019a; Brown et al., 2020). Models pre-trained this way yield considerably higher performance than when solely trained in a supervised manner.\n\n#### Unsupervised learning has long had great success in advancing the field of natural language processing (NLP) and this paper is inspired by these success. Thus the authors have confidence in adopting unsupervised learning in Text-to-Video domain.",
        "Inspired by these motivations, we propose Make-A-Video. Make-A-Video leverages T2I models to learn the correspondence between text and the visual world, and uses unsupervised learning on unlabeled (unpaired) video data, to learn realistic motion. Together, Make-A-Video generates videos from text without leveraging paired text-video data.\n\n#### Leveraging frame rate conditioning, authours enable an additional augmentation method to tackle the limited volume of available videos at training timee, and provides additional control on the generated video at inference time by a varying number of frames-per-second.",
        "Datasets.To train the image models, we use a 2.3B subset of the dataset from (Schuhmann et al., ) where the text is English. We filter out sample pairs with NSFW images 333We used this model: https://github.com/GantMan/nsfw_model, toxic words in the text, or images with a watermark probability larger than 0.5.We use WebVid-10M (Bain et al., 2021) and a 10M subset from HD-VILA-100M (Xue et al., 2022) 444These 100M clips are sourced from 3.1M videos. We randomly downloaded 3 clips per video to form our HD-VILA-10M subset. to train our video generation models.Note that only the videos (no aligned text) are used. The decoder \\operatorname{D}^{t} and the interpolation model is trained on WebVid-10M. \\operatorname{SR}_{l}^{t} is trained on both WebVid-10M and HD-VILA-10M.While prior work (Hong et al., 2022; Ho et al., 2022) have collected private text-video pairs for T2V generation, we use only public datasets (and no paired text for videos). We conduct automatic evaluation on UCF-101 (Soomro et al., 2012) and MSR-VTT (Xu et al., 2016) in a zero-shot setting.\n\n#### For a more thorough evaluation than existing literature in T2V, the authors collect an evaluation set from Amazon Mechanical Turk (AMT) that consists of 300 prompts and filtered out prompts that were incomplete, too abstract, or offensive and then identified 5 categories (animals, fantasy, people, nature and scenes, food and beverage) and selected prompts for these categories. It is used for zero-shot T2V human evaluation.",
        "Inspired by these motivations, we propose Make-A-Video. Make-A-Video leverages T2I models to learn the correspondence between text and the visual world, and uses unsupervised learning on unlabeled (unpaired) video data, to learn realistic motion. Together, Make-A-Video generates videos from text without leveraging paired text-video data.\n\n#### There is no alinged text and only the videos are used. The authors use only public datasets (and no paired text for videos). A text description describes an image frame in video so it has limitations to associate between text and phenomenon in video. It needs to depict more detailed stories, is left for future work. Moreover, for all of experiments they applied extrapolation network↑F with frame skip 5 to upsample a 16 frame video to 76 frames.",
        "The Internet has fueled collecting billions of (alt-text, image) pairs from HTML pages (Schuhmann et al., 2022), enabling the recent breakthroughs in Text-to-Image (T2I) modeling. However, replicating this success for videos is limited since a similarly sized (text, video) dataset cannot be easily collected.It would be wasteful to train Text-to-Video (T2V) models from scratchwhen there already exist models that can generate images.Moreover, unsupervised learning enables networks to learn from orders of magnitude more data. This large quantity of data is important to learn representations of more subtle, less common concepts in the world. Unsupervised learning has long had great success in advancing the field of natural language processing (NLP) (Liu et al., 2019a; Brown et al., 2020). Models pre-trained this way yield considerably higher performance than when solely trained in a supervised manner.\n\n#### It is hard to collect datasets because a similarly sized (text, video) dataset cannot be easily collected. For human evaluation, they employ some annotators and filtered out according to their criteria. Therefore, they are not making an excuse about not collecting the dataset.",
        "In order to expand the two-dimensional (2D) conditional network into the temporal dimension, we modify the two key building blocks that now require not just spatial but also temporal dimensions in order to generate videos: (i) Convolutional layers (Sec. 3.2.1), and (ii) attention layers (Sec. 3.2.2), discussed in the following two subsections. Other layers, such as fully-connected layers, do not require specific handling when adding an additional dimension, as they are agnostic to structured spatial and temporal information.Temporal modifications are made in most U-Net-based diffusion networks: the spatiotemporal decoder \\operatorname{D^{t}} now generating 16 RGB frames, each of size 64\\times 64, the newly added frame interpolation network \\uparrow_{F}, increasing the effective frame rate by interpolating between the 16 generated frames (as depicted in Fig. 2), and the super-resolution networks \\operatorname{SR}_{l}^{t}.\n\n#### They train a new masked frame interpolation and extrapolation network ↑F , capable of increasing the number of frames of the generated video either by frame interpolation for a smoother generated video, or by pre/post frame extrapolation for extending the video length. Additionally, the spatial super-resolution models enable to increase a higher (controllable) frame rate. Therefore, using the extrapolation network ↑F, it can possible to extend the video length from 16 frames to 76 frames.",
        "Make-A-Video’s final T2V inference scheme (depicted in Fig. 2) can be formulated as:yt^=SRh∘SRlt∘↑F∘Dt∘P∘(x^,Cx(x)),\\hat{y_{t}}=\\operatorname{SR}_{h}\\circ\\operatorname{SR}_{l}^{t}\\circ\\uparrow_{F}\\circ\\operatorname{D}^{t}\\circ\\operatorname{P}\\circ(\\hat{x},\\operatorname{C}_{x}(x)),over^ start_ARG italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG = roman_SR start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ∘ roman_SR start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ∘ ↑ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ∘ roman_D start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ∘ roman_P ∘ ( over^ start_ARG italic_x end_ARG , roman_C start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( italic_x ) ) ,(1)where \\hat{y_{t}} is the generated video, \\operatorname{SR}_{h},\\operatorname{SR}_{l} are the spatial and spatiotemporal super-resolution networks (Sec. 3.2), \\uparrow_{F} is a frame interpolation network (Sec. 3.3), \\operatorname{D}^{t} is the spatiotemporal decoder (Sec. 3.2), \\operatorname{P} is the prior (Sec. 3.1), \\hat{x} is the BPE-encoded text, \\operatorname{C}_{x} is the CLIP text encoder (Radford et al., 2021), and x is the input text. The three main components are described in detail in the following sections.\n\n#### First, a prior network \\operatorname{\\textbf{P}}, that during inference generates image embeddings y_{e} given text embeddings x_{e} and BPE encoded text tokens \\hat{x}. Second, a decoder network \\operatorname{\\textbf{D}} that generates a low-resolution 64\\times 64 RGB image \\hat{y}_{l}, conditioned on the image embeddings y_{e}. Finally, two super-resolution networks \\operatorname{\\textbf{SR}}_{\\textbf{l}},\\operatorname{\\textbf{SR}}_{\\textbf{h}} that increase the generated image \\hat{y}_{l} resolution to 256\\times 256 and 768\\times 768 pixels respectively, resulting in the final222We then downsample to 512 using bicubic interpolation for a cleaner aesthetic. Maintaining a clean aesthetic for high definition videos is part of future work. generated image \\hat{y}.",
        "In order to expand the two-dimensional (2D) conditional network into the temporal dimension, we modify the two key building blocks that now require not just spatial but also temporal dimensions in order to generate videos: (i) Convolutional layers (Sec. 3.2.1), and (ii) attention layers (Sec. 3.2.2), discussed in the following two subsections. Other layers, such as fully-connected layers, do not require specific handling when adding an additional dimension, as they are agnostic to structured spatial and temporal information.Temporal modifications are made in most U-Net-based diffusion networks: the spatiotemporal decoder \\operatorname{D^{t}} now generating 16 RGB frames, each of size 64\\times 64, the newly added frame interpolation network \\uparrow_{F}, increasing the effective frame rate by interpolating between the 16 generated frames (as depicted in Fig. 2), and the super-resolution networks \\operatorname{SR}_{l}^{t}.\n\n#### They extend the spatial layers at the model initialization stage, to include temporal information, and the extended spatial-temporal network learn significantly accelerates the T2V training process by instantaneously transferring the knowledge\nfrom a previously trained T2I network to a new T2V one. Because of the fact that using 3D convolutional layers is computationally heavy, they followed the work of (Ho et al., 2022) extending dimension decomposition strategy to attention layers. In contrast to VDM, they apply an additional 3x1x1 convolution projection (after each 1x3x3) such that the temporal information will also be passed through each convolution layer.",
        "Note that super resolution involves hallucinating information. In order to not have flickering artifacts, the hallucination must be consistent across frames. As a result, our \\operatorname{SR}_{l}^{t} module operates across spatial and temporal dimensions. In qualitative inspection we found this to significantly outperform per-frame super resolution. It is challenging to extend \\operatorname{SR}_{h} to the temporal dimension due to memory and compute constraints, as well as a scarcity of high resolution video data. So \\operatorname{SR}_{h} operates only along the spatial dimensions. But to encourage consistent detail hallucination across frames, we use the same noise initialization for each frame.\n\n#### To prevent flickering artifacts, they sustain hallucinating information to be consistent across frames. They use the same noise initialization for each frame to encourage consistent detail hallucination. For future works, they explain about thier several technical limitations such as learning association between text and phenomenon.",
        "Clearly, text describing images does not capture the entirety of phenomena observed in videos. That said, one can often infer actions and events from static images (e.g. a woman drinking coffee, or an elephant kicking a football) as done in image-based action recognition systems (Girish et al., 2020). Moreover, even without text descriptions, unsupervised videos are sufficient to learn how different entities in the world move and interact (e.g. the motion of waves at the beach, or of an elephant’s trunk). As a result, a model that has only seen text describing images is surprisingly effective at generating short videos, as demonstrated by our temporal diffusion-based method. Make-A-Video sets the new state-of-the-art in T2V generation.\n\n#### In the limited volume of available videos at training time, conditioning on a varying number of frames-per-second, enables an additional augmentation method, and provides rovides additional control on the generated video at inference time. In human evaluation experiments, it shows that raters choose this method more realistic motion more than the half of the time. It is observed that this method excels when there are large differences between frames where having real-world knowledge of how objects move is crucial. Table 1 demonstrates the quantitative results of Make-A-Video.",
        "Datasets.To train the image models, we use a 2.3B subset of the dataset from (Schuhmann et al., ) where the text is English. We filter out sample pairs with NSFW images 333We used this model: https://github.com/GantMan/nsfw_model, toxic words in the text, or images with a watermark probability larger than 0.5.We use WebVid-10M (Bain et al., 2021) and a 10M subset from HD-VILA-100M (Xue et al., 2022) 444These 100M clips are sourced from 3.1M videos. We randomly downloaded 3 clips per video to form our HD-VILA-10M subset. to train our video generation models.Note that only the videos (no aligned text) are used. The decoder \\operatorname{D}^{t} and the interpolation model is trained on WebVid-10M. \\operatorname{SR}_{l}^{t} is trained on both WebVid-10M and HD-VILA-10M.While prior work (Hong et al., 2022; Ho et al., 2022) have collected private text-video pairs for T2V generation, we use only public datasets (and no paired text for videos). We conduct automatic evaluation on UCF-101 (Soomro et al., 2012) and MSR-VTT (Xu et al., 2016) in a zero-shot setting.\n\n#### In NSFW images, there are toxic words in the text, or images with a watermark. Therefore, authors filter out sample pairs with probability larger than 0.5. As with all large-scale models trained on data from the web, our models have learnt and likely exaggerated social biases, including harmful ones. Compared to these models, T2I generation model was trained on data that removed NSFW content and toxic words.",
        "Inspired by these motivations, we propose Make-A-Video. Make-A-Video leverages T2I models to learn the correspondence between text and the visual world, and uses unsupervised learning on unlabeled (unpaired) video data, to learn realistic motion. Together, Make-A-Video generates videos from text without leveraging paired text-video data.\n\n#### Authors suggest future works that their our approach can not learn associations between text and phenomenon that can only be inferred in videos. How to incorporate these (e.g., generating a video of a person waving their hand left-to-right or right-to-left), along with generating longer videos, with multiple scenes and events, depicting more detailed stories, is left for future work.",
        "Automatic Metrics.For UCF-101, we write one template sentence for each class (without generating any video) and fix it for evaluation. We report Frechet Video Distance (FVD) and Inception Score (IS) on 10K samples following (Ho et al., 2022). We generate samples that follow the same class distribution as the training set. For MSR-VTT, we report Frechet Inception Distance (FID) (Parmar et al., 2022) and CLIPSIM (average CLIP similarity between video frames and text) (Wu et al., 2021a), where all 59,794 captions from the test set are used, following (Wu et al., 2021b).\n\n#### They collect 300 text prompts for human evaluation and the prompts include 5 categories. For quantitative results, Make-A-Video outperform CogVideo in both Chinese and English settings that it can infer that Make-AVideo has significantly better generalization capabilities than prior work. Moreover, table 2 demonstrates that Make-A-Video’s zero-shot performance is already competitive than other approaches that are trained on UCF-101, and is much better than CogVideo. It indicates that Make-A-Video can generalize better even to such a specific domain.",
        "Human Evaluation Set and Metrics.We collect an evaluation set from Amazon Mechanical Turk (AMT) that consists of 300 prompts. We asked annotators what they would be interested in generating if there were a T2V system. We filtered out prompts that were incomplete (e.g., “jump into water”), too abstract (e.g., “climate change”), or offensive. We then identified 5 categories (animals, fantasy, people, nature and scenes, food and beverage) and selected prompts for these categories. These prompts were selected without generating any videos for them, and were kept fixed. In addition, we also used the DrawBench prompts from Imagen (Saharia et al., 2022) for human evaluation.We evaluate video quality and text-video faithfulness. For video quality, we show two videos in random order and ask annotators which one is of higher quality. For faithfulness, we additionally show the text and ask annotators which video has a better correspondence with the text (we suggest them to ignore quality issues). In addition, we also conducted human evaluation to compare video motion realism of our interpolation model and FILM (Reda et al., 2022).For each comparison, we use the majority vote from 5 different annotators as the final result.\n\n#### They collect 300 text prompts and asked annotators what they would be interested in generating if there were a T2V system. It is used for zero-shot T2V human evaluation which they plan to release.",
        "Inspired by these motivations, we propose Make-A-Video. Make-A-Video leverages T2I models to learn the correspondence between text and the visual world, and uses unsupervised learning on unlabeled (unpaired) video data, to learn realistic motion. Together, Make-A-Video generates videos from text without leveraging paired text-video data.\n\n#### Text describing images does not capture the entirety of phenomena observed in videos. That said, one can often infer actions and events from static images. as done in image-based action recognition systems (Girish et al., 2020). Moreover, even without text descriptions, unsupervised videos are sufficient to learn how different entities in the world move and interact (e.g. the motion of waves at the beach, or of an elephant’s trunk).",
        "The Internet has fueled collecting billions of (alt-text, image) pairs from HTML pages (Schuhmann et al., 2022), enabling the recent breakthroughs in Text-to-Image (T2I) modeling. However, replicating this success for videos is limited since a similarly sized (text, video) dataset cannot be easily collected.It would be wasteful to train Text-to-Video (T2V) models from scratchwhen there already exist models that can generate images.Moreover, unsupervised learning enables networks to learn from orders of magnitude more data. This large quantity of data is important to learn representations of more subtle, less common concepts in the world. Unsupervised learning has long had great success in advancing the field of natural language processing (NLP) (Liu et al., 2019a; Brown et al., 2020). Models pre-trained this way yield considerably higher performance than when solely trained in a supervised manner.\n\n#### Unsupervised learning enables networks to learn from orders of magnitude more data. This large quantity of data is important to learn representations of more subtle, less common concepts in the world. Unsupervised learning has long had great success in advancing the field of natural language processing (NLP).",
        "Automatic Evaluation on UCF-101. UCF-101 is a popular benchmark to evaluate video generation and has been recently used in T2V models. CogVideo performed finetuning of their pretrained model for class-conditional video generation. VDM (Ho et al., 2022) performed unconditional video generation and trained from scratch on UCF-101. We argue that both settings are not ideal and is not a direct evaluation of the T2V generation capabilities. Moreover, the FVD evaluation model expects the videos to be 0.5 second (16 frames), which is too short to be used for video generation in practice. Nevertheless, in order to compare to prior work, we conducted evaluation on UCF-101 in both zero-shot and finetuning settings.As shown in Table 2, Make-A-Video’s zero-shot performance is already competitive than other approaches that are trained on UCF-101, and is much better than CogVideo, which indicates that Make-A-Video can generalize better even to such a specific domain. Our finetuning setting achieves state-of-the-art results with a significant reduction in FVD, which suggests that Make-A-Video can generate more coherent videos than prior work.\n\n#### Coherent means a semantically similar video in spite of large differences between frames where having real-world knowledge of how objects move is crucial.",
        "The Internet has fueled collecting billions of (alt-text, image) pairs from HTML pages (Schuhmann et al., 2022), enabling the recent breakthroughs in Text-to-Image (T2I) modeling. However, replicating this success for videos is limited since a similarly sized (text, video) dataset cannot be easily collected.It would be wasteful to train Text-to-Video (T2V) models from scratchwhen there already exist models that can generate images.Moreover, unsupervised learning enables networks to learn from orders of magnitude more data. This large quantity of data is important to learn representations of more subtle, less common concepts in the world. Unsupervised learning has long had great success in advancing the field of natural language processing (NLP) (Liu et al., 2019a; Brown et al., 2020). Models pre-trained this way yield considerably higher performance than when solely trained in a supervised manner.\n\n#### A model that has only seen text describing images is surprisingly effective at generating short videos, as demonstrated by our temporal diffusion-based method. A diffusion-based T2I model to T2V through a spatiotemporally factorized diffusion model. They leverage joint text-image priors to bypass the need for paired text-video data, which in turn allows us to potentially scale to larger quantities of video data.",
        "Make-A-Video consists of three main components: (i) A base T2I model trained on text-image pairs (Sec. 3.1), (ii) spatiotemporal convolution and attention layers that extend the networks’ building blocks to the temporal dimension (Sec. 3.2), and (iii) spatiotemporal networks that consist of both spatiotemporal layers, as well as another crucial element needed for T2V generation - a frame interpolation network for high frame rate generation (Sec. 3.3).\n\n#### A frame interpolation network for high frame rate generation can make a semantically similar video by taking the average CLIP embedding of all frames from a video as the condition.",
        "Note that super resolution involves hallucinating information. In order to not have flickering artifacts, the hallucination must be consistent across frames. As a result, our \\operatorname{SR}_{l}^{t} module operates across spatial and temporal dimensions. In qualitative inspection we found this to significantly outperform per-frame super resolution. It is challenging to extend \\operatorname{SR}_{h} to the temporal dimension due to memory and compute constraints, as well as a scarcity of high resolution video data. So \\operatorname{SR}_{h} operates only along the spatial dimensions. But to encourage consistent detail hallucination across frames, we use the same noise initialization for each frame.\n\n#### Pseudo-3D convolutional layers facilitates information sharing between the spatial and temporal axes, without succumbing to the heavy computational load of 3D conv layers. Additionally, conditioning on a varying number of frames-per-second, enables an additional augmentation method to tackle the limited volume of available videos at training time, and provides additional control on the generated video at inference time.",
        "As with all large-scale models trained on data from the web, our models have learnt and likely exaggerated social biases, including harmful ones. Our T2I generation model was trained on data that removed NSFW content and toxic words. All our data (image as well as videos) is publicly available, adding a layer of transparency to our models, and making it possible for the community to reproduce our work.\n\n#### Modeling videos require expensive computational complexity that it is challenging in high-quality video data collection. Thus, large-scale paired text-video is expensive as well. Because of the limitations, the progress of T2V generation lags behind.",
        "Automatic Metrics.For UCF-101, we write one template sentence for each class (without generating any video) and fix it for evaluation. We report Frechet Video Distance (FVD) and Inception Score (IS) on 10K samples following (Ho et al., 2022). We generate samples that follow the same class distribution as the training set. For MSR-VTT, we report Frechet Inception Distance (FID) (Parmar et al., 2022) and CLIPSIM (average CLIP similarity between video frames and text) (Wu et al., 2021a), where all 59,794 captions from the test set are used, following (Wu et al., 2021b).\n\n#### They employed annotators to make prompts and filtered out them correctly. Evaluation is done about video quality and faithfulness. For each comparison, 5 different annotators are employed. They report FVD and IS on 10K samples and generate samples that follow the same class distribution as the training set. Moreover, for MSR-VTT, FID and CLIPSIM are introduced.",
        "The Internet has fueled collecting billions of (alt-text, image) pairs from HTML pages (Schuhmann et al., 2022), enabling the recent breakthroughs in Text-to-Image (T2I) modeling. However, replicating this success for videos is limited since a similarly sized (text, video) dataset cannot be easily collected.It would be wasteful to train Text-to-Video (T2V) models from scratchwhen there already exist models that can generate images.Moreover, unsupervised learning enables networks to learn from orders of magnitude more data. This large quantity of data is important to learn representations of more subtle, less common concepts in the world. Unsupervised learning has long had great success in advancing the field of natural language processing (NLP) (Liu et al., 2019a; Brown et al., 2020). Models pre-trained this way yield considerably higher performance than when solely trained in a supervised manner.\n\n#### Make-A-Video adopt unsupervised learning method by leveraging joint text-image prior that it is not need paried text-video data. But, for training of the prior \\operatorname{P}, text input is required.",
        "Make-A-Video’s final T2V inference scheme (depicted in Fig. 2) can be formulated as:yt^=SRh∘SRlt∘↑F∘Dt∘P∘(x^,Cx(x)),\\hat{y_{t}}=\\operatorname{SR}_{h}\\circ\\operatorname{SR}_{l}^{t}\\circ\\uparrow_{F}\\circ\\operatorname{D}^{t}\\circ\\operatorname{P}\\circ(\\hat{x},\\operatorname{C}_{x}(x)),over^ start_ARG italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG = roman_SR start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT ∘ roman_SR start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ∘ ↑ start_POSTSUBSCRIPT italic_F end_POSTSUBSCRIPT ∘ roman_D start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ∘ roman_P ∘ ( over^ start_ARG italic_x end_ARG , roman_C start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ( italic_x ) ) ,(1)where \\hat{y_{t}} is the generated video, \\operatorname{SR}_{h},\\operatorname{SR}_{l} are the spatial and spatiotemporal super-resolution networks (Sec. 3.2), \\uparrow_{F} is a frame interpolation network (Sec. 3.3), \\operatorname{D}^{t} is the spatiotemporal decoder (Sec. 3.2), \\operatorname{P} is the prior (Sec. 3.1), \\hat{x} is the BPE-encoded text, \\operatorname{C}_{x} is the CLIP text encoder (Radford et al., 2021), and x is the input text. The three main components are described in detail in the following sections.\n\n#### Figure 4 (c) compares the task of interpolation between two images. A frame interpolation network generates high frame rate and it can be interpreted as interpolating between two images.",
        "To demonstrate our approach on unconditional generation, we use a popular benchmark of Soomro et al. (2012) for unconditional modeling of video. The benchmark consists of short clips of people performing one of 101 activities, and was originally collected for the purpose of training action recognition models. We model short segments of 16 frames from this dataset, downsampled to a spatial resolution of 64x64. In Table 1 we present perceptual quality scores for videos generated by our model, and we compare against methods from the literature, finding that our method strongly improves upon the previous state-of-the-art. \n\n#### Video diffusion models present the first results on a large text-conditioned video generation tasks, and they achieve state-of-the-art results on popular video datasets. They train the model with image-video jointly to improve sample quality. Moreover, the conditional sampling method, introduced in Section 3.1, shows better quality compared to the existing replacement method.",
        "We show that high quality videos can be generated using essentially the standard formulation of the Gaussian diffusion model (Sohl-Dickstein et al., 2015), with little modification other than straightforward architectural changes to accommodate video data within the memory constraints of deep learning accelerators. We train models that generate a fixed number of video frames using a 3D U-Net diffusion model architecture, and we enable generating longer videos by applying this model autoregressively using a new method for conditional generation. We additionally show the benefits of joint training on video and image modeling objectives. We test our methods on video prediction and unconditional video generation, where we achieve state-of-the-art sample quality scores, and we also show promising first results on text-conditioned video generation.\n\n#### Video diffusion models modify little of the archicture to accommodate video data within the memory constraints of deep learning accelerators. They approach with the standard diffusion modelformalism. In their method, one of skill to make high resolution video is the spatial upsampling introduced by Menick and Kalchbrenner (2019).\nAlso, reconstruction guidance is extended to constuct the high-resolution model. When they have low resolution ground truth videos, it upsamples them into high resolution videos using an unconditional high resolution diffusion model.",
        "Figure 3 shows the effect of classifier-free guidance (Ho and Salimans, 2021) on a text-conditioned video model. Similar to what was observed in other work that used classifier-free guidance on text-conditioned image generation (Nichol et al., 2021) and class-conditioned image generation (Ho and Salimans, 2021; Dhariwal and Nichol, 2021), adding guidance increases the sample fidelity of each individual image and emphases the effect of the conditioning signal.\n\n#### The higher performance in Text-to-Video Generation requires not only excellent fidelity of video samples but also good handling of social bias in text-description given as a condition.",
        "We report our results on video diffusion models for unconditional video generation (Section 4.1), conditional video generation (video prediction) (Section 4.2), and text-conditioned video generation (Section 4.3). We evaluate our models using standard metrics such as FVD (Unterthiner et al., 2018), FID (Heusel et al., 2017), and IS (Salimans et al., 2016); details on evaluation are provided below alongside each benchmark.Samples and additional results are provided at https://video-diffusion.github.io/.Architecture hyperparameters, training details, and compute resources are listed in Appendix A.\n\n#### Video Diffusion Model can be conditioned on text descriptions or image frame.\nWhen conditioned on a text description, they generate a video explaining the text.",
        "We show that high quality videos can be generated using essentially the standard formulation of the Gaussian diffusion model (Sohl-Dickstein et al., 2015), with little modification other than straightforward architectural changes to accommodate video data within the memory constraints of deep learning accelerators. We train models that generate a fixed number of video frames using a 3D U-Net diffusion model architecture, and we enable generating longer videos by applying this model autoregressively using a new method for conditional generation. We additionally show the benefits of joint training on video and image modeling objectives. We test our methods on video prediction and unconditional video generation, where we achieve state-of-the-art sample quality scores, and we also show promising first results on text-conditioned video generation.\n\n#### Other diffusion models that generate images use a 2D U-Net, but they use a 3D U-Net to handle video.\nA 3D U-Net diffusion model is used to generate a fixed number of video frames.\nA 2D U-Net is modified into each 2D convolution into a space-only 3D convolution, and inserted a temporal attention block that performs attention over the first axis and treats the spatial axes as batch axes.\nAuthors concatenate random independent image frames to the end of each video\nsampled from the dataset and they choose these random independent images from random videos within the same dataset.",
        "We show that high quality videos can be generated using essentially the standard formulation of the Gaussian diffusion model (Sohl-Dickstein et al., 2015), with little modification other than straightforward architectural changes to accommodate video data within the memory constraints of deep learning accelerators. We train models that generate a fixed number of video frames using a 3D U-Net diffusion model architecture, and we enable generating longer videos by applying this model autoregressively using a new method for conditional generation. We additionally show the benefits of joint training on video and image modeling objectives. We test our methods on video prediction and unconditional video generation, where we achieve state-of-the-art sample quality scores, and we also show promising first results on text-conditioned video generation.\n\n#### Video Diffusion Models demonstrates their inital attempt to generate text-to-image generation results in various settings such as classifier-free guidance, jointly training of video-image, and unconditional and conditional generation.\nThey consider several additional image frames for joint training of video-image.\nMoreover, they adjust the weight of classifier-free guidance, and conditioning method with the newly proposed reconstruction guidance for autoregressive extension and simultaneous spatial and temporal super-resolution.",
        "We show that high quality videos can be generated using essentially the standard formulation of the Gaussian diffusion model (Sohl-Dickstein et al., 2015), with little modification other than straightforward architectural changes to accommodate video data within the memory constraints of deep learning accelerators. We train models that generate a fixed number of video frames using a 3D U-Net diffusion model architecture, and we enable generating longer videos by applying this model autoregressively using a new method for conditional generation. We additionally show the benefits of joint training on video and image modeling objectives. We test our methods on video prediction and unconditional video generation, where we achieve state-of-the-art sample quality scores, and we also show promising first results on text-conditioned video generation.\n\n#### Due to memory constraints of deep learning accelerators, a fixed number of video frames should be used.\nIf memory constraints are addressed, a larger number of frames can be used.\nTo address this issue, they introduce joint training on video and image.\nThey concatenate random independent image frames to the end of each video sampled from the dataset to consider more frames during training and implement a memory optimization to fit more independent examples in a batch.",
        "As described in Section 3, one of the main advantages of our video architecture is that it allows us to easily train the model jointly on video and image generative modeling objectives. To implement this joint training, we concatenate random independent image frames to the end of each video sampled from the dataset, and we mask the attention in the temporal attention blocks to prevent mixing information across video frames and each individual image frame. We choose these random independent images from random videos within the same dataset; in future work we plan to explore the effect of choosing images from other larger image-only datasets.\n\n#### Due to memory limit, authors consider newly joint training method utilizing both image and video.\nAs more independent image frames are added, we can see the reduced variane of the gradient at the expense of some bias for the video modeling.\nTable 4 shows that additional frames per video helps to improve in video and image sample quality metrics.",
        "The videos we consider modeling typically consist of hundreds to thousands of frames, at a frame rate of at least 24 frames per second. To manage the computational requirements of training our models, we only train on a small subset of say 16 frames at a time. However, at test time we can generate longer videos by extending our samples. For example, we could first generate a video \\mathbf{x}^{\\text{a}}\\sim p_{\\theta}(\\mathbf{x}) consisting of 16 frames, and then extend it with a second sample \\mathbf{x}^{\\text{b}}\\sim p_{\\theta}(\\mathbf{x}^{\\text{b}}|\\mathbf{x}^{\\text{a}}). If \\mathbf{x}^{\\text{b}} consists of frames following \\mathbf{x}^{\\text{a}}, this allows us to autoregressively extend our sampled videos to arbitrary lengths, which we demonstrate in Section 4.3.3. Alternatively, we could choose \\mathbf{x}^{\\text{a}} to represent a video of lower frame rate, and then define \\mathbf{x}^{\\text{b}} to be those frames in between the frames of \\mathbf{x}^{\\text{a}}.This allows one to then to upsample a video temporally, similar to how Menick and Kalchbrenner (2019) generate high resolution images through spatial upsampling.\n\n#### To manage the computational requirements of training our models, they only train on a small subset of say 16 frames at a time. But thier newly introduced joint training on video and image modeling, they concatenate random independent image frames to the end of each video sampled from the dataset. Due to memory constraints, they use fixed number of frames but these randomly sampled frames helps to reduce bias in training.\nFor evaluation, they adopt fixed number of conditioning samples and generating a sequence of video frames to compare other baselines.",
        "The videos we consider modeling typically consist of hundreds to thousands of frames, at a frame rate of at least 24 frames per second. To manage the computational requirements of training our models, we only train on a small subset of say 16 frames at a time. However, at test time we can generate longer videos by extending our samples. For example, we could first generate a video \\mathbf{x}^{\\text{a}}\\sim p_{\\theta}(\\mathbf{x}) consisting of 16 frames, and then extend it with a second sample \\mathbf{x}^{\\text{b}}\\sim p_{\\theta}(\\mathbf{x}^{\\text{b}}|\\mathbf{x}^{\\text{a}}). If \\mathbf{x}^{\\text{b}} consists of frames following \\mathbf{x}^{\\text{a}}, this allows us to autoregressively extend our sampled videos to arbitrary lengths, which we demonstrate in Section 4.3.3. Alternatively, we could choose \\mathbf{x}^{\\text{a}} to represent a video of lower frame rate, and then define \\mathbf{x}^{\\text{b}} to be those frames in between the frames of \\mathbf{x}^{\\text{a}}.This allows one to then to upsample a video temporally, similar to how Menick and Kalchbrenner (2019) generate high resolution images through spatial upsampling.\n\n#### No, it doesn't. It enables generating longer videos by applying this model autoregressively using a new method for a conditional generation. Also, P4 explains that the conditioning method helps the model outperform the existing method. The samples from the reconstruction guidance method are temporally coherent over the course of the entire autoregressive generation process and we can infer that the quality is not affected by generated frames.",
        "Human is capable of one-shot learning [22, 23, 42]. For instance, given a video paired with a textual description of “a man is skiing on snow” as a hint, we might hallucinate how a panda skis on snow if we could picture what a panda looks like.Since T2I models pre-trained with large-scale image-text data already capture the knowledge of open-domain concepts,an intuitive question arises:can it infer other novel videos from a single video example like human beings?A new T2V generation problem is therefore introduced, namely, One-Shot Video Generation, where only a single text-video pair is presented for training an open-domain T2V generator.The generator is expected to capture necessary motion knowledge from the input video and synthesize novel videos guided by edited prompts.\n\n#### The T2V generator is expected to capture necessary motion knowledge from the input video and synthesize novel videos guided by edited prompts. They use the pre-trained T2I model which is able to generate images that align well with the text, including the verb terms.",
        "The large-scale multimodal dataset [35] with billions of text-image pairs crawled from Internet has enabled breakthrough in open-domain Text-to-Image (T2I) generation [25, 29, 4, 6, 34]. To replicate this success in Text-to-Video (T2V) generation, recent works [36, 14, 17, 48] extend the spatial-only T2I generation models to the spatio-temporal domain.These models generally adopt the standard paradigm to finetune T2I models on large-scale text-video datasets (e.g., WebVid-10M [2]).Although this paradigm produces decent results for T2V generation, it requires extensive training, which is expensive and not affordable to everyone.\n\n#### One-Shot Tuning acquires temporal knowledge from one training video, which is enabled by Sparse-Causal Attention (SCAttn) and temporal self-attention (Temp-Attn). It aptures spatial information and yields similar semantics as the training video to perform semantic mixing.",
        "We implement our findings into a simple yet effective method, dubbed as Tune-A-Video, for the task of One-Shot Video Generation.Tune-A-Video is based on a simple inflation of pre-trained T2I diffusion models [31] over time dimension, by extending the 3\\times 3 convolution to 1\\times 3\\times 3, and spatial self-attention to spatio-temporal cross-frame attention.We propose an efficient tuning strategy that only updates the projection matrices in attention blocks to capture continuous motion dynamics from the one-shot video, with the rest of parameters being frozen.\n\n#### Tune-A-Video is based on a pre-trained T2I diffusion model and only updates the projection matrices in attention blocks, with the rest of parameters being frozen. Moreover, SC-Attn reduce the computational complexity compared to CogView2.",
        "Human is capable of one-shot learning [22, 23, 42]. For instance, given a video paired with a textual description of “a man is skiing on snow” as a hint, we might hallucinate how a panda skis on snow if we could picture what a panda looks like.Since T2I models pre-trained with large-scale image-text data already capture the knowledge of open-domain concepts,an intuitive question arises:can it infer other novel videos from a single video example like human beings?A new T2V generation problem is therefore introduced, namely, One-Shot Video Generation, where only a single text-video pair is presented for training an open-domain T2V generator.The generator is expected to capture necessary motion knowledge from the input video and synthesize novel videos guided by edited prompts.\n\n#### The authors examine the ability of attribute modification with the adjectives like color annd chage. Also, style transfer demonstrates the examples.",
        "The large-scale multimodal dataset [35] with billions of text-image pairs crawled from Internet has enabled breakthrough in open-domain Text-to-Image (T2I) generation [25, 29, 4, 6, 34]. To replicate this success in Text-to-Video (T2V) generation, recent works [36, 14, 17, 48] extend the spatial-only T2I generation models to the spatio-temporal domain.These models generally adopt the standard paradigm to finetune T2I models on large-scale text-video datasets (e.g., WebVid-10M [2]).Although this paradigm produces decent results for T2V generation, it requires extensive training, which is expensive and not affordable to everyone.\n\n#### To imitate human's ability to adapt new visual concets, One-Shot Video Generation task is proposed. Tune-A-Video generates videos with novel visual concepts (e.g., subjects, backgrounds, attributes, styles, etc.) guided by the text prompt. It is expensive to finetune T2I models on large-scale text-video datasets and not affordable to everyone.",
        "We first follow VDM baselines [17, 14] to use inflated 1\\times 3\\times 3 convolution kernels for video inputs and append temporal self-attention with causal mask for temporal modeling. However, we empirically observe that factorized space-time attention in VDM baselines is insufficient to generate consistent content in the task of One-Shot Video Generation (see Sec. 4.3). We further inflate the spatial self-attention to cross-frame attention as follows.\n\n#### Figure 8 shows that the VDM baselines with factorized space-time attention fail to generate consistent content. But Tune-A-Video can generate better temporal consistency video.",
        "We first follow VDM baselines [17, 14] to use inflated 1\\times 3\\times 3 convolution kernels for video inputs and append temporal self-attention with causal mask for temporal modeling. However, we empirically observe that factorized space-time attention in VDM baselines is insufficient to generate consistent content in the task of One-Shot Video Generation (see Sec. 4.3). We further inflate the spatial self-attention to cross-frame attention as follows.\n\n#### Factorized space-time attention in VDM baselines is insufficient to generate consistent content in the task of One-Shot Video Generation. The self-attention layers in T2I models are only driven by spatial similarities rather than pixel positions. Using full attention in space-time leads to quadratic growth in computation. It is thus infeasible for generating long-form videos with increasing frames.",
        "Intuitively, the key to video generation is to keep the continuous motion of consistent objects.So we make the following observations on state-of-the-art T2I diffusion models [31] that motivate our method accordingly.(1) Regarding motion: T2I models are able to generate images that align well with the text, including the verb terms. For example, given the text prompt “a man is running on the beach”, the T2I models produce the snapshot where a man is running (not walking or jumping), but not continuously (the first row of Fig. 2).This serves as evidence that T2I models can properly attend to verbs via cross-modal attention for static motion generation.(2) Regarding consistent objects: Simply extending the self-attention in the T2I model from one image to multiple images maintains content consistency across frames.Taking the same example, when we generate consecutive frames in parallel with extended cross-frame attention to the 1st frame, the same man and the same beach can be observed in the resultant sequence though the motion is still not continuous (the second row of Fig. 2). This implies that the self-attention layers in T2I models are only driven by spatial similarities rather than pixel positions.\n\n#### The authors extend the spatial self-attention in the T2I model from one image to multiple images to maintain content consistency across frames. It is useful in spatiotemporal domain like generating videos.",
        "Formally, given a video \\mathcal{V}=\\left\\{v_{i}|i\\in[1,m]\\right\\} with m frames, accompanied with a corresponding textual description \\mathcal{T}, our objective is to generate novel videos \\hat{\\mathcal{V}} driven by text prompts \\hat{\\mathcal{T}} using a pre-trained T2I model M, i.e., M(\\hat{\\mathcal{V}}|\\mathcal{V},\\mathcal{T},\\hat{\\mathcal{T}}), where \\mathcal{T} and \\hat{\\mathcal{T}} share the same verbs.Examples of output variations driven by \\hat{\\mathcal{T}} include: changes of subject, background (e.g., the place where the subject is), attribute (e.g., color, age, etc.), and other semantic modifications (see Fig. 1 and Fig. 7).\n\n#### Conditioning the first frame, it can autoregressively extend video frames with shared verb.",
        "Human is capable of one-shot learning [22, 23, 42]. For instance, given a video paired with a textual description of “a man is skiing on snow” as a hint, we might hallucinate how a panda skis on snow if we could picture what a panda looks like.Since T2I models pre-trained with large-scale image-text data already capture the knowledge of open-domain concepts,an intuitive question arises:can it infer other novel videos from a single video example like human beings?A new T2V generation problem is therefore introduced, namely, One-Shot Video Generation, where only a single text-video pair is presented for training an open-domain T2V generator.The generator is expected to capture necessary motion knowledge from the input video and synthesize novel videos guided by edited prompts.\n\n#### Training with opendomain data, it is hard to capture necessary motion knowledge from the input video and synthesize novel videos guided by edited prompts",
        "We first measure the perplexity of English pretrained MLMs in other languages. We use Wiki-40B, a multilingual language modeling dataset that covers 41 languages Guo et al. (2020). Following the Wiki-40B paper, we report bits per character (BPC) to allow comparison between models with different tokenizations of the text.\n\n#### RoBERTa performs at about 2.6 BPC on the MLM task with the Wiki-40B dataset. RoBERTa performs better than BERT.",
        "Recent work has claimed that monolingual pretrained models are also surprisingly good at transferring between languages, despite ostensibly having never seen the target language before (Gogoulou et al., 2021; Li et al., 2021, inter alia).However, because of the large scale of pretraining data and because many pretraining corpora are not publicly available, it is currently unknown how much foreign language data exists in monolingual pretraining corpora.In this paper, we show that (1) these data are almost certainly contaminated with very small percentages of text from other languages and that (2) cross-lingual transfer is possible from such data leakage in the pretraining corpus.\n\n#### No, they are not, relative to models trained on corpora with non-English text.",
        "In this paper, we demonstrate that English pretrained models are exposed to a considerable amount of non-English data during pretraining, particularly in the case of more recent models that are trained on larger corpora derived from web crawls. We also find that this non-English text acts as a significant source of signal for cross-lingual transfer.\n\n#### Well-known pre-training resources already include multilingual data.",
        "We now ask: how well do models pretrained on these putatively English corpora perform on non-English tasks? While the English data is more multilingual than previously thought, there are many differences between monolingual and multilingual pretraining; non-English data are often tokenized into more subword units333For example, the Basque UD treebank requires on average 1.78, 2.59, and 2.66 tokens per word to be encoded by XLMR, RoBERTa, and BERT, respectively.and are much less frequently observed during monolingual training.\n\n#### Authors mention BERT, RoBERTa, T5, mBERT, and XLM-R.",
        "Next, we evaluate how well monolingual English models perform on non-English downstream tasks, using part-of-speech (POS) tagging as a case study.\n\n#### Authors do not discuss how this performance is achieved.",
        "This difference is likely due to two factors. First, in terms of relative percentages, RoBERTa is exposed to more non-English text than T5 (0.78% compared to only 0.22%). Secondly, RoBERTa’s subword vocabulary is robust to unexpected inputs and does not substitute an UNK token any input tokens; in contrast, T5 and BERT have high rates of UNK tokens for some non-Latin languages (Appendix B).555UNK tokens refer to placeholder tokens used when the model receives an input not covered by its vocabulary.However, for many high-resource languages the English models perform competitively, with T5 outperforming mBERT on German and Portuguese, among others.\n\n#### T5 data contains 0.26%, and RoBERTa data contains 0.78%.",
        "To test if the effects of foreign language data carry through after finetuning, we also finetune a subset of the models (BERT{}_{base}, RoBERTa{}_{base}, mBERT, XLMR{}_{base}) for non-English POS tagging (Figure 1(c)). After finetuning, the gap between the mono- and multilingual models is much smaller: RoBERTa only averages 2.65 points worse than XLM-R, compared to 12.5 points when probing.\n\n#### It is fine tuning.",
        "We then investigate the correlation between potential transfer causes and model performance (Table 2). Specifically, we consider the quantity of target language data found in the model’s pretraining corpus and the language similarity to English as potential causes of cross-lingual transfer.\n\n#### They are quantity of target language data in the pre-training corpora and language similarity.",
        "We then investigate the correlation between potential transfer causes and model performance (Table 2). Specifically, we consider the quantity of target language data found in the model’s pretraining corpus and the language similarity to English as potential causes of cross-lingual transfer.\n\n#### Authors do not discuss how they pointed to these potential causes.",
        "We find that across tasks, RoBERTa task performance is most strongly correlated with the amount of target language data seen during pretraining. BERT and T5 task performance are less correlated with observed pretrained data, likely due to tokenization artifacts (Appendix B). Indeed, when we control for languages not written with Latin script on T5, the correlation between performance and the amount of target pretraining data increases to \\rho= 0.313.\n\n#### It is 0.313.",
        "We then investigate the correlation between potential transfer causes and model performance (Table 2). Specifically, we consider the quantity of target language data found in the model’s pretraining corpus and the language similarity to English as potential causes of cross-lingual transfer.\n\n#### Pretraining data size is more related to model performance.",
        "In this paper, we demonstrate that English pretrained models are exposed to a considerable amount of non-English data during pretraining, particularly in the case of more recent models that are trained on larger corpora derived from web crawls. We also find that this non-English text acts as a significant source of signal for cross-lingual transfer.\n\n#### It can enhance cross-lingual transfer and generalization.",
        "We also see that non-English text makes up small percentages of the overall data, though this still leads to millions of tokens in large datasets.The largest individual languages after English only make up 0.01%, 0.15%, and 0.05% of the BERT, RoBERTa, and T5 training data, respectively.Multilingual pretraining work has shown that models generalize to new languages from varying amounts of data Delvin (2019); Lample and Conneau (2019); Conneau et al. (2020); however, these approaches intentionally select data across languages, and most upsample low-resource languages during training.Without these considerations, it is an open question how well the models trained on these relatively small amounts of non-English data generalize.\n\n#### Automatic language identification and manual qualitative analysis measure non-English data. They are denominated in lines, tokens, and percentages across the paper.",
        "Pretrained language models have become an integral part of NLP systems. They come in two flavors: monolingual, where the model is trained on text from a single language, and multilingual, where the model is jointly trained on data from many different languages. Monolingual pretrained models are generally applied to tasks in the same language, whereas multilingual ones are used for cross-lingual tasks or transfer.\n\n#### They are monolingual and multilingual.",
        "A summary of the language identification experiments is presented in Figure 1.111Full results of this evaluation are detailed in Appendix C. We see that every corpus contains notable quantities of non-English data, with our estimates ranging between 300k to 406M tokens. An obvious factor that affects the amount of non-English data in each corpus is the overall size of the dataset; however, even when controlling for size by looking at the percentage of non-English data, we still see that the smaller corpora (Wikipedia, BookCorpus, and Stories) have relatively less non-English data.\n\n#### Non-English tokens make up 300k to 406M in the datasets investigated.",
        "Our analysis also shows that the language classifier performs worse on the non-web crawled data. For example, it misclassified a quarter of the sampled lines from Stories as non-English when they in fact only contain English text; many of these lines stem from snippets of dialogue in the dataset. We generally observe that lines coded as En tend to be shorter than the correctly labeled lines and often contain non-standard English. The language classifier also struggles to handle noisy lines, for which it has no appropriate language label.\n\n#### Models perform worse on web-crawled data.",
        "We also perform a closer analysis on a random subset (200 per corpus) of non-English lines predicted by the language classifier (Table 1). Each example is manually coded into one of six categories. The first set covers various kinds of foreign language data: NE, where the line contains only non-English language text; BiL, or bilingual, where the line contains both English and non-English text; Trans., in which the English and non-English data that are translations of each other; and Ent., where the line is primarily English but contains non-English entities. The last two codes pertain to errors made by the language classifier: En., where the line only contains English text, and XX, which refers to lines that contain no natural language.\n\n#### Non-English text classifier uses six categories.",
        "We also perform a closer analysis on a random subset (200 per corpus) of non-English lines predicted by the language classifier (Table 1). Each example is manually coded into one of six categories. The first set covers various kinds of foreign language data: NE, where the line contains only non-English language text; BiL, or bilingual, where the line contains both English and non-English text; Trans., in which the English and non-English data that are translations of each other; and Ent., where the line is primarily English but contains non-English entities. The last two codes pertain to errors made by the language classifier: En., where the line only contains English text, and XX, which refers to lines that contain no natural language.\n\n#### No, it is not.",
        "We now ask: how well do models pretrained on these putatively English corpora perform on non-English tasks? While the English data is more multilingual than previously thought, there are many differences between monolingual and multilingual pretraining; non-English data are often tokenized into more subword units333For example, the Basque UD treebank requires on average 1.78, 2.59, and 2.66 tokens per word to be encoded by XLMR, RoBERTa, and BERT, respectively.and are much less frequently observed during monolingual training.\n\n#### Language composition estimation and POS tagging can measure multilingual performance.",
        "We find that both BERT models perform notably worse on modeling other languages; however, RoBERTa, reduces the gap with the multilingual models from 2.51 BPC to 0.87 BPC (Figure 1(a)). This finding is consistent with Tran (2020), who also found RoBERTa transfers well cross-lingually.\n\n#### Yes, it is.",
        "We consider the following pretraining datasets: English Wikipedia(11.8GB); BookCorpus (Zhu et al. 2015, 4.2GB); Stories (Trinh and Le 2018, 31GB); OpenWebText (Gokaslan and Cohen 2019, 38GB), which is an open-source version of WebText Radford et al. (2019); CC-NEWS (Liu et al. 2019, 76 GB); and C4.En (Raffel et al. 2020, 305GB), as provided by Dodge et al. (2021). We use the versions of Wikipedia, BookCorpus, and CC-NEWS used to pretrain RoBERTa.\n\n#### English Wikipedia, BookCorpus, Stories, OpenWebText, CC-NEWS, and C4.En datasets were used in pretraining.",
        "These approaches break the problem into smaller modules and use separate LMs to solve each module Zhou et al. (2022b); Khot et al. (2022); Sprague et al. (2022); Zhou et al. (2022a).Most relevant to our work,in Tafjord et al. (2020), a single LM module iteratively and exhaustively derives all conclusions based on the facts and rules, and then the goal statement is checked against the final set of conclusions to confirm if it can be proved from the theory. Since exhaustively deriving all conclusions is computationally expensive, Creswell et al. (2022) consider an alternative approach with two modules: 1- selection, which, guided by the goal, selects a subset of the facts and rules from which new conclusions can be derived toward proving the goal, and 2- inference, which takes the selected facts and rules and derives a new conclusion. The two modules are called iteratively until a halting criterion is met. In this paper, we compare against the second approach.\n\n#### yes, there are alternate ways also for halting criteria.",
        "The results for Lambada and the baselines on the two ProofWriter datasets are provided in Figure 1, and PrOntoQA results are shown in Figure 2. From the results, we observe that Lambada significantly outperforms the other two baselines, especially on ProofWriter-PUD which contains Unknown labels (44\\% relative improvement compared to CoT and 56\\% compared to SI on Depth-5) as well as on the higher depths of PrOntoQA (37\\% relative improvement compared to CoT and 113\\% compared to SI on Depth-5). These results show the merit of Lambada for logical reasoning and also show that backward chaining (which is the backbone of reasoning in Lambada) may be a better choice compared to forward chaining (the backbone in SI). The results also reveal a short-coming of the CoT approach in dealing with Unknown labels, as, unlike the examples for which the label is Proved or Disproved, there is no natural chain of thought for the examples whose labels are Unknown.\n\n#### We can observe that there's little over fitment of data. As it outperforms the other two baselines, especially on ProofWriter-PUD which contains Unknown labels (44% relative improvement compared to CoT and 56% compared to SI on Depth-5) as well as on the higher depths of PrOntoQA (37% relative improvement compared to CoT and 113% compared to SI on Depth-5).",
        "To understand the reason behind the high accuracy of CoT on higher depths of ProofWriter-PD, we randomly selected 50 examples from depth-5 of the dataset where CoT predicted the result correctly and manually verified if the proof chain is correct or not. For comparison, we also manually verified the proofs generated by Lambada following a similar procedure.\n\n#### The 50 examples were randomly selected.",
        "Based on the results of largest PaLM model in Figure 4, the Rule Selection module has the lowest accuracy among the different modules followed by the Goal Decomposition. In the case of Fact Check, when we allow the model to only select one fact the accuracy is 0.94 but that increases to a near perfect accuracy when we allow the model to select two facts. The Sign Agreement module also shows a near perfect accuracy.\n\n#### when we allow the model to just choose one fact the accuracy is 0.94 but that jumps to a near perfect accuracy when we enable the model to select two facts. The Sign Agreement module likewise exhibits a near flawless accuracy.",
        "We developed Lambada, an algorithm for text-based deductive logical reasoning that combines the capacity of LMs to handle naturalistic text input with the backward chaining (BC) algorithm for high-level reasoning. We showed that Lambada achieves significant improvements over competitive existing approaches such as Chain-of-Thought and Selection-Inference both in terms of prediction accuracy (predicting if a statement can be proved or disproved based on a theory) and proof accuracy. Furthermore, we demonstrated how Lambada efficiently searches the entire proof space to accurately conclude that a statement can neither be proved nor disproved based on the theory.\n\n#### Lambada can be adopted for other NLP tasks as Lambada is an algorithm for text-based deductive logical reasoning that combines the capacity of LMs to handle naturalistic text input with the BC algorithm for high-level reasoning. Lambada achieves significant improvements over existing approaches such as Chain-of-Thought and Selection-Inference in terms of prediction accuracy and proof accuracy.",
        "We developed Lambada, an algorithm for text-based deductive logical reasoning that combines the capacity of LMs to handle naturalistic text input with the backward chaining (BC) algorithm for high-level reasoning. We showed that Lambada achieves significant improvements over competitive existing approaches such as Chain-of-Thought and Selection-Inference both in terms of prediction accuracy (predicting if a statement can be proved or disproved based on a theory) and proof accuracy. Furthermore, we demonstrated how Lambada efficiently searches the entire proof space to accurately conclude that a statement can neither be proved nor disproved based on the theory.\n\n#### Lambada, is an algorithm for text-based deductive logical reasoning that combines the ability of LMs to handle realistic text input with the backward chaining (BC) technique for high-level reasoning.  Lambada makes considerable gains over competing current techniques such as Chain-of-Thought and Selection-Inference both in terms of prediction accuracy (predicting whether a proposition can be proven or refuted based on a theory) and proof accuracy. Furthermore, Lambada rapidly examines the full proof space to appropriately infer that a statement can neither be proven nor denied based on the theory.",
        "A number of approaches specifically look into whether LMs can generalize from examples requiring shorter reasoning chains (shown to them either as demonstration or as finetuning data) to examples requiring longer chains Anil et al. (2022); Tafjord et al. (2020). With our model, length generalization comes for free because the model learns the building blocks of solving the problem that are applied as many times as needed to solve the problem.\n\n#### the longer rule gave a validated fact check over the short rule in some examples but it doesn't hinder our intuition.",
        "The results for Lambada and the baselines on the two ProofWriter datasets are provided in Figure 1, and PrOntoQA results are shown in Figure 2. From the results, we observe that Lambada significantly outperforms the other two baselines, especially on ProofWriter-PUD which contains Unknown labels (44\\% relative improvement compared to CoT and 56\\% compared to SI on Depth-5) as well as on the higher depths of PrOntoQA (37\\% relative improvement compared to CoT and 113\\% compared to SI on Depth-5). These results show the merit of Lambada for logical reasoning and also show that backward chaining (which is the backbone of reasoning in Lambada) may be a better choice compared to forward chaining (the backbone in SI). The results also reveal a short-coming of the CoT approach in dealing with Unknown labels, as, unlike the examples for which the label is Proved or Disproved, there is no natural chain of thought for the examples whose labels are Unknown.\n\n#### The prediction of Unknown values does not have an influence on proved and disproved.",
        "During a proof, Lambada may be called multiple times with the same theory and goal; in Appendix A we explain how cycles and redundant computations can be avoided using a cache.\n\n#### Yes batch calls uses cache values.",
        "We conduct experiments with ProofWriter Tafjord et al. (2020) and PrOntoQA Saparov and He (2022) which are challenging datasets for LM reasoning containing examples requiring proof chains of up to 5 hops in length, and (in the former case) examples where the goal can neither be proved nor disproved from the provided theory. On these datasets, we show that Lambada has substantially higher deductive accuracy, and is considerably more likely to generate valid reasoning chains compared to other techniques which find correct conclusions with spurious proof traces, while also being more query efficient than other LM-based modular reasoning approaches. Our results strongly indicate that future work on reasoning with LMs should incorporate backward chaining or goal-directed strategies.\n\n#### No , the result substantially gets better with 5 hops",
        "We argue that the extent to which reasoning algorithms break the problem into sub-problem should be dependent on the scale and power of the LMs. If smaller LMs are used, then one may need to break the problem into sub-problems even further (e.g., further decomposing the one-to-many comparisons in the selection module). And as LMs become larger and stronger in the future, one could rely on them to solve problems even with a coarser-grained decomposition of the problem.\n\n#### If smaller LMs are utilised, then one may need to split the issue into sub-problems even more (e.g., further decomposing the one-to-many comparisons in the selection module) (e.g., further decomposing the one-to-many comparisons in the selection module)",
        "Lambada and SI require multiple LM inference call per example. In Figure 5, we compare the two models with respect to the average number of inference calls they make to the LM per example, for the different depths of the ProofWriter-PUD dataset. We observe that Lambada requires significantly fewer inference calls, especially at higher depths. For example, for Depth-1, Lambada requires 3.8x fewer calls whereas for Depth-5 it requires 11.8x fewer calls.\n\n#### Decreasing the depth by 1 requires fewer calls as compared to other values.",
        "For higher depths (3+), on the three datasets SI produces predictions that are close to the majority class prediction. We find that it tends to over-predict Disproved in the binary case and Unknown in the three-way classification case (cf. Appendix B.3), making it perform even worse than the majority class for Depth-5 of PrOntoQA which has more Proved labels than Disproved. However, we surprisingly observe that the performance of CoT remains relatively high for the ProofWriter-PD dataset, and the accuracy does not diminish. In the next sub-section, we verify the reason for this behaviour of CoT.\n\n#### Yes, the results are similar for other variants of values.",
        "In the case where we succeed in proving the antecedent of r, whether the goal is proved or disproved depends on whether the sign of the goal agrees or disagrees with the sign of the consequent of r. For instance, in Example 2, for the goal ‘‘Fiona is red?’’, since the sign of the goal agreed with the sign of the consequent of the second rule and the antecedent of the rule was proved, we concluded that the goal is proved. However, if the second rule was ‘‘Rough, nice people are not red.’’, then the sign of the goal would disagree with the sign of the consequent and so we would conclude that the goal is disproved. This motivates the fourth module, Sign Agreement, described next.\n\n#### No, the possibility of having many rules does not make it ambiguous.",
        "One solution to the aforementioned problems is to integrate the strength and reliability of classical AI models in logical reasoning with LMs Garcez and Lamb (2020); Marcus (2020).In the classic literature, there are two major approaches to logical reasoning Poole and Mackworth (2010):1.Forward Chaining (FC) where one starts from the facts and rules (“theory”), and iterates between making new inferences and adding them to the theory until the goal statement can be proved or disproved,2.Backward Chaining (BC) where one starts from the goal and recursively decomposes it into sub-goals until the sub-goals can be proved or disproved based on the facts.Previous approaches to reasoning with LMs mostly incorporate elements of FC into LMs Tafjord et al. (2020); Creswell et al. (2022). FC requires selecting a subset of facts and rules from the entire set which might be difficult for an LM as it requires a combinatorial search over a large space.Moreover, deciding when to halt and declare failure to prove is challenging in FC Creswell et al. (2022), sometimes requiring specialized modules trained on intermediate labels Creswell and Shanahan (2022). Indeed, the classic automated reasoning literature is heavily weighted towards BC or goal-directed strategies for proof-finding.\n\n#### The triggered sentence is \"One solution to the aforementioned problems is to integrate the strength and reliability of classical AI models in logical reasoning with LMs Garcez and Lamb \".",
        "These approaches break the problem into smaller modules and use separate LMs to solve each module Zhou et al. (2022b); Khot et al. (2022); Sprague et al. (2022); Zhou et al. (2022a).Most relevant to our work,in Tafjord et al. (2020), a single LM module iteratively and exhaustively derives all conclusions based on the facts and rules, and then the goal statement is checked against the final set of conclusions to confirm if it can be proved from the theory. Since exhaustively deriving all conclusions is computationally expensive, Creswell et al. (2022) consider an alternative approach with two modules: 1- selection, which, guided by the goal, selects a subset of the facts and rules from which new conclusions can be derived toward proving the goal, and 2- inference, which takes the selected facts and rules and derives a new conclusion. The two modules are called iteratively until a halting criterion is met. In this paper, we compare against the second approach.\n\n#### Yes, breaking the problem into sub-problems increases computation.",
        "We here view contemporary ML as limited to local gen- eralisation within a single task or well-deﬁned set of tasks that only holds when the training data used is independent- and-identically-distributed (i.i.d). ML is then limited when this does not hold or when it comes to causal inference and out-of-distribution (o.o.d) generalisation (Chollet 2019; Scholkopf et al. 2021).\n\n#### How trustworthy are ML decisions depends on many factors. Human understanding and trust in ML concerns not only understanding promoted decisions, but also, evaluating these decisions in relation to limitations built into the ML model. Limitations are introduced in ML systems by humans during the design phase. The approach towards understanding ML decisions builds on connecting human understandable concepts to the ML models knowledge representations with the goal of making them explicable. We here view contemporary ML as limited to local generalization within a single task or well-deﬁned set of tasks that only holds when the training data used is independent- and-identically-distributed (i.i.d). ML is then limited when this does not hold or when it comes to causal inference and out-of-distribution (o.o.d) generalization.",
        "ML systems increasingly affect many aspects of human life, gaining trust in their decisions is a central and active re- search area. What if -questions and the centrality of concepts is the focus for this review where we examine how concepts are extracted from a neural network. We presuppose a situ- ation where a human, with domain knowledge, use concepts to answer why-questions. In our review, we use the structure of D-N explanations and three types why-questions, What if I see? , What if I do? and What if I had done? as an ana- lytic lens to deepen and detail what we can expect, and not expect, from the research reviewed.\n\n#### What if -questions and the centrality of concepts is the focus for this review where we examine how concepts are extracted from a neural network. We presuppose a situation where a human, with domain knowledge, use concepts to answer why-questions. In our review, we use the structure of D-N explanations and three types why-questions, What if I see? , What if I do? and What if I had done? as an analytic lens to deepen and detail what we can expect, and not expect, from the research reviewed. No other questions are defined or handled in this paper.",
        "We now extend the DeepFool algorithm to the general case of multiclass differentiable classifiers. For general non-linear classifiers, the set P in Eq. (7) that describes the region of the space where the classifier outputs label \\hat{k}(\\bm{x}_{0}) is no longer a polyhedron. Following the explained iterative linearization procedure in the binary case, we approximate the set P at iteration i by a polyhedron \\tilde{P}_{i}P~i=⋂k=1c{\\displaystyle\\tilde{P}_{i}=\\bigcap_{k=1}^{c}\\Big{\\{}over~ start_ARG italic_P end_ARG start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ⋂ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT {\\displaystyle\\bm{x}:f_{k}(\\bm{x}_{i})-f_{\\hat{k}(\\bm{x}_{0})}(\\bm{x}_{i})(10)+∇fk(𝒙i)⊤𝒙−∇fk^⁢(𝒙0)(𝒙i)⊤𝒙≤0}.\\displaystyle+\\nabla f_{k}(\\bm{x}_{i})^{\\top}\\bm{x}-\\nabla f_{\\hat{k}(\\bm{x}_{0})}(\\bm{x}_{i})^{\\top}\\bm{x}\\leq 0\\Big{\\}}.+ ∇ italic_f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_x - ∇ italic_f start_POSTSUBSCRIPT over^ start_ARG italic_k end_ARG ( bold_italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ) end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT bold_italic_x ≤ 0 } .We then approximate, at iteration i, the distance between \\bm{x}_{i} and the complement of P, \\text{{dist}}(\\bm{x}_{i},P^{c}), by \\text{{dist}}(\\bm{x}_{i},\\tilde{P}_{i}^{c}). Specifically, at each iteration of the algorithm, the perturbation vector that reaches the boundary of the polyhedron \\tilde{P}_{i} is computed, and the current estimate updated.The method is given in Algorithm 2. It should be noted that the proposed algorithm operates in a greedy way and is not guaranteed to converge to the optimal perturbation in (1). However, we have observed in practice that our algorithm yields very small perturbations which are believed to be good approximations of the minimal perturbation. \n\n#### Yes, the authors use the common one-vs-all scheme \\hat{k}(\\bm{x})=\\operatorname*{arg\\,max}_{k}f_{k}(\\bm{x}).",
        "We compare the proposed DeepFool approach to state-of-the-art techniques to compute adversarial perturbations in [18] and [4]. The method in [18] solves a series of penalized optimization problems to find the minimal perturbation, whereas [4] estimates the minimal perturbation by taking the sign of the gradient\\displaystyle\\hat{\\bm{r}}(\\bm{x})=\\epsilon\\,\\text{sign}\\left(\\nabla_{\\bm{x}}J(\\bm{\\theta},\\bm{x},y)\\right),with J the cost used to train the neural network, \\bm{\\theta} is the model parameters, and y is the label of \\bm{x}. The method is called fast gradient sign method. In practice, in the absence of general rules to choose the parameter \\epsilon, we chose the smallest \\epsilon such that 90\\% of the data are misclassified after perturbation.555Using this method, we observed empirically that one cannot reach 100\\% misclassification rate on some datasets. In fact, even by increasing \\epsilon to be very large, this method can fail in misclassifying all samples.\n\n#### The fast gradient sign method is very quick but may lead to sub-optimal perturbations thus damaging the overall robustness estimation, and fine-tuning with such adversarial samples may sometimes result in a drop in the overall performance of the model. On the other hand, DeepFool creates adversarial perturbations that are closer to the absolute minimum compared to others thus giving us a more reliable tool in terms of robustness estimation and fine-tuning.",
        "Deep neural networks are powerful learning models that achieve state-of-the-art pattern recognition performance in many research areas such as bioinformatics [1, 16], speech [12, 6], and computer vision [10, 8]. Though deep networks have exhibited very good performance in classification tasks, they have recently been shown to be particularly unstable to adversarial perturbations of the data [18]. In fact, very small and often imperceptible perturbations of the data samples are sufficient to fool state-of-the-art classifiers and result in incorrect classification. (e.g., Figure 1). Formally, for a given classifier, we define an adversarial perturbation as the minimal perturbation \\bm{r} that is sufficient to change the estimated label \\hat{k}(\\bm{x}):\\displaystyle\\Delta(\\bm{x};\\hat{k}):=\\min_{\\bm{r}}\\|\\bm{r}\\|_{2}\\text{ subject to }\\hat{k}(\\bm{x}+\\bm{r})\\neq\\hat{k}(\\bm{x}),(1)where \\bm{x} is an image and \\hat{k}(\\bm{x}) is the estimated label. We call \\Delta(\\bm{x};\\hat{k}) the robustness of \\hat{k} at point \\bm{x}. The robustness of classifier \\hat{k} is then defined as\n\n#### Adversarial perturbation is a small and unnoticeable change to the data that fool the given model (i.e give a different class after applying the perturbation). It allows an understanding limits of existing architectures and calculation of the robustness of the models.",
        "In order to evaluate the robustness to adversarial perturbations of a classifier f, we compute the average robustness \\hat{\\rho}_{\\text{adv}}(f), defined by\\hat{\\rho}_{\\text{adv}}(f)=\\frac{1}{|\\mathscr{D}|}\\sum_{\\bm{x}\\in\\mathscr{D}}\\frac{\\|\\hat{\\bm{r}}(\\bm{x})\\|_{2}}{\\|\\bm{x}\\|_{2}},(15)where \\hat{\\bm{r}}(\\bm{x}) is the estimated minimal perturbation obtained using DeepFool, and \\mathscr{D} denotes the test set444For ILSVRC2012, we used the validation data..\n\n#### The metrics that are used to compare different methods of finding adversarial perturbations are: the average robustness of the model estimated in some type of norm (2-norm or infinity-norm in the paper); and the average running time needed to find the estimated minimal perturbation.",
        "Let f(\\bm{x}) be an affine classifier, i.e., f(\\bm{x})=\\mathbf{W}^{\\top}\\bm{x}+\\bm{b} for a given \\mathbf{W} and \\bm{b}. Since the mapping \\hat{k} is the outcome of a one-vs-all classification scheme, the minimal perturbation to fool the classifier can be rewritten as follows\\begin{split}&\\operatorname*{arg\\,min}_{\\bm{r}}\\|\\bm{r}\\|_{2}\\\\&\\text{s.t. }\\exists k:\\bm{w}_{k}^{\\top}(\\bm{x}_{0}+\\bm{r})+b_{k}\\geq\\bm{w}_{\\hat{k}(\\bm{x}_{0})}^{\\top}(\\bm{x}_{0}+\\bm{r})+b_{\\hat{k}(\\bm{x}_{0})},\\end{split}(6)where \\bm{w}_{k} is the k^{\\text{th}} column of \\mathbf{W}. Geometrically, the above problem corresponds to the computation of the distance between \\bm{x}_{0} and the complement of the convex polyhedron P,\\displaystyle P=\\bigcap_{k=1}^{c}\\{\\bm{x}:f_{\\hat{k}(\\bm{x}_{0})}(\\bm{x})\\geq f_{k}(\\bm{x})\\},(7)where \\bm{x}_{0} is located inside P.We denote this distance by \\text{{dist}}(\\bm{x}_{0},P^{c}).The polyhedron P defines the region of the space where f outputs the label \\hat{k}(\\bm{x}_{0}). This setting is depicted in Figure 4. The solution to the problem in Eq. (6) can be computed in closed form as follows. Define \\hat{l}(\\bm{x}_{0}) to be the closest hyperplane of the boundary of P (e.g. \\hat{l}(\\bm{x}_{0})=3 in Figure 4). Formally, \\hat{l}(\\bm{x}_{0}) can be computed as follows\\hat{l}(\\bm{x}_{0})=\\operatorname*{arg\\,min}_{k\\neq{\\hat{k}(\\bm{x}_{0})}}\\frac{\\left|f_{k}(\\bm{x}_{0})-f_{\\hat{k}(\\bm{x}_{0})}(\\bm{x}_{0})\\right|}{\\|\\bm{w}_{k}-\\bm{w}_{\\hat{k}(\\bm{x}_{0})}\\|_{2}}.(8)The minimum perturbation \\bm{r}_{*}(\\bm{x}_{0}) is the vector that projects \\bm{x}_{0} on the hyperplane indexed by \\hat{l}(\\bm{x}_{0}), i.e.,\\bm{r}_{*}(\\bm{x}_{0})=\\frac{\\left|f_{\\hat{l}(\\bm{x}_{0})}(\\bm{x}_{0})-f_{\\hat{k}(\\bm{x}_{0})}(\\bm{x}_{0})\\right|}{\\|\\bm{w}_{\\hat{l}(\\bm{x}_{0})}-\\bm{w}_{\\hat{k}(\\bm{x}_{0})}\\|_{2}^{2}}(\\bm{w}_{\\hat{l}(\\bm{x}_{0})}-\\bm{w}_{\\hat{k}(\\bm{x}_{0})}).(9)In other words, we find the closest projection of \\bm{x}_{0} on faces of P.\n\n#### The affine classifier is the classifier in the form of an affine function. The general form that is used in the paper is the function f: R^n -> R^m, where f(x) = W^T * x + B, for the given matrix and vector W and B.",
        "In practice, the above algorithm can often converge to a point on the zero level set \\mathscr{F}. In order to reach the other side of the classification boundary, the final perturbation vector \\hat{\\bm{r}} is multiplied by a constant 1+\\eta, with \\eta\\ll 1. In our experiments, we have used \\eta=0.02. \n\n#### The perturbation constant that is used is n = 0.02.",
        "It can be seen that DeepFool estimates smaller perturbations (hence closer to minimal perturbation defined in (1)) than the ones computed using the competitive approaches. For example, the average perturbation obtained using DeepFool is 5 times lower than the one estimated with [4]. On the ILSVRC2012 challenge dataset, the average perturbation is one order of magnitude smaller compared to the fast gradient method. It should be noted moreover that the proposed approach also yields slightly smaller perturbation vectors than the method in [18]. The proposed approach is hence more accurate in detecting directions that can potentially fool neural networks. As a result, DeepFool can be used as a valuable tool to accurately assess the robustness of classifiers.On the complexity aspect, the proposed approach is substantially faster than the standard method proposed in [18].In fact, while the approach [18] involves a costly minimization of a series of objective functions, we observed empirically that DeepFool converges in a few iterations (i.e., less than 3) to a perturbation vector that fools the classifier. Hence, the proposed approach reaches a more accurate perturbation vector compared to state-of-the-art methods, while being computationally efficient. This makes it readily suitable to be used as a baseline method to estimate the robustness of very deep neural networks on large-scale datasets. In that context, we provide the first quantitative evaluation of the robustness of state-of-the-art classifiers on the large-scale ImageNet dataset. It can be seen that despite their very good test accuracy, these methods are extremely unstable to adversarial perturbations: a perturbation that is 1000 smaller in magnitude than the original image is sufficient to fool state-of-the-art deep neural networks.\n\n#### The authors only claim that the DeepFool can be used as a baseline for adversarial perturbation calculation and that it heavily depends on existing optimization methods. In the paper, its effectiveness is proven relative to other state-of-the-art methods. Although the analysis of how far the estimated perturbation from the actual minimal perturbation can be found in referenced papers, the more sophisticated analysis is not mentioned in the paper. Thus, it is difficult to answer the question entirely.",
        "We then approximate, at iteration i, the distance between xi and the complement of P , dist(xi, P c), by dist(xi,  ̃P c i ). Specifically, at each iteration of the algorithm, the perturbation vector that reaches the boundary of the polyhedron  ̃Pi is computed, and the current estimate updated. The method is given in Algorithm 2. It should be noted that the proposed algorithm operates in a greedy way and is not guaranteed to converge to the optimal perturbation in (1). However, we have observed in practice that our algorithm yields very small perturbations which are believed to be good approximations of the minimal perturbation.\n\n#### The DeepFool method is designed iteratively starting from very simple binary classifiers to more general non-linear differentiable classifiers. The effectiveness of the greedy algorithm is justified by previous work and the results show very small perturbations, thus the authors claim that it is a viable method. However, it is difficult to answer the question fully just from the information in the paper.",
        "We now test our DeepFool algorithm on deep convolutional neural networks architectures applied to MNIST, CIFAR-10, and ImageNet image classification datasets. We consider the following deep neural network architectures:•MNIST: A two-layer fully connected network, and a two-layer LeNet convoluational neural network architecture [9]. Both networks are trained with SGD with momentum using the MatConvNet [20] package.•CIFAR-10: We trained a three-layer LeNet architecture, as well as a Network In Network (NIN) architecture [11].•ILSVRC 2012: We used CaffeNet [7] and GoogLeNet [17] pre-trained models.\n\n#### Although the conclusion of the paper claims that 8 different classifiers were used, we can only see 6 classifiers with different datasets: 2-layer fully-connected network (MNIST), 2-layer LeNet (MNIST), 3-layer LeNet (CIFAR-10), NIN (CIFAR-10), CaffeNet (ILSVRC 2012), and GoogLeNet (ILSVRC 2012).",
        "In this paper, we have measured the perturbations using the \\ell_{2} norm. Our framework is however not limited to this choice, and the proposed algorithm can simply be adapted to find minimal adversarial perturbations for any \\ell_{p} norm (p\\in[1,\\infty)). To do so, the update steps in line 10 and 11 in Algorithm 2 must be respectively substituted by the following updates\\displaystyle\\hat{l}\\displaystyle\\leftarrow\\operatorname*{arg\\,min}_{k\\neq{\\hat{k}(\\bm{x}_{0})}}\\frac{\\left|f^{\\prime}_{k}\\right|}{\\|\\bm{w}^{\\prime}_{k}\\|_{q}},(11)\\displaystyle\\bm{r}_{i}\\displaystyle\\leftarrow\\frac{|f^{\\prime}_{\\hat{l}}|}{\\|\\bm{w}^{\\prime}_{\\hat{l}}\\|_{q}^{q}}|\\bm{w}^{\\prime}_{\\hat{l}}|^{q-1}\\odot\\text{sign}(\\bm{w}^{\\prime}_{\\hat{l}}),(12)where \\odot is the pointwise product and q=\\frac{p}{p-1}.333To see this, one can apply Holder’s inequality to obtain a lower bound on the \\ell_{p} norm of the perturbation. In particular, when p=\\infty (i.e., the supremum norm \\ell_{\\infty}), these update steps become\\displaystyle\\hat{l}\\displaystyle\\leftarrow\\operatorname*{arg\\,min}_{k\\neq{\\hat{k}(\\bm{x}_{0})}}\\frac{\\left|f^{\\prime}_{k}\\right|}{\\|\\bm{w}^{\\prime}_{k}\\|_{1}},(13)\\displaystyle\\bm{r}_{i}\\displaystyle\\leftarrow\\frac{|f^{\\prime}_{\\hat{l}}|}{\\|\\bm{w}^{\\prime}_{\\hat{l}}\\|_{1}}\\text{sign}(\\bm{w}^{\\prime}_{\\hat{l}}).(14)\n\n#### The authors claim that the DeepFool algorithm is a well-founded baseline for finding adversarial perturbations for state-of-the-art models. Although the use of the l-2 norm is not explicitly justified within the paper, it is a reasonable choice taking into account the scarcity of baseline methods. Also, the method can be easily adapted to any l-p norm and the claims of the paper seem to hold for the l-infinity norm.",
        "In this paper, we have measured the perturbations using the \\ell_{2} norm. Our framework is however not limited to this choice, and the proposed algorithm can simply be adapted to find minimal adversarial perturbations for any \\ell_{p} norm (p\\in[1,\\infty)). To do so, the update steps in line 10 and 11 in Algorithm 2 must be respectively substituted by the following updates\\displaystyle\\hat{l}\\displaystyle\\leftarrow\\operatorname*{arg\\,min}_{k\\neq{\\hat{k}(\\bm{x}_{0})}}\\frac{\\left|f^{\\prime}_{k}\\right|}{\\|\\bm{w}^{\\prime}_{k}\\|_{q}},(11)\\displaystyle\\bm{r}_{i}\\displaystyle\\leftarrow\\frac{|f^{\\prime}_{\\hat{l}}|}{\\|\\bm{w}^{\\prime}_{\\hat{l}}\\|_{q}^{q}}|\\bm{w}^{\\prime}_{\\hat{l}}|^{q-1}\\odot\\text{sign}(\\bm{w}^{\\prime}_{\\hat{l}}),(12)where \\odot is the pointwise product and q=\\frac{p}{p-1}.333To see this, one can apply Holder’s inequality to obtain a lower bound on the \\ell_{p} norm of the perturbation. In particular, when p=\\infty (i.e., the supremum norm \\ell_{\\infty}), these update steps become\\displaystyle\\hat{l}\\displaystyle\\leftarrow\\operatorname*{arg\\,min}_{k\\neq{\\hat{k}(\\bm{x}_{0})}}\\frac{\\left|f^{\\prime}_{k}\\right|}{\\|\\bm{w}^{\\prime}_{k}\\|_{1}},(13)\\displaystyle\\bm{r}_{i}\\displaystyle\\leftarrow\\frac{|f^{\\prime}_{\\hat{l}}|}{\\|\\bm{w}^{\\prime}_{\\hat{l}}\\|_{1}}\\text{sign}(\\bm{w}^{\\prime}_{\\hat{l}}).(14)\n\n#### To adapt the algorithm to use any l-p norm, only 2 lines in the algorithm (10 and 11) should be substituted with \\displaystyle\\hat{l}\\displaystyle\\leftarrow\\operatorname*{arg\\,min}_{k\\neq{\\hat{k}(\\bm{x}_{0})}}\\frac{\\left|f^{\\prime}_{k}\\right|}{\\|\\bm{w}^{\\prime}_{k}\\|_{q}},(11)\\displaystyle\\bm{r}_{i}\\displaystyle\\leftarrow\\frac{|f^{\\prime}_{\\hat{l}}|}{\\|\\bm{w}^{\\prime}_{\\hat{l}}\\|_{q}^{q}}|\\bm{w}^{\\prime}_{\\hat{l}}|^{q-1}\\odot\\text{sign}(\\bm{w}^{\\prime}_{\\hat{l}}), where q = p/(p-1).",
        "Overall, we observed very few works on hair diseases. The recent related works lack at least one of the following categories – discussion over false positive and false negative rates, ignoring inter-class differences, model reliability, and overfitting problem. In this work, we have attempted to fill these gaps by leveraging a convolutional neural network\n\n#### There is multiple important features in a model to consider: false positive and false negative rates, ignoring inter-class differences, model reliability, and overfitting problem. But the paper doesn’t mention which is the most important feature of the model. Therefore the question is not completely answerable.",
        "Alopecia, folliculitis, and psoriasis are some common causes of hair loss. There is a difference between regular hair fall and alopecia; the latter develops coin-sized bald patches all over the scalp area. Alopecia or patchy hair loss can be of different types. Androgenetic alopecia or male-pattern baldness (MPB) is the most common form of alopecia where the hairline starts to recede, following a pattern where the frontal and temple area are most affected. 70% of men and 40% of women get this type of hair loss and thinning issue [3]. According to Liu et al., MPB is an X-linked polygenic disease, and males are more genetically prone to develop baldness at a mature age [5]. Topical minoxidil solution thickens the hair by 50% [3]. On the other hand, Alopecia areata (AA) is an autoimmune disease affecting individuals irrespective of age and sex. Primarily affecting the scalp area, AA can also spread in the beard, eyelashes, and eyebrows. In this case, the body’s immune cells cannot recognize hair follicles as ‘self.’ Instead, they consider these follicles as ‘foreign,’ which ultimately causes the hair follicles to be\n\n#### MPB is an X-linked polygenic\ndisease, and males are more genetically prone to develop baldness at a mature age. That's why MPB is less severe in women as compared to men.",
        "Hair, made of keratin protein, pertains to beauty and masculinity. Approximately 5 million hair follicles are present throughout our body [1]. Scalp Hair maintains body temperature and protects the brain from external heat. A typical hair growth cycle runs for 2-7 years, according to Patel et al. [2] and Wolff, Fischer, and Blume-Peytavi [3]. A healthy human has 100,000 hairs on the scalp, and 50-100 hair loss per day is considered normal. Hair loss is not a present-day issue. The hair-loss treatment was found in ancient Ayurveda scriptures 6000 years ago [2]. However, Hair and scalp-related issues are gaining more recognition nowadays compared to earlier years due to certain factors, such as environmental pollution, hormonal imbalance, autoimmune disease, gut microbiota alteration, elevated physical and mental stress levels in human lifestyle, seasonal change, unhealthy diet, micronutrient deficiency, genetic predisposition, and side-effects of drugs [2], [3]. According to Peyravian et al., 80 million Americans have hair loss- related issues to some extent [4]. Although most hair loss diseases are localized, some can spread to other locations. Some diseases require prescribed drugs and hair\n\n#### The paper only says that the hair-loss treatment was found in ancient Ayurved by citing another paper, but it didn't discussed the various treatment found in ayurved for hair loss. Therefore, the question cannot be answered.",
        "targeted and destroyed by the immune cells. It is an example of a hereditary disease. The study from Benigno et al. reported that, in the US alone, 700,000 individuals suffer from AA [6]. This disease, if diagnosed early, might resolve spontaneously. In severe cases, topical corticosteroid or immune therapy is used [3].\n\n#### P0 discussed that for AA treatment immune therapy is used. But how does it helps is not discussed. Therefore the question cannot be answered.",
        "Some scalp infections may be treatable if diagnosed early. Some but not all diseases may go on their own. Only an expert physician can detect the illness by visual observation. In some cases, early disease detection is beneficial for dermatologists to initiate the treatment. An early scalp inspection includes a dermatoscopic examination of the scalp for inflammation, itching, localized lesion, dandruff, follicular flakes, louse eggs (nits), and a scalp biopsy. Besides visual observation, the patient can undergo blood and hormone tests to detect the exact disease. Unfortunately, most hair and scalp diseases are diagnosed in advanced stages, which complicate the treatment options. All these factors lengthen the diagnosis and treatment process. Therefore, researchers are putting more effort into developing different mechanisms for the early detection of hair and scalp diseases.\n\n#### Although early-stage detection of hair and scalp-related diseases is the key to the treatment process, hair loss and scalp diseases can often go undetected due to a lack of awareness and a lengthy diagnosis test.  An AI-based application might pave the way to facilitate early disease detection. Disease detection using machine learning approaches is gaining popularity in health informatics. Therefore, AI-based approach for fast detection is a good way to make people go for the early diagnosis of the hair diseases.",
        "The most challenging part of using visual images for disease prediction and disease classification is data collection. Often, one can get fewer appropriate images for a specific illness found. Moreover, the pictures are scattered over the internet. In this study, the authors extracted the images from different websites, such as DermQuest, DermNet, MedicineNet, DermnetNZ, and various medical professionals.\n\n#### In this study, the authors extracted the images from different websites, such as DermQuest, DermNet, MedicineNet, DermnetNZ, and various medical professionals. Therefore the paper answered the question directly.",
        "In this section, we introduce the system workflow of our model and explain the functions of each module in details. As shown in Fig. 2, first, the captured image is sent to preprocessing steps which are divided into three parts: image equalization, image enhancement, and data balancing.\n\n#### The three preprocessing steps used in this paper are image equalization, image enhancement, and data balancing. First two parts are mainly for increasing image quality, and the last part is for model versatility. The paper answer the question directly.",
        "Another study [19] proposed a model for early alopecia detection. They used 100 samples for this research, with 80% as training data and the other 20% as testing data. They looked for four attributes, length of the hair, nail brittleness, amount of damage made to the hair, and hair follicle. Two- layer feed-forward network with a back propagation technique was used for detection purposes. The proposed model system consisting of 4 input neurons, 10 hidden neurons, and a linear output neuron, achieved 91% training accuracy with 86.7% validation accuracy. It showed the best performance at epoch 4 with a 0.059687 gradient. However, the study has some pitfalls, too, as they did not mention their data source or differentiate data classes with their respective sample sizes. Also, no image pre-processing was performed on the collected images. Although there is a possibility of overfitting without a proper data balancing technique, this report did not discuss the data balancing between the two classes. Furthermore, they did not calculate the model’s false- positive and false-negative rates, which is crucial for a model specially developed for the healthcare system.\n\n#### In all the models - CNN or SVM or FNN gets very high accuracy. In all the experiment number of dataset is very limited. Since there is no experiment on smaller/higher dataset, it is difficult to answer weather the CNN really achieving that accuracy or not with this limited dataset. Therefore, this paper doesn't fully answer this question.",
        "Noise is the degradation of image signals caused by external sources [23]. Noise introduces random variations of brightness or color information in the captured images. Most of the time, images on the internet have some noise associated with them. As we have collected most of the data samples from different dermatology websites, the noise in our dataset is not homogeneously distributed, which made it more complex. Therefore, we applied additional filters for\n\n#### The author tested images on multiple filters including gaussian filter, median filter with kernel_size = 3, bilateral filter, and non-local means filter with patch_size = 3 and patch_distance = 5. Comparing with other filter non-local means filter best result by preserving all the edges and reducing noise.",
        "extracted from the images: texture, shape, and color. The researchers divided the dataset into 70%-30% train-test-split and applied a support vector machine (SNM) and k-nearest neighbor (KNN) for the classification task. Overall, they achieved 91.4% and 88.9% accuracy using SVM and KNN, respectively, with a 10-fold cross-validation approach. However, using other machine learning algorithms might increase in the accuracy rate, which should have been discussed. Besides, the application of Histogram Equalization (HE) for image enhancement complicated the process of getting accurate texture features from distorted images, as HE itself adds noise to the output image, distorting the signals. Moreover, this study only shed light on alopecia areata disease, ignoring the inter-class differences between other similar type diseases, which increased the likelihood of inaccurate prediction of other diseases as alopecia areata, thereby making this framework less reliable.\n\n#### Input image gets high contrast when pass through HE and hence loose information by adding noise. Compare to that CLAHE is a adaptive histogram equalization method in which the contrast amplification is limited, so as to reduce this problem of noise amplification.",
        "In this study, CNN is utilized for classification because it takes image’s raw pixel data, trains a model, and extracts the features automatically for better detection. We used autokeras to find the best model for this problem. After trying 25 different combinations, we selected 3 hidden layers with 1 input and 1 output layer as our final model which is shown in Fig. 5. For training the model, we used batch_size = 16 with 50 epochs for each batch. The preprocessed data is divided into 70-30 train-test-split for training and validation purpose. Our model consists of 256 inputs, 3 x 3 square kernel, 3 output units and a softmax output. We used ReLU as our activation function to prevent the exponential growth of required computation and to explore the non-linear relationship between input and output variables. After each convolutional layer, input goes through the pooling layer having 2 x 2 kernel size to reduce the dimensions of the features map. Pooling layer summarizes the presented features in a region and helps to prevent the over-fitting problem by down sampling. We also used dropout layer after each pooling layer to prevent neurons in a layer from synchronously optimizing their weights and converging to the same goal. Our model’s dropout rate is 0.3, which means 30% of the neurons of this layer will be randomly dropped in each epoch.\n\n#### Autokeras is best way to find model parameter. It automatically tries different combination (in this case is 25) and find size of the model network. In this case the best size is 3 hidden layer with 1 input and 1 output.",
        "In this study, CNN is utilized for classification because it takes image’s raw pixel data, trains a model, and extracts the features automatically for better detection. We used autokeras to find the best model for this problem. After trying 25 different combinations, we selected 3 hidden layers with 1 input and 1 output layer as our final model which is shown in Fig. 5. For training the model, we used batch_size = 16 with 50 epochs for each batch. The preprocessed data is divided into 70-30 train-test-split for training and validation purpose. Our model consists of 256 inputs, 3 x 3 square kernel, 3 output units and a softmax output. We used ReLU as our activation function to prevent the exponential growth of required computation and to explore the non-linear relationship between input and output variables. After each convolutional layer, input goes through the pooling layer having 2 x 2 kernel size to reduce the dimensions of the features map. Pooling layer summarizes the presented features in a region and helps to prevent the over-fitting problem by down sampling. We also used dropout layer after each pooling layer to prevent neurons in a layer from synchronously optimizing their weights and converging to the same goal. Our model’s dropout rate is 0.3, which means 30% of the neurons of this layer will be randomly dropped in each epoch.\n\n#### Using grid search the batch_size and epochs is determined. Since these are the optimal value hence used in the training.",
        "We trained our CNN model using the optimal hyperparameters selected from the grid search. These hyperparameters are listed in Table II. We divided the dataset into 70%-30% train-test-split where 105 randomly selected images are used for training and 45 random images for testing. After applying the preprocessing steps, we used the training dataset to train the CNN model and evaluated the test dataset using the model.\n\n#### Hyperparameters are Batch Size 16, Epoch 50, Kernel Size 3 x 3, Optimizer Adam, Dropout Rate 0.3, Pooling Size 2 x 2, Activation Function ReLU.",
        "We trained our CNN model using the optimal hyperparameters selected from the grid search. These hyperparameters are listed in Table II. We divided the dataset into 70%-30% train-test-split where 105 randomly selected images are used for training and 45 random images for testing. After applying the preprocessing steps, we used the training dataset to train the CNN model and evaluated the test dataset using the model.\n\n#### Optimal hyperparameter is used. Hence for epoch it is the optimal value. More epochs will not give us better accuracy.",
        "Related work [20] was performed on skin disease detection, where machine learning was used to analyze the digital image of the affected skin area for identifying eczema, melanoma, and psoriasis. Their dataset consists of 80 images from different websites specific to skin diseases. By using a convolutional neural network for feature extraction and applying multiclass SVM on those features, they achieved 100% accuracy in disease classification. However, they did not explore other essential model performance matrices and overfitting issues. In another skin disease detection-based article [21], the authors proposed a scheme to classify skin lesions into five categories: healthy, acne, eczema, benign, and malignant melanoma, using a pre-trained CNN model, AlexNET for feature extraction and error correcting output codes support vector machine for classification. The dataset consists of 9144 images from different sources and achieved 84.21% accuracy using a 10-fold cross-validation technique.\n\n#### The author discussed effectiveness of pre-trained network in previous work, however, they never used it for their model. There is no evidence to answer this question.",
        "Alopecia, folliculitis, and psoriasis are some common causes of hair loss. There is a difference between regular hair fall and alopecia; the latter develops coin-sized bald patches all over the scalp area. Alopecia or patchy hair loss can be of different types. Androgenetic alopecia or male-pattern baldness (MPB) is the most common form of alopecia where the hairline starts to recede, following a pattern where the frontal and temple area are most affected. 70% of men and 40% of women get this type of hair loss and thinning issue [3]. According to Liu et al., MPB is an X-linked polygenic disease, and males are more genetically prone to develop baldness at a mature age [5]. Topical minoxidil solution thickens the hair by 50% [3]. On the other hand, Alopecia areata (AA) is an autoimmune disease affecting individuals irrespective of age and sex. Primarily affecting the scalp area, AA can also spread in the beard, eyelashes, and eyebrows. In this case, the body’s immune cells cannot recognize hair follicles as ‘self.’ Instead, they consider these follicles as ‘foreign,’ which ultimately causes the hair follicles to be\n\n#### Alopecia areata (AA) is an autoimmune disease where the body’s immune cells cannot recognize hair follicles as ‘self.’ Instead, they consider these follicles as ‘foreign'. It is an example of a hereditary disease. But the paper didn't fully discussed why the cell can't recognise hair follicle as 'self'. Therefore the question cannot be answered fully.",
        "Acute pulmonary infection (pneumonia) is a condition in which the lungs become inflamed due to infection with bacteria, viruses, or fungi; this leads to a condition known as pleural effusion, in which the lungs become swollen with fluid. More than 15% of all deaths in children younger than 5 can be attributed to this cause. Countries with high rates of population growth, pollution, and poor sanitation have the highest rates of pneumonia, and these countries also have\n\n#### The question is directly verify as True from the statement that, more than 15% of all deaths in children younger than 5 can be attributed to this cause.",
        "CNN has built a model of the human brain using the mixture of these networks. CNN layers are organized so that simpler patterns (lines, curves, etc.) are detected initially and more complicated patterns (faces, objects, etc.) are detected afterwards. However, CNN has drawn a lot of interest in data science since it has demonstrated its ability to locate, segment, and identify objects in images. In this study, the term \"original CNN architecture\" refers to a CNN network and algorithm that are available on Keras or Github. In this study, the CNN algorithm is used exactly as its creators and programmers intended it to be, with no modifications to its processing units, parameterization and hyper-parameter optimization methodologies, design patterns, or layer connections. A well-known CNN network was frequently created and improved by several researchers and programmers over the course of numerous difficulties.\n\n#### The paper directly didn't mentioned the difference between CNN and D-CNN. But it is referable from P1 and P2 that, D-CNN multilayered, hierarchical and block-structure compare to CNN.",
        "voting are some of the ensemble techniques that have been utilized in research in the literature most frequently. Each constituent base learner is given equal priority by the average probability-based ensemble. But for a specific issue, one basic classifier might be better equipped to gather data than another. Therefore, weighting all of the base classifiers is a better technique. However, the importance of the weights given to each classifier is the most important component in ensuring the ensemble's improved performance. The majority of methods base this number on the outcomes of experiments. In this study, we developed a novel weight allocation method in which the best weights for three base CNN models—SeresNet152, ResNet152v2, and DenseNet- 201, Vgg-19, and Resnext101—were determined using four evaluation metrics: precision, recall, f1-score, and area under the receiver operating characteristics (ROC) curve (AUC). For providing weights to the base learners in research in the literature, only classification accuracy was often taken into account [8], which may not be a sufficient metric, especially when the datasets are class imbalanced. Other indicators might offer more useful data for deciding how important the basic learner is.\n\n#### In P1 the author mentioned they developed a novel weight allocation method. That answer the question that the author used weighted avg. probability in modelling.",
        "Because the dataset used in this experiment did not have any severe imbalances, the standard deviation was used as a model performance parameter in this study. Because this work deals with multi-class sorting, categorical cross- entropy was chosen as a loss task for all CNN architectures. The activation function employed in all transitional layers of the CNN architectures used in this study was relu, while the last layer's activation function was softmax. The following are the hyperparameters that were used: The dropout rate was 0.3, the learning rate was 0.0001, the batch size was 17, and there were 36 epochs. The model weights were updated using an adaptive moment estimation (Adam) optimizer. Before the resizing, all of the photographs were shrunk to the default image size for each architecture.\n\n#### Standard deviation was used as a model performance parameter in this study.",
        "Because the dataset used in this experiment did not have any severe imbalances, the standard deviation was used as a model performance parameter in this study. Because this work deals with multi-class sorting, categorical cross- entropy was chosen as a loss task for all CNN architectures. The activation function employed in all transitional layers of the CNN architectures used in this study was relu, while the last layer's activation function was softmax. The following are the hyperparameters that were used: The dropout rate was 0.3, the learning rate was 0.0001, the batch size was 17, and there were 36 epochs. The model weights were updated using an adaptive moment estimation (Adam) optimizer. Before the resizing, all of the photographs were shrunk to the default image size for each architecture.\n\n#### Standard deviation was used as a model performance parameter in this study.",
        "The performances of the six original individual CNN networks SecrensNet152, MobileNetV2, VGG19, ResNet152v2, ResNeXt100 and DenseNet201 are presented in this section. The models' classification performance is first presented. Following that, the overall measures for those models are discussed. gathering, in addition to descriptors, potential causes, and areas for improvement of results.\n\n#### The various CNN architecture author talks about are SecrensNet152, MobileNetV2, VGG19, ResNet152v2, ResNeXt101 and DenseNet201. The above paragraph directly answer the question.",
        "We used data augmentation methods to achieve the goals in the training data. However, color enhancement, such as brightness, contrast, and saturation, as well as position enhancement, by way of scaling, cropping, flipping, and revolution, was used. The technique of data enhancement also included random rotations from -15 to 15 degrees, rotations of 90 degrees by accident, accidental distortion, bending, vertical reversal, horizontal reversal, skate, and luminous intensity conversion. In this approach, 10 enhanced images were created from each original image. The selection of a subset of transformations helps to enhance a heterogeneous image.\n\n#### 10 enhanced images were created from each original image. But it doesn't directly answer how many for each class. We can refer that 10 times extra images is generated for each class.",
        "Because the dataset used in this experiment did not have any severe imbalances, the standard deviation was used as a model performance parameter in this study. Because this work deals with multi-class sorting, categorical cross- entropy was chosen as a loss task for all CNN architectures. The activation function employed in all transitional layers of the CNN architectures used in this study was relu, while the last layer's activation function was softmax. The following are the hyperparameters that were used: The dropout rate was 0.3, the learning rate was 0.0001, the batch size was 17, and there were 36 epochs. The model weights were updated using an adaptive moment estimation (Adam) optimizer. Before the resizing, all of the photographs were shrunk to the default image size for each architecture.\n\n#### Since hyperparameters tunning need computation resources and those are limited, the authors used set value of various parameter.",
        "The personality prediction is supported in this work by a questionnaire-based investigation. Openness to criticism, flexibility, team spirit, aspirations, and work ethics are among the traits that personality interview questions reveal. This aids to figure out how well a candidate may collaborate and work with team members. The responses to these queries give insight into the qualifications for the position The K- Modes clustering method is used in this survey-based investigation. The technique, which is simple to use and effective with vast amounts of data, is used to group categorical data. Based on the number of comparable categories between data points, clusters are defined. The k- modes clustering algorithm is an advancement over the k- means clustering method. K-means is the most widely used centre-based partitional clustering technique. Huang extends the k-means clustering method to the k-modes clustering algorithm to organize the categorical data:\n\n#### K-Modes clustering is more accurate than using K-means clustering as the K-mode algorithm uses categorical data to form clusters. Since the data in this paper is categorical, K-Modes is used. This question is found directly in the paper.",
        "This article makes suggestions for using the Ocean model based on AVI (referred to as AVI-AI) or the Big Five personality traits to forecast a person's personality [3]. AVI- AI methods have drawn a lot of interest in the disciplines of computer sciences and human resources, particularly for autonomously evaluating personality traits [4] and communication skills [5]. Unknown are the reliability and accuracy of the ground-breaking employment selection tool known as AVI-AI. Automatically conducting interviews at a specific time is possible with the help of asynchronous video interviewing technology (AVI). The interview can be reviewed by employers at a later time. If employers want to examine how the candidates replied to the questions, they may also allow anyone to watch the recorded interview. It is difficult for human reviewers to accurately.\n\n#### AVI-AI is a AI based asynchronous video interviewing technology that helps to automate administrative tasks.",
        "To estimate scores, several artificial neural networks (ANNs) were trained on a sizable labelled dataset. It utilised a cascade of ANNs to forecast personality traits from static face images to examine the connections between signals from stationary facial expression cues and self-reported personality traits. The finding provides strong evidence that multidimensional personality profiles can be predicted using ANNs trained on substantial labelled datasets from static facial photos. According to the study, advanced computer vision algorithms can be used to realise personality traits in real-world photos obtained in unexpected situations. shows unequivocally that each of the Big Five features is connected to a collection of face clues that can be gathered by using machine learning methods. [15]\n\n#### Face clues, personality scores, common sense knowledge and psycho-linguistic features are used to judge person facial emotion and speech emotion.",
        "end-to-end AI conducting interviews system. The above system performs automatic personality recognition based on features extracted from the AVIs and the genuine personality scores from the respondents' self-reported survey questions and facial gestures. Employers can later evaluate sound records using this method [32]. Based on the above studies to determine a person's personality, we have employed K-Model clustering and the OCEAN model to predict the personalities.\n\n#### AVI-AI is a end-to-end AI conducting interviews system. The above system performs automatic personality recognition based on features extracted from the AVIs.",
        "Automated interviewing enhances evaluation consistency by establishing an organized and objective hiring procedure, assisting recruiters in quickly identifying the greatest fit.\n\n#### Automated interviewing enhances evaluation consistency by establishing an organized and objective hiring procedure, assisting recruiters in quickly identifying the greatest fit. As said in the paper, by developing an orderly and objective hiring approach proposed model increases the reliablity of the assesment.",
        "Automated video interviews are efficient in more ways than one. They not only make it possible to schedule several interviews at once quickly, but they can also do it anywhere. As a result, the business can utilize the skills of a worker who is employed elsewhere in the world but is unable to relocate for a variety of reasons.\n\n#### Yes. It is true. Proposed model enhances the efficiency of the interviews by conducting multiple at the same time also makes it place-independent.",
        "To assess how well current employees are working, individual work performance (IWP), a useful and regularly used outcome measure, is often utilized. Job performance may be correlated with personality. The phrase \"behaviours or acts that are related to the aims of the organization\" [7] is a definition of IWP. IWP thus emphasizes employee behaviours or activities rather than the outcomes of those behaviours. Additionally, behaviours should be in the individual's control, omitting those that are limited by the environment [8]. The personalities of the employees at any given time can be ascertained from their answers to a series of questions that can be given to them. The first dimension, task performance, traditionally has received the most attention and can be defined as \"the proficiency with which individuals perform the core substantive or technical tasks central to his or her job\" [7]. The second dimension of IWP is contextual performance, defined as “behaviours that support the organizational, social and psychological environment in which the technical core must function” [9]. The third dimension of IWP is counterproductive to work behaviour, defined as “behaviour that harms the well-being of the organization” [8].\n\n#### Task performance, contextual performance and counter productive to work behaviour are the three components of individual work performance.",
        "Once the company has determined the requirements of the position, it can use the AVI-AI-based system which uses OCEAN Model to evaluate candidates' various personality qualities. To support its analysis, a questionnaire-based study using the K-modes clustering algorithm is also used.\n\n#### For the implementation of the model no set of questionnaire is used. But to support the result of the model a questionnaire-based study used.",
        "To determine the optimal number of clusters, the Elbow method is used but it is modified to use within cluster difference. From the results of plotting within cluster differences for various values, the principle of the Elbow method takes the value of k at the point when the value does not decrease significantly with the addition of the value of k.\n\n#### Elbow method is used to choose optimal number of cluster in the proposed model. The answer is directly given in a paragraph.",
        "Again, we can visualise the information captured by these style feature spaces built on different layers of the network by constructing an image that matches the style representation of a given input image (Fig 1, style reconstructions). 10,11 Indeed reconstructions from the style features produce texturised versions of the input image that capture its general appearance in terms of colour and localised structures. Moreover, the size and complexity of local image structures from the input image increases along the hierarchy, a result that can be explained by the increasing receptive ﬁeld sizes and feature complexity. We refer to this multi-scale representation as style representation . The key ﬁnding of this paper is that the representations of content and style in the Convo- lutional Neural Network are separable. That is, we can manipulate both representations inde- pendently to produce new, perceptually meaningful images. To demonstrate this ﬁnding, we generate images that mix the content and style representation from two different source images. In particular, we match the content representation of a photograph depicting the “Neckarfront” in T ¨ ubingen, Germany and the style representations of several well-known artworks taken from different periods of art (Fig 2). The images are synthesised by ﬁnding an image that simultaneously matches the content representation of the photograph and the style representation of the respective piece of art (see Methods for details). While the global arrangement of the original photograph is preserved, the colours and local structures that compose the global scenery are provided by the artwork. Effectively, this renders the photograph in the style of the artwork, such that the appearance of the synthesised image resembles the work of art, even though it shows the same content as the photograph. As outlined above, the style representation is a multi-scale representation that includes mul- tiple layers of the neural network. In the images we have shown in Fig 2, the style representation\n\n#### The paper suggests that it is impossible to completely separate the content and the style of the image. But it is possible to extract their representations to then combine them with a loss function that allows the generation of visually appealing images that somewhat satisfy (not fully) the content and stylistic constraints. It is important to mention that the artistic style representation is just a correlation of filter responses between layers in CNN. The paper suggests that this is a plausible way to obtain the content-independent visual appearance of the image. When the object recognition model is learning, it has to be able to extract features that are invariant to different variations of images. Thus, it allows the separation of content and style representations. Previous methods use non-parametric techniques that directly manipulate the pixels of the image without such separation of representations.",
        "creases with the position of the layer in the network. Hence a given input image (cid:126)x is encoded in each layer of the CNN by the ﬁlter responses to that image. A layer with N l distinct ﬁlters has N l feature maps each of size M l , where M l is the height times the width of the feature map. So the responses in a layer l can be stored in a matrix F l ∈ R N l × M l where F lij is the activation of the i th ﬁlter at position j in layer l . To visualise the image information that is encoded at different layers of the hierarchy (Fig 1, content reconstructions) we perform gradient descent on a white noise image to ﬁnd another image that matches the feature responses of the original image. So let (cid:126)p and (cid:126)x be the original image and the image that is generated and P l and F l their respective feature representation in layer l . We then deﬁne the squared-error loss between the two feature representations\n\n#### The loss function consists of 2 separate terms for content representation and artistic style representation. The difference between the content representation of the original image and the reconstructed image is calculated by taking the squared-error loss of the two. While the difference between the stylistic representation of the original artwork and the reconstructed image is calculated by taking the mean-square distance for each layer and combining them by averaging the weighted sum. In the paper, the weights for each style representation of a layer are distributed equally.",
        "The results presented in the main text were generated on the basis of the VGG-Network,22\n\n#### The paper does not explicitly mention model training process, so it is difficult to answer the question. However, the basis of their model is VGG-Network without its fully connected layers. Also, they obtained better gradient flow and better results when replacing the max pooling with the average pooling.",
        "creases with the position of the layer in the network. Hence a given input image (cid:126)x is encoded in each layer of the CNN by the ﬁlter responses to that image. A layer with N l distinct ﬁlters has N l feature maps each of size M l , where M l is the height times the width of the feature map. So the responses in a layer l can be stored in a matrix F l ∈ R N l × M l where F lij is the activation of the i th ﬁlter at position j in layer l . To visualise the image information that is encoded at different layers of the hierarchy (Fig 1, content reconstructions) we perform gradient descent on a white noise image to ﬁnd another image that matches the feature responses of the original image. So let (cid:126)p and (cid:126)x be the original image and the image that is generated and P l and F l their respective feature representation in layer l . We then deﬁne the squared-error loss between the two feature representations\n\n#### The work uses gradient descent to transform the white noise image to match the stylistic and content representations of an artwork and a photograph respectively. However, they do not discuss the reasons behind choosing gradient descent over other methods and do not provide alternatives.",
        "On top of the CNN responses in each layer of the network we built a style representation\n\n#### The stylistic representation of the image in a single layer is calculated as the Gram matrix of vectorized feature maps of that layer. The gram matrix is a matrix of the inner products of each vector. In other words, G_i_j = \\sum(V_i_k * V_j_k).",
        "creases with the position of the layer in the network. Hence a given input image (cid:126)x is encoded in each layer of the CNN by the ﬁlter responses to that image. A layer with N l distinct ﬁlters has N l feature maps each of size M l , where M l is the height times the width of the feature map. So the responses in a layer l can be stored in a matrix F l ∈ R N l × M l where F lij is the activation of the i th ﬁlter at position j in layer l . To visualise the image information that is encoded at different layers of the hierarchy (Fig 1, content reconstructions) we perform gradient descent on a white noise image to ﬁnd another image that matches the feature responses of the original image. So let (cid:126)p and (cid:126)x be the original image and the image that is generated and P l and F l their respective feature representation in layer l . We then deﬁne the squared-error loss between the two feature representations\n\n#### The authors use the white noise image as a starting point for the loss function to turn it into a combination of given images. And the results suggest that it works well. However, the reasons behind using the white noise image and its effectiveness are not discussed, thus it is difficult to answer the question.",
        "On top of the CNN responses in each layer of the network we built a style representation\n\n#### The authors calculate the difference between the stylistic representations of two images as the weighted average of the mean-squared distance of respective Gram matrices at each layer. Specifically, the distance between two Gram matrices of certain layer l is calculated as E_l = \\frac{1}{4*N_l^2*M_l^2} * (G_l_i_j^2 * A_l_i_j^2). In other words, it is the mean of squared distance in Euclidean space.",
        "including only a smaller number of lower layers, leading to different visual experiences (Fig 3, along the rows). When matching the style representations up to higher layers in the network, local images structures are matched on an increasingly large scale, leading to a smoother and more continuous visual experience. Thus, the visually most appealing images are usually cre- ated by matching the style representation up to the highest layers in the network (Fig 3, last row). Of course, image content and style cannot be completely disentangled. When synthesising an image that combines the content of one image with the style of another, there usually does not exist an image that perfectly matches both constraints at the same time. However, the loss function we minimise during image synthesis contains two terms for content and style respectively, that are well separated (see Methods). We can therefore smoothly regulate the emphasis on either reconstructing the content or the style (Fig 3, along the columns). A strong emphasis on style will result in images that match the appearance of the artwork, effectively giving a texturised version of it, but hardly show any of the photograph’s content (Fig 3, ﬁrst column). When placing strong emphasis on content, one can clearly identify the photograph, but the style of the painting is not as well-matched (Fig 3, last column). For a speciﬁc pair of source images one can adjust the trade-off between content and style to create visually appealing images. Here we present an artiﬁcial neural system that achieves a separation of image content from style, thus allowing to recast the content of one image in the style of any other image. We demonstrate this by creating new, artistic images that combine the style of several well-known paintings with the content of an arbitrarily chosen photograph. In particular, we derive the neural representations for the content and style of an image from the feature responses of high- performing Deep Neural Networks trained on object recognition. To our knowledge this is the ﬁrst demonstration of image features separating content from style in whole natural images.\n\n#### Since it is difficult to satisfy both content and stylistic constraints on the resulting image, the α and β weights in the loss function are used to manipulate the emphases on the content and stylistic representations respectively. Several different ratios of α/β (10^-5, 10^-4, 10^-3, 10^-2) are explored to demonstrate the differences between synthesized images. In general, it allowed smooth and continuous regulation of two separate terms of the loss function, thus producing more visually pleasing images.",
        "In general, our method of synthesising images that mix content and style from different\n\n#### The work only claims that the idea of separating the sources of variation in visual perception might be useful for a range of experiments from psychophysics to electrophysiological neural recordings. It does not go into detail about examples of such experiments. Thus, it is difficult to answer the question with only the contents of the paper.",
        "The class of Deep Neural Networks that are most powerful in image processing tasks are called Convolutional Neural Networks. Convolutional Neural Networks consist of layers of small computational units that process visual information hierarchically in a feed-forward man- ner (Fig 1). Each layer of units can be understood as a collection of image ﬁlters, each of which extracts a certain feature from the input image. Thus, the output of a given layer consists of so-called feature maps: differently ﬁltered versions of the input image. When Convolutional Neural Networks are trained on object recognition, they develop a representation of the image that makes object information increasingly explicit along the pro- cessing hierarchy. 8 Therefore, along the processing hierarchy of the network, the input image is transformed into representations that increasingly care about the actual content of the im- age compared to its detailed pixel values. We can directly visualise the information each layer contains about the input image by reconstructing the image only from the feature maps in that layer 9 (Fig 1, content reconstructions, see Methods for details on how to reconstruct the im- age). Higher layers in the network capture the high-level content in terms of objects and their arrangement in the input image but do not constrain the exact pixel values of the reconstruc- tion. (Fig 1, content reconstructions d,e). In contrast, reconstructions from the lower layers simply reproduce the exact pixel values of the original image (Fig 1, content reconstructions a,b,c). We therefore refer to the feature responses in higher layers of the network as the content representation . To obtain a representation of the style of an input image, we use a feature space originally designed to capture texture information. 8 This feature space is built on top of the ﬁlter responses in each layer of the network. It consists of the correlations between the different ﬁlter responses\n\n#### The content representation of the photograph resembles the pixel-wise image more in the lower layers, but encodes the more high-level contents in the higher layers. To construct the results in Figure 2, the authors use the content representation from one of the highest layers 'conv_4_2', which means they fuse well with the extracted style representations. Also, it is possible to change the emphasis between the content representation and style representation using the loss function. In general, the results of combining lower-layer content representations with styles are not presented, thus it is difficult to answer the question just from the paper's contents.",
        "On top of the CNN responses in each layer of the network we built a style representation that computes the correlations between the different filter responses, where the expectation is taken over the spatial extend of the input image. These feature correlations are given by the Gram matrix Gl ∈ RNl×Nl , where Gl ij is the inner product between the vectorised feature map and j in layer l: Gl ij = ∑ k F l ikF l jk. (3) To generate a texture that matches the style of a given image (Fig 1, style reconstructions), we use gradient descent from a white noise image to find another image that matches the style representation of the original image. This is done by minimising the mean-squared distance between the entries of the Gram matrix from the original image and the Gram matrix of the image to be generated. So let ~a and ~x be the original image and the image that is generated and Al and Gl their respective style representations in layer l. The contribution of that layer to the total loss is then El = 1 4N 2 l M 2 l ∑ i,j (Gl ij − Al ij )2 (4) and the total loss is Lstyle(~a, ~x) = L∑ l=0 wlEl (5) where wl are weighting factors of the contribution of each layer to the total loss (see below for specific values of wl in our results). The derivative of El with respect to the activations in layer l can be computed analytically: ∂El ∂F l ij = { 1 N 2 l M 2 l ((F l)T (Gl − Al)) ji if F l ij > 0 0 if F l ij < 0 . (6) The gradients of El with respect to the activations in lower layers of the network can be readily computed using standard error back-propagation. The five style reconstructions in Fig 1 were generated by matching the style representations on layer ‘conv1 1’ (a), ‘conv1 1’ and ‘conv2 1’ (b), ‘conv1 1’, ‘conv2 1’ and ‘conv3 1’ (c), ‘conv1 1’, ‘conv2 1’, ‘conv3 1’ and ‘conv4 1’ (d), ‘conv1 1’, ‘conv2 1’, ‘conv3 1’, ‘conv4 1’ and ‘conv5 1’ (e).\n\n#### The weights w_l can manipulate the emphases between stylistic representations obtained from different layers. To make the roles of each stylistic representation of each layer equal, the w_l is always kept at one divided by the number of active layers. They are constants in the loss function that are set before starting to optimize the loss function.",
        "To contribute to the efficient Transformers lineage, we propose SBM-Transformer, capable of adjusting its attention sparsity data-adaptively based without fully computing the attention score matrix (Figure 1). Leveraging a mixed-membership Stochastic Block Model (SBM) [2], each attention head samples a bipartite graph connecting queries to keys. Then, the adjacency of the sampled graph is used as an attention mask so that only attention scores corresponding to sampled edges are computed.The overall computational cost is linear in the number of edges, which can range from linear to quadratic in sequence length depending on the data and task under concern. Each attention head is equipped with its own underlying SBM, enabling the model to diversify the attention sparsity across heads and layers. By incorporating a straight-through estimator [4] in the discrete graph-sampling step, SBM-Transformer enjoys end-to-end differentiability and can find the proper attention sparsity based solely upon minimizing the predictive loss. The model can also easily be further regularized by penalizing the number of sampled edges, which results in a lighter model using less computational resources during inference. To the best of our knowledge, our method is the first Transformer architecture that can data-adaptively choose between linear to full attention with respective computational costs. To summarize, our main contributions are as follows:\n\n#### SBM-Transformer is the first Transformer architecture that can data-adaptively choose between linear to full attention with respective computational costs.",
        "The Stochastic Block Model (SBM) is a generative model that encodes the latent structure of graphs by grouping nodes into clusters. By modeling the cluster-membership of each node as well as inter-cluster relationships, SBMs can represent a wide variety of graph structures, which is a feature especially useful for generating new graphs or predicting missing edges in noisy data [1]. The standard SBM assigns each node to a single cluster, and the probability of an edge between two nodes strictly depends on the corresponding clusters. Several structural extensions include overlapping SBM [24] and mixed-membership SBM [2], which allow each node to be assigned to multiple clusters. The underlying SBM used by our framework mostly resembles these two variants, while the edge probability is modeled by a nonlinear function of two node embeddings rather than a bilinear one. There exist many other extensions including degree-corrected SBM [20] for multi-graphs and hierarchical SBM [31] for multiplex-graphs. Further details can be found in a recent survey [16].\n\n#### The mixed-membership Stochastic Block Model (SBM) is a generative model that encodes the latent structure of graphs by assigning each node into multiple clusters.",
        "Table 8 shows the test accuracies of each method. Our SBM-Transformer achieves the best overall performance, ranking first in two tasks, and second in one other. SBM-Transformer also outperforms full attention in all five tasks while computing 30% or less attention scores on average, which supports our claim that masked attention with partial attention score computations can be preferred over full attention depending on the task. With respect to the attention mask structure, we find that flexibility of SBM is indeed beneficial, as Reformer struggles in ListOps, most likely due to the inability of block-diagonal masks to model hierarchical contexts.\n\n#### SBM-Transformer allows more flexible attention mask structures between linear to full attention with respective computational costs, while Reformer can only use block-diagonal masks that cannot model hierarchical contexts.",
        "Then, we can show that these three patterns form directed graphs that together satisfy the three\n\n#### A Hamiltonian path is a path that visits all nodes in a graph.",
        "One way to remove the quadratic bottleneck from the attention score matrix is to apply a binary mask \\bm{M}\\in\\{0,1\\}^{n\\times n} and compute the scaled dot-products \\bm{Q}_{i}\\bm{K}_{j}^{T}/\\sqrt{d_{h}} only if \\bm{M}_{ij}=1. In presence of an attention mask, the operation is modified to\\displaystyle\\texttt{Attn}_{\\text{mask}}(\\bm{X},\\bm{M})=\\sigma_{\\bm{M}}\\left(\\bm{M}\\odot\\dfrac{\\bm{Q}\\bm{K}^{T}}{\\sqrt{d_{h}}}\\right)\\bm{V}(3)\\displaystyle\\sigma_{\\bm{M}}(\\bm{A})_{ij}\\coloneqq\\begin{cases}\\dfrac{\\exp(\\bm{A}_{ij})}{\\sum_{k\\in\\{k^{\\prime}|\\bm{M}_{ik^{\\prime}}=1\\}}\\exp(\\bm{A}_{ik})}&\\text{if}\\;\\;\\bm{M}_{ij}=1\\\\\\hfil 0&\\text{otherwise}\\end{cases}(4)where \\odot indicates entry-wise multiplication. Note that the masked-softmax \\sigma_{\\bm{M}}(\\cdot) operator only computes unmasked terms, ensuring that each (i,j)-th attention score survives as nonzero if and only if \\bm{M}_{ij}=1. This is thus equivalent to filling in the (i,j)-th attention score with -\\infty if \\bm{M}_{ij}=0, then applying the standard softmax operator. Most sparsity-based efficient Transformers fall under this formulation, while using different methods to either manually fix or learn the mask \\bm{M}. For instance, local attention [9, 3, 51] with a sliding window sets \\bm{M}_{ij}=1 if |i-j|<c for some context window size c while Reformer [22] sets \\bm{M}_{ij}=1 if \\bm{Q}_{i} and \\bm{K}_{j} are hashed into the same bucket.\n\n#### Local attention is a Transformer model that uses a sliding window of some fixed context window size.",
        "To test if the model can effectively learn under a constraint on the computational cost, we also test the model under a sparsity-based regularizer that discourages excessive use of query-key edges. We penalize each sampled edge by adding to the predictive loss a weighted regularization term \\lambda\\mathcal{L}_{s}, where \\mathcal{L}_{s} denotes the average mask density across all attention heads. Table 9 shows the performance of SBM-Transformer across varying regularization weights. Under strong regularization, the model surprisingly retains competitive performance while significantly reducing the average mask density.This indicates that similar local optima are shared across regimes with varying attention density in the loss landscape, and the regularization term is able to drive the model towards finding optimal attention scores with smaller density.\n\n#### The average attention sparsity is measured by the densities of masks sampled in SBM-Transformer averaged across all attention heads.",
        "While this approach enables backpropagation in the same O(m) cost\n\n#### The random edge exploration technique allows SBM-Transformer to avoid the problem of having edge probabilities accidentally collapsing to zero and to explore new edges and resuscitate their sampling probabilities if necessary.",
        "For this task, we compare SBM-Transformer with k=128 clusters against various efficient Transformers: Linear Transformer [21], Linformer [45], Reformer [22], Performer [10], and Nyströmformer [48]. Across all methods, we use a single-layer and single-head architecture with 32 hidden dimensions. Note that due to this constrained setting, the sole head must perform full attention to compare each token to all the others in order to attain 100% accuracy. All models are trained for 2000 epochs where a new batch of sequences is sampled on-the-fly at each epoch. We use a batch size of 256 and learning rate of 1e-3.\n\n#### Using a single-layer and single-head architecture forces a constrained setting where the sole head must perform full attention to compare each token to all the others in order to attain 100% accuracy.",
        "Furthermore, we compare computational costs during inference by measuring FLOP count and peak memory usage. For SBM-Transformer, we test the model trained under \\lambda=10^{-1}. Due to lack of support for sparse tensor operations in existing FLOP-counters, we measure FLOP counts by manually enumerating through each tensor operation. Table 3 shows that SBM-Transformer is comparably efficient across all tasks except for Text, where SBM-Transformer showed the largest average mask density. Note that while the cost of other baselines are fixed after initialization, the cost of SBM-Transformer is data-adaptive and can vary input-by-input. Further analysis and qualitative examples demonstrating the input-dependent attention mask densities can be found in Appendix C.\n\n#### SBM-Transformer is efficient compared to existing baselines in terms of FLOP count and peak memory use, but can result in longer runtimes due to sparse tensor operations being less optimized on GPU kernels.",
        "For proper parameterization of the SBM, we must infer the nonnegative node-memberships and block matrix from the queries and keys. To do so, we equip each attention head a 2-layer MLPdh→dh with ReLU activation, and a set of k trainable cluster-embeddings C ∈ R k×dh . First, our model computes the block matrix Sˆ ∈ R k×k + by taking dot products amongst cluster-embeddings C followed by a 2-dimensional softmax activation. The node embeddings are obtained by processing each query and key through the MLPdh→dh\n\n#### The node embeddings are obtained by processing each query and key through the 2-layer MLP, mapping token representations into the node representation space. The reason why the 2-layer MLP was chosen in particular cannot be answered in this paper.",
        "Leveraging previous work on the theoretical expressiveness of sparse attention [50, 51], we show that SBM-Transformer with a small modification111Here we consider a variant of SBM-Transformer where self-loops are added manually (i.e. \\bm{M}_{ii}=1 for all i). While this is useful in theoretical analysis, we find that not having self-loops slightly helps in empirical performance and hence omit self-loops for the main experiments. retains the same level of expressibility as full attention. Specifically, we show that the low-rank structure of the underlying SBMs does not degrade the expressive power of Transformer, and that SBM-Transformer can universally approximate arbitrary functions with \\mathcal{O}(n) connections. For brevity, we provide a rough overview of the proof and defer further details to Appendix A.\n\n#### We show that the low-rank structure of the underlying SBMs does not degrade the expressive power of Transformer, and that SBM-Transformer can universally approximate arbitrary functions with \\mathcal{O}(n) connections.",
        "After acquiring the pooling operator, the pooling process becomes obvious. Nodes are in fundamental representation while edge features and adjacency matrix are in adjoint representation. Which leads to the following transformation rules.\\displaystyle X_{i}^{(l+1)}=S^{(l)}X_{i}^{(l)}(13)\\displaystyle E_{ij}^{(l+1)}=S^{(l)}E_{ij}^{(l)}S^{(l)T}(14)\\displaystyle A_{ij}^{(l+1)}=S^{(l)}A_{ij}^{(l)}S^{(l)T}(15)If grouping is properly done, 0 (or close to 0) components will appear in the decomposed eigen value matrix. These zero eigenvalues arise naturally and play a role in disregarding group information; those are ineffective towards prediction. However, zero elements in the eigen values causes a major problem in the decomposition process since the matrix might carry a singular determinant.Eigen decomposition is based on an iterative approximation algorithm which includes unbounded terms if any two eigen values are small or close. One can see clearly about this matter in DBLP:journals/corr/IonescuVS15 .\\Big{(}\\frac{\\partial{l}}{\\partial{A}}\\Big{)}=U\\big{(}K^{T}\\odot(U^{T}\\frac{\\partial{l}}{\\partial{U}})+(\\frac{\\partial{l}}{\\partial{\\Lambda}})_{\\textrm{diag}})(U^{T})(16)Here, \\odot denotes element-wise product. Off-diagonal components of K=1/(\\lambda_{i}-\\lambda_{j}) causes the problem, since the value blows up to the infinity if any two eigen values are close or very small. However, there are some solutions for this matter by approximating gradient in different ways DBLP:journals/corr/abs-1906-09023 ; 9400752 ; DBLP:journals/corr/abs-2105-02498 . Those methods are developed further to achieve higher speed in the calculation DBLP:journals/corr/abs-2201-08663 . They claim that the method is noticeably faster, over 8 times, than the standard SVD which has the time complexity \\mathcal{O}(n^{3}). Thus, we utilized this method in our work to stabilize and accelerate the learning process. However, since the algorithm achieves the higher speed by approximating gradients, the error compared to standard SVD grows bigger as the size of the matrix grows. Therefore, this method might not be valid with large sized graph data.\n\n#### GMPool may not be eligible to be used for large graphs as is due to the large cubic time complexity.",
        "To overcome this challenge, we propose GMPool, a general pooling framework that does not require an universal number of clusters as a user hyperparameter. Figure 1 depicts the overall framework of GMPool. The core intuition is that the product of a pooling matrix with itself forms a grouping matrix, where each (i,j)-th entry indicates the pairwise clustering similarity: whether the nodes i and j are pooled to the same clusters. For each graph, GMPool parameterizes the clustering similarities in its grouping matrix via a classification layer. Finally, we perform SVD on the grouping matrix to obtain the pooling matrix such that the overall rank represents the suitable number of clusters. We also test a single-pooling variant NGMPool that does not perform any decomposition, but rather uses the grouping matrix as is. In real-world molecular property prediction tasks, we show that our approach outperforms previous baselines, while successfully learning suitable clusters.\n\n#### NGMPool is a single-pooling variant of GMPool that does not perform SVD on the grouping matrix, but rather uses the grouping matrix as is.",
        "The pooling operator S is a square matrix with size of nl × nl, yet the eigen value Λ suppresses\n\n#### The grouping matrix is symmetric and real, which guarantees to have real eigen values as well as vectors. The additional connection between SVD and EVD given this property of the grouping matrix cannot be found in this paper.",
        "For baseline pooling methods that require the cluster size as a hyperparameter, we perform grid search across candidates following previous work, and present best results.However, we fix the final pooling size to 10 as the average size of most common 40 functional groups in bioactive molecules is 4.25 ertl2020most , indicating that molecules under concern (statistics shown in Table 1) can have up to 10 clusters.The specific hyperparameter setups used for pooling baselines can be found in appendix.\n\n#### For baseline pooling methods, we perform grid search following previous work, and present best results. We fix the final pooling size to 10 as the average size of most common 40 functional groups in bioactive molecules is 4.25.",
        "In this section, we propose a novel differentiable pooling layer, GMPool, which obtains the pooling matrix by first building a grouping matrix that contains clustering similarities of pairwise nodes and then decomposing the matrix into its square-root form. We start the section with preliminary information, then outline the details of GMPool in later sections.\n\n#### GMPool and NGMPool overcome the limitation of existing pooling frameworks that require a universal number of clusters as user parameter by first building a grouping matrix and decomposing the matrix into its square-root form.",
        "In most inductive settings, there is no single number of clusters that is suitable across all graphs in the dataset.Particularly in molecular graphs, the number of functional groups often determines useful characteristics and chemical behaviors, while varying significantly across different molecules.Nonetheless, existing pooling methods require the number of clusters as a hyperparameter, then operates under the assumption that all graphs share the same number of clusters ranjan2020asap . This is often undesirable as it not only requires additional hyperparameter tuning, but also imposes a strong inductive bias that deteriorates downstream performance.\n\n#### The proposed graph pooling method was tested specifically on molecular property prediction tasks because predefining the number of clusters is especially detrimental in molecular property prediction where there is no single number of clusters that is suitable across all graphs. The number of functional groups that determine useful characteristics and chemical behaviors can vary significantly across different molecules.",
        "After acquiring the pooling operator, the pooling process becomes obvious. Nodes are in fundamental representation while edge features and adjacency matrix are in adjoint representation. Which leads to the following transformation rules.\\displaystyle X_{i}^{(l+1)}=S^{(l)}X_{i}^{(l)}(13)\\displaystyle E_{ij}^{(l+1)}=S^{(l)}E_{ij}^{(l)}S^{(l)T}(14)\\displaystyle A_{ij}^{(l+1)}=S^{(l)}A_{ij}^{(l)}S^{(l)T}(15)If grouping is properly done, 0 (or close to 0) components will appear in the decomposed eigen value matrix. These zero eigenvalues arise naturally and play a role in disregarding group information; those are ineffective towards prediction. However, zero elements in the eigen values causes a major problem in the decomposition process since the matrix might carry a singular determinant.Eigen decomposition is based on an iterative approximation algorithm which includes unbounded terms if any two eigen values are small or close. One can see clearly about this matter in DBLP:journals/corr/IonescuVS15 .\\Big{(}\\frac{\\partial{l}}{\\partial{A}}\\Big{)}=U\\big{(}K^{T}\\odot(U^{T}\\frac{\\partial{l}}{\\partial{U}})+(\\frac{\\partial{l}}{\\partial{\\Lambda}})_{\\textrm{diag}})(U^{T})(16)Here, \\odot denotes element-wise product. Off-diagonal components of K=1/(\\lambda_{i}-\\lambda_{j}) causes the problem, since the value blows up to the infinity if any two eigen values are close or very small. However, there are some solutions for this matter by approximating gradient in different ways DBLP:journals/corr/abs-1906-09023 ; 9400752 ; DBLP:journals/corr/abs-2105-02498 . Those methods are developed further to achieve higher speed in the calculation DBLP:journals/corr/abs-2201-08663 . They claim that the method is noticeably faster, over 8 times, than the standard SVD which has the time complexity \\mathcal{O}(n^{3}). Thus, we utilized this method in our work to stabilize and accelerate the learning process. However, since the algorithm achieves the higher speed by approximating gradients, the error compared to standard SVD grows bigger as the size of the matrix grows. Therefore, this method might not be valid with large sized graph data.\n\n#### GMPool decomposes the grouping matrix using a method that approximates gradients in SVD to stabilize gradient computations.",
        "Another future direction would be to enhance scalability of our methods to improve applicability to large-scale graphs. Since the grouping matrix decomposition step via SVD is the main computational bottleneck of GMPool, incorporating faster decomposition modules such as randomized approximation halko2011finding ; DBLP:journals/corr/abs-1710-02812  methods can lead to faster inference. However, this is likely to incur loss in predictive performance, and as the focus of this work lies in allowing variation in the number of clusters in small molecular graphs where scalability is not an issue, we defer improving the scalability to future work.\n\n#### One future direction to enhance scalability of GMPool is to incorporate faster decomposition modules such as randomized approximation methods. However, this is likely to incur loss in predictive performance.",
        "As our backbone GNN, we adopt the Directed Message Passing Neural Network (DMPNN) doi:10.1021/acs.jcim.9b00237  which aggregates messages through directed edges. Note that while we chose DMPNN due to its superior performance over GNN architectures, our pooling layer is module-agnostic and can be combined with any GNN as long as node representations are returned as output.Given a graph, DMPNN first initializes the hidden state of each edge (i,j) based on its feature E_{ij} and the source-node’s feature X_{i}. At each timestep t, each directional edge gathers hidden states from incident edges into a message m_{ij}^{t+1} and updates its own hidden state to h_{ij}^{t+1} as follows\\displaystyle m_{ij}^{t+1}=\\sum_{k\\in\\mathcal{N}(i)\\setminus j}h_{ki}^{t}(1)\\displaystyle h_{ij}^{t+1}=\\texttt{ReLU}(h_{ij}^{0}+W_{e}m_{ij}^{t+1})(2)Here, \\mathcal{N}(i) denotes the set of neighboring nodes of node i and W_{e} a learnable weight. The hidden states of nodes are updated by aggregating the hidden states of incident edges into message m_{i}^{t+1}, and passing its concatenation with the node feature X_{i} into a linear layer followed by ReLU non-linearity\\displaystyle m_{i}^{t+1}=\\sum_{j\\in\\mathcal{N}(i)}h_{ij}^{t}(3)\\displaystyle h_{i}^{t+1}=\\texttt{ReLU}(W_{n}\\texttt{concat}(X_{i},m_{i}^{t+1}))(4)Similarly, W_{n} denotes a learnable weight. Assuming DMPNN runs for T timesteps, we use (X_{out},E_{out})=\\texttt{GNN}(A,X,E) to denote the output representation matrices containing hidden states of all nodes and edges, respectively (i.e., X_{out,i}=h_{i}^{T} and E_{out,ij}=h_{ij}^{T}).\n\n#### While the authors chose DMPNN due to its superior performance over GNN architectures, the proposed pooling layer is module-agnostic and can be combined with any GNN. Results leveraging more recent GNN architectures such as GIN or Graph Transformers cannot be found in this paper.",
        "In this work, we compare our proposed method with a data preprocessing approach proposed by Kandpal et al. (2022) which shows that deduplicating the training corpora before pretraining helps pretrain LMs that show stronger robustness against extraction attacks than an LM pretrained under the same circumstances without deduplicating the pretraining corpora. However, we highlight that this approach, which may still be effective at mitigating the overall privacy risks, is not the most suitable approach when considering a realistic scenario of individuals requesting the removal of their information from the implicit parameters of the LMs.\n\n#### Deduplicating the pretraining corpora proves to mitigate privacy risks for LMs.",
        "We show the effect of varying s (the # of data instances to be forgotten at once) in Figure 2a across model scales. We denote this approach as batch unlearning. As shown by the s=128 results, it is harder to forget more samples at once, resulting in substantial degradation of average LM performance regardless of how large the LM is. Since s\\leq 32 does not show much degradation, we explore if sequentially unlearning can be a solution. In Figure 2b, we show the result of dividing the 128 samples into 4 chunks of 32 and performing sequential unlearning; we unlearn each chunk at a time until the chunk reaches the forgetting threshold. Surprisingly, as shown by the performance gap at s=128 between the dotted lines (the s=128 performance of Figure 2a) and straight lines, the end result is vastly different even though exactly the same instances were forgotten. Sequential unlearning shows almost no degradation of average LM performance. In Appendix G, we show that chunks once forgotten stay forgotten and that later chunks are forgotten much faster compared to the initial chunk. This result hints at the generalization of unlearning, which we do not further explore in the scope of this work. The result also suggests that knowledge unlearning can be continually applied to LMs when needed.\n\n#### Results show that forgetting 128 samples at once results in a severe degradation of general LM performance while forgetting 32 samples does not.",
        "First, we show the Extraction Likelihood (EL) Forgetting Threshold values for n=[5,10,20,40] by measuring the value on the 10,000 validation instances unseen during training in Table 12. Next, we show the average LM performance (on the 9 classification benchmarks) where we perform unlearning on the LM on 32 samples until the target token sequences are forgotten (the EL & MA value are both lower than the threshold values) in Table 13. Performance shows the average of 5 random samplings.\n\n#### The average LM perfomance of varying n for the EL metric is shown in Table 13.",
        "Previous work that explores to which extent LMs have memorized their training data approach the phenomenon with two different viewpoints. Some work view memorization of LMs simply as a threat to individual privacy (Carlini et al., 2021; 2022; Jagielski et al., 2022) and utilize metrics that quantify how much the LMs are susceptible to adversarial attacks. These metrics are mostly dependent on the specific types of attacks such as the membership inference attack (Shokri et al., 2017) and measure the privacy risks of LMs by quantifying the success rate of these attacks.\n\n#### These metrics are dependent on the specific attacks, while ours is agnostic of the type of attack.",
        "We set the n value to 10 since we empirically consider an extraction to be successful when 10 consecutive token sequences are successfully generated by the LM. We show varying the n with values from [5,10,20,40] in Appendix H.\n\n#### The n value is set to 10 because we consider an extraction attack to be successfuly when 10 token sequences are successfully extracted by the LM.",
        "We highlight five main observations regarding the results. (1) OPT LMs show a much lower EL10 and MA than GPT-NEO LMs, confirming that deduplicating the pretraining corpora is indeed helpful for mitigating privacy risks. (2) NEO + DPD+ enables effective protection against extraction attacks demonstrated via the lowest EL and MA score; however, it brings severe degradation of generation capabilities measured via the Average F1 score of the 4 dialogue generation tasks. (3) NEO + UL+ results in severe degradation of both classification and dialogue tasks for the 125M, only severe degradation of dialogue tasks for 1.3B LM while for the 2.7B LMs, it enables retaining most of its previous capabilities. (4) While the LMs scale to larger sizes, it takes fewer epochs for the target sequences to be forgotten. Together with (3), this implies that larger LMs are strong unlearners. (5) While NEO + UL+ provides stronger privacy protection than OPT without sacrificing its performance from NEO for the 2.7B LM, it is much more computationally efficient (3,500,000x) than re-training the underlying LM, which is required for all data preprocessing approaches.\n\n#### Larger LMs are stronger unlearners because they take fewer epochs for forgetting specific target token sequences and retains most of its previous capabilities compared to smaler LMs.",
        "By utilizing both \\textsc{EL}_{n} and MA, we empirically define a specific token sequence \\bm{x} to be forgotten and is no longer susceptible to extraction attacks when the following conditions are met:\n\n#### Since the forgetting definition is dependent on a held-out validation corpora, it is considered 'empirically' forgotten.",
        "MA quantifies how much f_{\\theta} has memorized the given token sequences and was proposed by Tirumala et al. (2022) to analyze the training dynamics of large LMs.\n\n#### MA was first used to quantify the training dynamics of large LMs.",
        "For the actual target data used to quantify the privacy risks of the LMs, we sample instances from the Training Data Extraction Challenge 111https://github.com/google-research/lm-extraction-benchmark where 15,000 examples (each are 200 token sequences long) from 16 different domains of the Pile corpora that are identified to be somewhat easy-to-extract are provided. For our experiments, we randomly sample s samples from the 15,000 examples and make the underlying LM forget the s samples at once. As a default, we show the average results of 5 random samplings of s samples for all of our experimental settings. We only provide the average of the 5 samplings and do not separately report the standard deviation. Instead, we provide the results of each individual run in Appendix A.\n\n#### The standard deviation is not shown in the table because it is shown in the Appendix.",
        "We concretely use the variational Transformer inspired by Lin et al. [22]. They used a Transformer-based model extended by a conditional VAE framework to gener- ate a response from a conditional context . We leverage this seq2seq architecture to achieve a variational neural machine translation (VNMT) from a given melody to the chords [23]–[25]. To the best of our knowledge, we are the ﬁrst to apply the VNMT approach to music generation. In particular, our approach is different from previous music generation studies using the variational Transformer, which mostly served as an autoencoder [26], [27].\n\n#### The proposed work is different from previous studies using Transformer-based VAE frameworks, which achieves representation including global or hierarchical information of the given data, in that the learned representation is disentangled according to domain-specific inductive bias to control generated chords.",
        "A melody harmonization task requires capturing the long-term dependencies in music since a constrained sets of chord progressions can consistently interact with a given melody [4]. This has motivated the use of linguistic tech- niques such as context-free grammar [5], genetic algo- rithms [6], or hidden Markov models (HMMs) [3], [7], [8].\n\n#### A melody harmonization task is important for understanding human composition since it aims to capture the long-term dependencies in music by constraining sets of chord progressions that can interact with a given melody.",
        "where e T , e N , S , and N denote the time-level embed- ding vectors, note-level embedding vectors, STHarm, and the number of melody notes, respectively, Embedding and Self-AttBlocks denote the embedding layer and L multi- head self-attention blocks that are identical to the vanilla Transformer, respectively [12], w ∗ denotes a sinusoidal posi- tional embedding scaled by a trainable weight [40], and TimeToNote is a novel method that we propose to convert the timewise embedding to the notewise embedding to capture the note patterns in a melody.\n\n#### Note-based representation is better than grid-based representation in learning chord patterns. The reason is that learning with the grid-based representation can result in generating chord progression with ambiguous patterns or hierarchies. On the other hand, modeling the note-based representation can capture note patterns in a melody.",
        "Nevertheless, these LSTM-based studies had limitations in generating concrete chord structures. First, the models were unable to encode an original melodic structure despite their sequential architectures [4]. The notes in a melody were aggregated within a chord duration into a pitch-class histogram before being fed to the model. Second, the models did not explicitly consider capturing the patterns of chord pro- gressions. Chord labels correspond to the constant time grids (e.g., a bar or half-bar). Sequential modeling of grid-based chord labels is likely to result in ambiguous patterns or hier- archies of the generated outputs [8].\n\n#### LSTM-based approaches have failed to capture realistic patterns of chords due to two reasons. The first reason is that they cannot encode an original melodic structure by aggregating melody notes for each chord into a pitch-class histogram before being fed to the model. The second reason is that they capture ambiguous patterns or hierarchies in chord progressions since they recurrently model grid-based chord labels. Empirically, it has been investigated that the LSTM-based models tend to generate some syncopated chord rhythms that can weaken the metrical boundaries, unlike real-world music.",
        "In the Time2Note procedure, we add the scaled positional embedding w T to e (S) T . Then, we transfer it to the notewise embedding e (S) N with average pooling by an alignment matrix M ∈ { 0 , 1 } T × N as (2), where M indicates the alignment path between a piano roll and a series of notes. This process enables each frame of the notewise embedding to preserve the information of the original note duration :\n\n#### TimeToNote method is different from similar approaches to capture musical hierarchy. First, it aims to aggregate grid-based information into musically meaningful units, while previous approaches map low-level musical units to high-level musical units, such as a bar. Moreover, the aggregated information preserves the length information of the original representation, which is also different from the previous studies that simply average-pooled the representation.",
        "The proposed architecture of VTHarm is inspired by [22]. VTHarm has an additional probabilistic encoder for a latent variable z , where z represents the global attribute of the aggregated melody and chords. We denote this encoder as the context encoder . We add a global key signature label as a conditional input token to the model. The key signature is essential for an arbitrary melody to obtain a certain harmonic context [41]. The key signature token can aid the model in specifying the latent space and sampling the outputs from the\n\n#### \"Global key signature\" means the harmonic context of music that is constrained to a certain range. For example, the C major key is constrained to have functionally important chords such as C, G, and F major chords.",
        "We expand the conventional criteria [10], [11] for deeper analysis of human judgment. Harmonicity measures how coherent the chords are with a given melody. Unexpected- ness measures how much the chords deviate from expecta- tion. Complexity measures how complex chord progression is perceived to be. Preference measures personal favor for chord progression [9].\n\n#### \"Chord coverage\" can represent chord complexity, as the corresponding scores are empirically correlated to \"Complexity\" scores that are collected by human participants during the listening test. \"Complexity\" metric represents how complex a human listener perceives the chord progression to be.",
        "constrained chord distributions. In contrast, STHarm does not use this token since it ﬁnds the mean distribution for chords that best ﬁt a given melody.\n\n#### The objective of STHarm does not include condition c as it aims to find mean distribution for chords that maximizes the likelihood given a certain melody. STHarm may generate the chords that share the best-fit harmonic context with the melody through its objective. Therefore, STHarm does not need extra information that constrains the harmonic context to better predict harmonically coherent chords.",
        "HLSD [13] is an online database of melody and chord annota- tions that cover various genres, such as the pop, new age, and original soundtracks. This dataset has been constructed on a crowdsourcing platform called TheoryTab, 1 in which users have transcribed a large number of high quality melodies and chords. This dataset contains the raw annotations of melodies and chords in XML format, JSON data of the symbolic fea- tures of melodies and chords, and piano-roll ﬁgures depicting the melody and chords. We use the JSON data for 9,218 songs divided into 13,335 parts. We also normalize all songs into C major or C minor, as in previous studies [10], [11]. Fol- lowing Sun et al. [11], we use 500 parts for the test set and the other 500 parts for the validation set. As a result, we use 32,619, 1,346, and 809 samples for the training, validation, and test sets, respectively.\n\n#### Using the HLSD dataset without transposing to various key signatures, we can reproduce the baseline model performance with the same dataset setting to the previous studies and verify the proposed models compared to the baseline performance. Therefore, it is beneficial over only using a new dataset.",
        "The models are implemented and evaluated in Python 3 and the PyTorch deep learning framework of version 1.5.0. For training each model, we use one NVIDIA GeForce GTX 1080 Ti. We mostly refer to the previous implemen- tations [40], [48] when implementing the vanilla Trans- former. For implementing and training BLSTM and ONADE, we use the original settings [9], [11]. The gradients are all clipped to 1 for the learning stability during training of all models. VTHarm, rVTHarm, and ONADE are assessed with 10 test samples per melody due to their randomness.\n\n#### The baseline models are implemented from scratch, where the experimental settings are referred to the original settings in the corresponding papers.",
        "The embedding sizes of the melody and chord are 128 and 256, respectively. We use a hidden size of 256, attention head size of 4, number of attention blocks L of 4, and size of the latent variable z of 16. A dropout layer is used after every scaled positional encoding at a rate of 0.2. We use an Adam optimizer [46] with an initial learning rate of 1e-4, which is reduced to 95% after every epoch. We train the proposed models for 100 epochs with a batch size of 128. To select the value of λ KL , we refer to several studies on VAE-based music generation in which a scaling weight smaller than 1 encour- ages better reconstruction [21], [47]. Then, we empirically set λ KL and λ Reg to be 0.1 and 1, respectively, which results in the best performance.\n\n#### Lambda Reg has been empirically set to 1 through several trials with various values. The concrete results of such a process are not reported in the paper.",
        "distance (DICD) measure the distance between two chord progressions:\n\n#### TPSD is based on the relationship of two adjacent chords in terms of the circle-of-fifths rule and the shared pitch-class indices in the four levels of the tonic space. On the other hand, DICD is based on the pitch-class intervals between the two adjacent chords.",
        "Table 5 shows that the results mainly support the quantita- tive evaluation results. In contrast, STHarm shows the highest H score regardless of melody awareness. This suggests that STHarm outputs plausible chords to listen to than the baseline models. For U and C, VTHarm shows the highest scores, and\n\n#### STHarm may have generated \"common\" chords that are frequent in real-world music. Harmonicity and Preference scores are the highest for the STHarm, regardless of melody awareness, and those scores are evaluated by the human listeners who usually have listened to popular music where common chords are used.",
        "We investigate the harmonic similarity between the human-composed and generated chords. We use the samples from Human as the ground truth. This explicit comparison with Human can provide insight into whether the generated chords from each model are as well-structured as human- composed music [8].\n\n#### A harmonic similarity to human music is connected to the structuredness of chord patterns because human-composed music is a ground truth representing the music that is well-structured and the objective of this paper is fundamentally generating chords similar to real-world music.",
        "Furthermore, we attempt to regularize the variational Transformer for controlling the chord outputs through a dis- entangled representation. Generating arbitrary sets of chords may not satisfy users who would like to create music based on their own tastes. In terms of building interactive music gen- eration systems as well as learning a good representation for sequential data, controllable generation with the VAE frame- work has mainly been approached by recent studies. These studies have aimed to learn disentangled representations for high-level musical features, such as pitch, rhythm, harmony, context, or arousal, through supervised learning [28]–[31]. Inspired by these studies, we use domain-speciﬁc induc- tive bias to achieve a disentangled representation for the well-summarized context of the target melody and chords.\n\n#### VTHarm cannot guarantee a disentangled representation of the desired aspect because it does not aim a supervised learning that can decouple the representation by the high-level musical features. Empirically, the learned representation from VTHarm has been shown to be less correlated to the target chord attribute than rVTHarm which regularizes the representation.",
        "In addition, we examine the attention maps of rVTHarm with different values of α . We randomly sample z , where α is set to be one of {− 3 , 0 , 3 } , and generate the chords from z and the test melodies. We sum the attention matrices along the head dimension to see the aggregated weights. Fig. 3 shows that the attention weights become balanced and diagonal when α increases from − 3 to 3. This implies that the decoder of rVTHarm tends to focus on more melody notes when α increases.\n\n#### The proposed measure to quantize how the attention maps differ by a value of alpha would be one of the metrics that detect the diagonality of the matrix.",
        "where V denotes VTHarm, Concatd denotes the concatenation over the feature dimension, Pool denotes the average pooling over time, and self-AttBlock denotes only one loop of\n\n#### The alpha has been selected to be one of {-3, 0, 3} since {-3, 3} can be the two extremes for the prior that is assumed to be the normal distribution, where the range from -3 to 3 includes 99.7% of the probability distribution.",
        "Training VTHarm alone cannot guarantee a disentangled representation of the desired aspect. Therefore, rVTHarm aims to achieve a disentangled representation to control the generated chord outputs. We use the auxiliary loss by Pati et al. [32] to directly supervise the latent representation z . In this study, we choose the number of unique chords in the progression, or chord coverage , as a naive attribute for the chord complexity [10].\n\n#### rVTHarm is better than VTHarm in that it can control the desired attribute of chords with the latent representation while VTHarm is not guaranteed for controllable generation of the chords. Although rVTHarm does not show the best scores in any metrics for the listening test, it shows higher preference scores than VTHarm with melody awareness. Practically, the melody would be aware by the user as the melody is intentionally created or memorized by the user, hence the strength of rVTHarm in the situation with melody awareness can be more helpful than VTHarm.",
        "Figs. 4 and 5 show some of the actual samples from the listening test for all ﬁve models as well as the human- composed music. These samples reveal the strengths of the proposed models. First, Fig. 4 mainly shows that the proposed models tend to reproduce the binary metrical structure of the chords compared to the baseline models. The binary metric structure is close to real-world music, most of which has been composed of four beats and strongly inﬂuenced by metrical boundaries [52]. In contrast, the chords generated from the baseline models show some syncopated rhythms, which can weaken the metrical boundaries. Fig. 5 illustrates another advantage of the proposed models, which is that the majority of the chord roots tend to shift in intervals either of perfect fourth or ﬁfth according to the circle-of- ﬁfths rule. This aspect reﬂects conventional Western music theory, which serves as domain knowledge for modeling real-world music [51], [54]. Moreover, the proposed models are shown to generate some natural chromatic progressions according to the given melody. On the other hand, the baseline models show some short transitions on the circle-of-ﬁfths at arbitrary spots, in contrast to the melody with regular phrasings.\n\n#### The baseline models can be concluded to be weaker than the proposed models in that they generate some syncopated rhythms of chords which are not close to real-world music which is mostly composed of four or binary beats for a bar and strongly influenced by metrical boundaries.",
        "The encoder used in VTHarm is identical to the encoder used in STHarm, except that the conditional token c is con- catenated at the beginning of the note-based melody embed-\n\n#### The \"beginning\" of the decoder input is a sum of the latent variable z and the key signature token c, which is concatenated over the sequence dimension. The concatenated embeddings are not added to any embedding such as that for the <bos> token.",
        "We conduct an ablation study to verify the beneﬁt of adding the conditional token c to VTHarm and rVTHarm. We assume that c provides key signature information that can efﬁciently constrain the latent space to a concrete harmonic context, improving the chord structuredness and reconstruction per- formance of the model. We compute the chord similarity metrics between the ground truth and generated chords from the VT models according to the presence of c . The results are demonstrated in Table 7. This table shows that the VT models without c mostly obtain worse scores for all similarity metrics than the models with c . This indicates that adding key signature information to the VT models in most cases not only enhances the one-by-one accuracy but also improves the structure of the generated chords to be more human-like.\n\n#### It is valid enough to conduct an ablation study on harmonic similarity because constraining the harmonic context fundamentally aims to improve the chord structuredness and reconstruction performance. Constraining the harmonic context with the key signature can help the model specify the latent space and increase the probability to generate the right chord sequence that is close to the human-composed data which is well-structured.",
        "When the melody is unaware, BLSTM and rVTHarm obtain signiﬁcantly lower Preference scores than when the melody is aware ( p < 0 . 001). We further compute Pearson’s correlation coefﬁcient of U with C or P scores, as shown in Table 6. As a result, rVTHarm reveals the most nega- tive correlation of U with both C and P scores when the melody is aware. This indicates that 1) controlled chords are more unexpected and unpleasant with a familiar melody, and 2) some factors other than complexity seem to cause an increased unexpectedness in rVTHarm. However, the mean preference score of rVTHarm signiﬁcantly increases with melody awareness. This implies that the familiarity of the melody may strongly compensate for the high unexpect- edness of rVTHarm. This tendency needs further investi- gation to improve the robustness of controllable melody harmonization.\n\n#### The method for exploring the effect of melody awareness can be one that deeply investigates how the awareness of the melody can affect the unexpectedness of the controlled chords and how this unexpectedness affects the perceived complexity and preference of the chords.",
        "However, these studies have constrained musical creativity. Maezawa et al. controlled musical expression only through quantized features from the musical scores. Tan et al. did not consider controlling tempo or timing with a latent representation. These methods may have restricted any potential for rendering piano performances with flexible musical expression. Musical creativity can be expanded not only by composers but also by performers who can elastically choose various strategies to highlight multiple nuances or emotions [13, 14, 15]. Moreover, the music generation field can be also broadened if static music created by automatic composition systems can be easily colored with realistic and elastic expression [16].\n\n#### An example of \"explicit planning\" would be the plan or strategy of abruptly increasing dynamics for performing a climax within the music to highlight a certain emotion such as anger.",
        "Score Features. The features for a musical score represent eight categorical attributes for how the notes are composed:Pitch is a MIDI index number that ranges from 21 to 108.RelDuration and RelIOI are 11-class attributes of a quantized duration and IOI between a note onset and a previous chord, respectively. They range from 1 to 11, and each class represents a multiple of a 16th note’s length with respect to a given tempo [30, 31].IsTopVoice is a binary attribute of whether the note is the uppermost voice. It is heuristically computed regarding pitches and durations of surrounding notes.PositionInChord and NumInChord are 11-class attributes of a positional index of a note within its chord and the total number of notes in that chord, respectively, that range from 1 to 11. An index 1 for PositionInChord denotes the most bottom position.Staff is a binary attribute of the staff of a note, either of the G clef or F clef.IsDownbeat is a binary attribute of whether a note is at a downbeat or not.\n\n#### IsTopVoice is different from PositionInChord in that an index 1 of IsTopVoice represents the uppermost voice while that of PositionInChord represents the lowermost voice. They are also different that IsTopVoice is binary while PositionInChord is multi-class.",
        "We employ a self-supervised learning framework to force the latent representations to learn our target attributes [25, 26, 24].In addition, we facilitate independent control of the three expressive attributes–dynamics, articulation, and tempo–by utilizing an existing method that aligns the latent code with a target attribute [27, 28]. Finally, we design a novel mechanism that intuitively models a polyphonic structure of piano performance. In particular, we insert intermediate steps for chordwise encoding and decoding of the piano performance to our encoder-decoder architecture, where a chord denotes a group of simultaneous notes.\n\n#### The authors intend a \"chord\" to represent simultaneous notes to intuitively models a polyphonic structure of piano performance that is defined by its temporal progression. More fine-grained resolution than the beat-based resolution can reflect trivial changes in expression that varies by simultaneous note groups, such as a syncopation.",
        "Inference. A probabilistic encoder parameterized by \\phi approximates the posterior distibutions of the latent representations z^{(\\text{pln})} and z^{(\\text{str})} from the performance input x and conditional score input y:\\displaystyle q_{\\phi}(z^{(\\text{pln})},z^{(\\text{str})}|x,y)=\\displaystyle q_{\\phi}(z^{(\\text{pln})}|x^{(\\text{chd})})(3)\\displaystyle\\prod_{c=1}^{C}q_{\\phi}(z^{(\\text{str})}_{c}|x^{(\\text{chd})}_{\\leq c},y^{(\\text{chd})}_{\\leq c})where x^{(\\text{chd})}=\\text{N2C}(e_{x}) is the chordwise embedding, and e_{x} is the notewise embedding for x. The posterior distributions of z^{(\\text{pln})}_{c} and z^{(\\text{str})}_{c} are approximated by distribution parameters encoded by f^{(\\text{pln})}(x^{(\\text{chd})}) and f^{(\\text{str})}(x^{(\\text{chd})},y^{(\\text{chd})}), where f^{(\\text{pln})} and f^{(\\text{str})} are bidirectional and unidirectional recurrent neural networks, respectively.We note that z^{(\\text{pln})} is independent of the score features y. This allows a flexible transfer of the explicit planning among other musical pieces. On the other hand, z^{(\\text{str})} is constrained by y since the structural attributes are dependent on the note structure.\n\n#### The latent variable for explicit planning has no temporal dependency. The latent variable is derived from the standard normal distribution without the dependency on the score features.",
        "Prediction Tasks. We extract new supervisory signals for additional prediction tasks from the input data [24]. We define a signal of explicit planning I^{(\\text{pln})} as a set of smoothed contours of the expressive parameters. It is extracted as a polynomial function predicted from the chordwise performance parameters k. We also derive a signal of structural attribute as I^{(\\text{str})}=\\text{sign}(k-I^{(\\text{pln})}) which represents normalized directions of the performance parameters.We train two discriminators D^{(\\text{pln})} and D^{(\\text{str})} that directly receive z^{(\\text{pln})} and z^{(\\text{str})}, respectively. D^{(\\text{pln})} is composed of A sub-discriminators where each discriminator D^{(\\text{pln})}_{a} predicts a signal I^{(\\text{pln})}_{a} for each expressive attribute a from z^{(\\text{pln})}_{a}\\in\\mathbb{R}^{C\\times(d^{(\\text{pln})}/A)}, where z^{(\\text{pln})}_{a} is a constituent part of z^{(\\text{pln})}, and A is the number of expressive attributes. This setting is for a clear disentanglement among the expressive attributes. On the other hand, D^{(\\text{str})} predicts the signal I^{(\\text{str})} at once for all expressive attributes that belong to the same musical structure. All discriminators are jointly trained with the generative model, and the costs \\mathcal{L}_{\\text{pln}} and \\mathcal{L}_{\\text{str}} are minimized as \\mathcal{L}_{\\text{pln}}=\\frac{1}{A}\\sum_{a}\\text{MSE}(D^{(\\text{pln})}_{a}(z^{(\\text{pln})}_{a}),I^{(\\text{pln})}_{a}) and \\mathcal{L}_{\\text{str}}=\\text{MSE}(D^{(\\text{str})}(z^{(\\text{str})}),I^{(\\text{str})}), respectively.\n\n#### The authors use a polynomial function to extract explicit planning as explicit planning is defined to be a high-level sketch that the performer draws as the bigger plan of progressing musical expression throughout the piece. Such a sketch is assumed to be \"smoothed\" since it would derive from human thought that memorizes or imagines musical expression that can be also represented as an aural form by  \"singing out\" the musical progression.",
        "We use Yamaha e-Competition Dataset [8] and Vienna 4x22 Piano Corpus [40]. From these datasets, we collect 356 performances of 34 pieces by Frédéric Chopin, which have been representative research subjects for analyzing the Western musical expression [22, 41, 6, 42]. We use 30 pieces (108,738 batches) for training and the rest for testing. To verify the generality of model performances, we also collect the external dataset from ASAP dataset [43]. We use 116 performances for 23 pieces by 10 composers who represent various eras of Western music. For subjective evaluation, we collect 42 songs of non-Classical songs from online source222http://www.ambrosepianotabs.com/page/library which are less constrained to written expression than most Classical excerpts.\n\n#### The authors use only one composer, Chopin, rather than several composers together because Chopin's music has been one of the most common resources that are analyzed by literature to investigate the development in Western musical expression with respect to various musical structures. In other words, modeling music only from Chopin is assumed to be enough for learning Western musical expression derived from various musical patterns.",
        "Therefore, we attempt a new approach that renders piano performances with flexible musical expressions. We disregard a typical assumption from previous studies that a performer must follow a composer’s intent [4, 17–19]. According to the literature, performers learn to identify or imitate \"expressive models\", or explicit planning, of existing piano performances [20]. We focus on this attribute, defining it as a higher-level sketch of the expressive attributes (i.e. dynamics, articulation, and tempo [21]) that the performer draws based on a personal interpretation of the musical piece [4, 11, 20]. We also assume that the remaining attribute represents common performing strategies that are connected to certain musical patterns, while these strategies slightly differ across performers [22, 23]. We call this attribute as a structural attribute that belongs to given note structures of a musical piece.\n\n#### The authors did not use the previous studies as the baseline models since the proposed work attempts a new approach that disregards a typical assumption from the previous studies. There has been no identical assumption in the previous studies that musical expression can vary regardless of the written expression provided by the composers.",
        "We verify whether the latent representations are well-disentangled by appropriate information[24]. To this end, each model infers the latent representations z^{(\\text{pln})} and z^{(\\text{str})} from the test sets. Each model also randomly samples \\tilde{z}^{(\\text{str})} and infers z^{(\\text{pln})}_{0}\\sim q_{\\phi}(z^{(\\text{pln})}|x_{0}). We use z^{(\\text{pln})}_{0} to measure the structural attribute, since z^{(\\text{pln})}_{0} represents a flat expression where the structural attribute can be solely exposed. Each model generates new outputs as x^{(\\text{pln})}\\sim p_{\\theta}(x^{(\\text{pln})}|z^{(\\text{pln})},\\tilde{z}^{(\\text{str})},y) and x^{(\\text{str})}\\sim p_{\\theta}(x^{(\\text{str})}|z^{(\\text{pln})}_{0},z^{(\\text{str})},y). Then, we compute a new signal \\tilde{I}^{(\\text{pln})} from x^{(\\text{pln})} using the polynomial regression. The MSE values are calculated as \\text{MSE}_{\\text{p}}=\\text{MSE}(\\tilde{I}^{(\\text{pln})},I^{(\\text{pln})}) and \\text{MSE}_{\\text{s}}=\\text{MSE}(x^{(\\text{str})},k-I^{(\\text{pln})}).\n\n#### The reconstruction metric that measures the performance for predicting the structure attribute is calculated from zero explicit planning. The reason is that using a flat expression derived by the zero explicit planning can let the generated structural attribute be solely exposed, not mixed with any musical expression.",
        "We verify whether the latent representations are well-disentangled by appropriate information[24]. To this end, each model infers the latent representations z^{(\\text{pln})} and z^{(\\text{str})} from the test sets. Each model also randomly samples \\tilde{z}^{(\\text{str})} and infers z^{(\\text{pln})}_{0}\\sim q_{\\phi}(z^{(\\text{pln})}|x_{0}). We use z^{(\\text{pln})}_{0} to measure the structural attribute, since z^{(\\text{pln})}_{0} represents a flat expression where the structural attribute can be solely exposed. Each model generates new outputs as x^{(\\text{pln})}\\sim p_{\\theta}(x^{(\\text{pln})}|z^{(\\text{pln})},\\tilde{z}^{(\\text{str})},y) and x^{(\\text{str})}\\sim p_{\\theta}(x^{(\\text{str})}|z^{(\\text{pln})}_{0},z^{(\\text{str})},y). Then, we compute a new signal \\tilde{I}^{(\\text{pln})} from x^{(\\text{pln})} using the polynomial regression. The MSE values are calculated as \\text{MSE}_{\\text{p}}=\\text{MSE}(\\tilde{I}^{(\\text{pln})},I^{(\\text{pln})}) and \\text{MSE}_{\\text{s}}=\\text{MSE}(x^{(\\text{str})},k-I^{(\\text{pln})}).\n\n#### The authors use the randomly sampled z(str) to measure explicit planning as they aim to disentangle explicit planning from any structural attribute. They also use z(pln) from zero explicit planning to measure the structural attributes since a flat expression can expose any structural attribute that is not mixed with arbitrary musical expression.",
        "We conduct a listening test to compare the proposed model architecture to Notewise and CVAE. We qualitatively evaluate the base quality of the samples that have flat expressions, so that quality judgments are independent of any preference of arbitrary explicit planning. We generate each sample using z^{(\\text{pln})}_{0}. A listening test is composed of 30 trials where each participant chooses a more \"human-like\" sample out of the generated sample and its plain MIDI [9]. Both samples have the same length which is a maximum of 15 seconds, rendered with TiMidity++333https://sourceforge.net/projects/timidity/ without any pedal effect. Human-likeness denotes how similar the sample is to an actual piano performance that commonly appears in popular music. A total of 28 participants are involved, and 6 participants are professionally trained in music.\n\n#### The authors didn't try the listening test for the samples from non-zero, realistic explicit planning due to the following reason. Such realistic explicit planning should be inserted by the user, or inferred from the posterior distribution with respect to the ground truth data, maybe Classical music with various musical expressions, but the existing expressions can be already constrained by the written guidelines. The written expression can be a strong bias to the listeners so that the new expression against the original expression can be perceived as awkward regardless of how natural the expression itself is.",
        "Therefore, we attempt a new approach that renders piano performances with flexible musical expressions. We disregard a typical assumption from previous studies that a performer must follow a composer’s intent [17, 18, 19, 4]. According to the literature, performers learn to identify or imitate \"expressive models\", or explicit planning, of existing piano performances [20]. We focus on this attribute, defining it as a higher-level sketch of the expressive attributes (i.e. dynamics, articulation, and tempo [21]) that the performer draws based on a personal interpretation of the musical piece [20, 4, 11]. We also assume that the remaining attribute represents common performing strategies that are connected to certain musical patterns, while these strategies slightly differ across performers [22, 23]. We call this attribute as a structural attribute that belongs to given note structures of a musical piece.\n\n#### The difference between the black and orange lines can be interpreted as a granular variety in the performing strategies with respect to the given musical structure by different performers. Those different strategies can represent the common technique that the performers may choose to represent the musical structure, but they may vary since they are induced from two human behaviors that cannot be identical to each other.",
        "Prediction Tasks. We extract new supervisory signals for additional prediction tasks from the input data [24]. We define a signal of explicit planning I^{(\\text{pln})} as a set of smoothed contours of the expressive parameters. It is extracted as a polynomial function predicted from the chordwise performance parameters k. We also derive a signal of structural attribute as I^{(\\text{str})}=\\text{sign}(k-I^{(\\text{pln})}) which represents normalized directions of the performance parameters.We train two discriminators D^{(\\text{pln})} and D^{(\\text{str})} that directly receive z^{(\\text{pln})} and z^{(\\text{str})}, respectively. D^{(\\text{pln})} is composed of A sub-discriminators where each discriminator D^{(\\text{pln})}_{a} predicts a signal I^{(\\text{pln})}_{a} for each expressive attribute a from z^{(\\text{pln})}_{a}\\in\\mathbb{R}^{C\\times(d^{(\\text{pln})}/A)}, where z^{(\\text{pln})}_{a} is a constituent part of z^{(\\text{pln})}, and A is the number of expressive attributes. This setting is for a clear disentanglement among the expressive attributes. On the other hand, D^{(\\text{str})} predicts the signal I^{(\\text{str})} at once for all expressive attributes that belong to the same musical structure. All discriminators are jointly trained with the generative model, and the costs \\mathcal{L}_{\\text{pln}} and \\mathcal{L}_{\\text{str}} are minimized as \\mathcal{L}_{\\text{pln}}=\\frac{1}{A}\\sum_{a}\\text{MSE}(D^{(\\text{pln})}_{a}(z^{(\\text{pln})}_{a}),I^{(\\text{pln})}_{a}) and \\mathcal{L}_{\\text{str}}=\\text{MSE}(D^{(\\text{str})}(z^{(\\text{str})}),I^{(\\text{str})}), respectively.\n\n#### Conducting polynomial regression is different from predicting explicit planning from the learned representation since polynomial regression would be based on a finite set of data in a certain length. In other words, different lengths of the input data of the polynomial function can result in different polynomial curves. On the other hand, the prediction of explicit planning from the latent representation is not affected by the input length.",
        "We use Yamaha e-Competition Dataset [8] and Vienna 4x22 Piano Corpus [40]. From these datasets, we collect 356 performances of 34 pieces by Frédéric Chopin, which have been representative research subjects for analyzing the Western musical expression [22, 41, 6, 42]. We use 30 pieces (108,738 batches) for training and the rest for testing. To verify the generality of model performances, we also collect the external dataset from ASAP dataset [43]. We use 116 performances for 23 pieces by 10 composers who represent various eras of Western music. For subjective evaluation, we collect 42 songs of non-Classical songs from online source222http://www.ambrosepianotabs.com/page/library which are less constrained to written expression than most Classical excerpts.\n\n#### The possible genres or composers to use in the experiments for further investigation would be more contemporary genres, such as jazz or blues, since the trained dataset is completely Classical while the test dataset is more contemporary.",
        "Baselines. We evaluate our methods with five graph neural networks : GCN GCN , GAT GAT , GIN xu2018powerful , SGConv wu2019simplifying  and GTN yun2019graph . Our methods can be applied to both homogeneous graphs and heterogeneous graphs. We compare four learning strategies: Vanilla, standard training of base models only with the primary task samples; w/o meta-path, learning a primary task with sample weighting function \\mathcal{V}(\\xi;\\Theta); w/ meta-path, training with the primary task and auxiliary tasks (meta-path prediction) with a standard loss function; SELAR proposed in Section 3.2, learning the primary task with optimized auxiliary tasks by meta-learning; SELAR+Hint introduced in Section 3.3.In all the experiments, we report the mean performance of three independent runs.Implementation details are in the supplement. Our experiments were mainly performed based on NAVER Smart Machine Learning platform (NSML) sung2017nsml ; kim2018nsml .\n\n#### Yes, GTN (Graph Transformer Networks) among the five GNNs used for evaluation is designed for heterogeneous graphs.",
        "Pre-training with an auxiliary task is a common technique for deep neural networks.Indeed, it is the de facto standard step in natural language processing and computer vision to learn a powerful backbone networks such as BERT devlin2018bert  and ResNet he2016deep  leveraging large datasets such as BooksCorpus zhu2015aligning , English Wikipedia, and ImageNet deng2009imagenet .The models trained on the auxiliary task are often beneficial for the primary (target) task of interest.Despite the success of pre-training, few approaches have been generalized to graph-structured data due to their fundamental challenges.First, graph structure (e.g., the number of nodes/edges, and diameter) and its meaning can significantly differ between domains. So the model trained on an auxiliary task can harm generalization on the primary task, i.e., negative transfer pan2009survey .Also, many graph neural networks are transductive approaches. This often makes transfer learning between datasets inherently infeasible.So, pre-training on the target dataset has been proposed using auxiliary tasks: graph kernel  navarin2018pre , graph reconstruction zhang2020graph , and attribute masking  hu2020strategies . These assume that the auxiliary tasks for pre-training are carefully selected with substantial domain knowledge and expertise in graph characteristics to assist the primary task.Since most graph neural networks operate on homogeneous graphs, which have a single type of nodes and edges, the previous pre-training/auxiliary tasksare not specifically designed for heterogeneous graphs, which have multiple types of nodes and edges.Heterogeneous graphs commonly occur in real-world applications, for instance, a music dataset has multiple types of nodes (e.g., user, song, artist) and multiple types of relations (e.g., user-artist, song-film, song-instrument).\n\n#### Negative transfer happens when the learning of an auxiliary task negatively impacts the performance of the primary task. In the case of graph-based tasks, it can happen because the graph structure, such as the number of nodes, edges, and diameter, can be vastly different between domains. This causes confusion for the model, resulting in poor generalization of the primary task.",
        "Meta-path prediction is similar to link prediction but meta-paths allow heterogeneous composite relations.The meta-path prediction can be achieved in the same manner as link prediction.If two nodes u and v are connected by a meta-path p with the heterogeneous edges (t_{1},t_{2},\\ldots t_{\\ell}), then y_{u,v}^{p}=1, otherwise y_{u,v}^{p}=0. The labels can be generated from a heterogeneous graph without any manual labeling.They can be obtained by A_{p}=A_{t_{l}}\\ldots A_{t_{2}}A_{t_{1}}, where A_{t} is the adjacency matrix of edge type t. The binarized value at (u,v) in A_{p} indicates whether u and v are connected with the meta-path p.In this paper, we use meta-path prediction as a self-supervised auxiliary task.\n\n#### The authors designed the meta-path prediction task as a variation of link prediction. In meta-path prediction, instead of just predicting links between two nodes, the task is to predict the presence of a specific sequence of heterogeneous composite relations, called a meta-path. The prediction is done in the same way as link prediction, by assigning a binary label (1 or 0) to indicate whether the two nodes are connected by the meta-path. The labels for the task can be generated automatically from the heterogeneous graph, by calculating the product of the adjacency matrices of the edge types in the meta-path.",
        "Meta-path prediction is generally more challenging than link prediction and node classification since it requires the understanding of long-range relations across heterogeneous nodes. The meta-path prediction gets more difficult when mini-batch training is inevitable due to the size of datasets or models. Within a mini-batch, important nodes and edges for meta-paths are not available. Also, a small learner network, e.g., two-layer GNNs, with a limited receptive field, inherently cannot capture long-range relations. The challenges can hinder representation learning and damage the generalization of the primary task. We proposed a Hint Network (HintNet) which makes the challenge tasks more solvable by correcting the answer with more information at the learner’s need. Specifically, in our experiments, the HintNet corrects the answer of the learner with its own answer from the augmented graph with hub nodes, see Fig. 2.\n\n#### Challenging auxiliary tasks refer to tasks that are difficult for the model to learn, which can negatively impact the performance of the primary task. In the case of meta-path prediction, it is considered more challenging than link prediction and node classification because it requires the understanding of long-range relations across heterogeneous nodes. The task becomes even more difficult when mini-batch training is necessary due to the large size of datasets or models, as important nodes and edges for meta-paths may not be available within a mini-batch.",
        "The amount of help (correction) by HintNet is optimized maximizing the learner’s gain.Let \\mathcal{V}_{H}(\\cdot) and \\Theta_{H} be a weight function to determine the amount of hint and its parameters which are optimized by meta-learning. Then, our formulation with HintNet is given as\\displaystyle\\min_{\\mathbf{w},\\Theta}\\sum_{i=1}^{M_{0}}\\frac{1}{M_{0}}\\ell^{0}(y_{i}^{(0,meta)},f(x_{i}^{(0,meta)};\\mathbf{w}^{\\ast}(\\Theta,\\Theta_{H})))(10)\\displaystyle\\text{s.t. }\\mathbf{w}^{\\ast}(\\Theta)=\\operatorname*{\\arg\\!\\min}_{\\mathbf{w}}\\sum_{t=0}^{T}\\sum_{i=1}^{N_{t}}\\frac{1}{N_{t}}\\mathcal{V}(\\xi^{(t,train)}_{i},\\ell^{t};\\Theta)\\ell^{t}(y_{i}^{(t,train)},\\hat{y}_{i}^{(t,train)}(\\Theta_{H})),(11)where \\hat{y}_{i}^{(t,train)}(\\Theta_{H}) denotes the convex combination of the learner’s answer and HintNet’s answer, i.e., \\mathcal{V}_{H}(\\xi^{(t,train)}_{i};\\Theta_{H})f^{t}(x_{i}^{(t,train)};\\mathbf{w})+(1-\\mathcal{V}_{H}(\\xi^{(t,train)}_{i};\\Theta_{H}))f_{H}^{t}(x_{i}^{(t,train)};\\mathbf{w}). The sample embedding is\\xi^{(t,train)}_{i}=\\left[\\ell^{t};\\ell^{t}_{H};e_{t};y_{i}^{(t,train)}\\right]\\in\\textbf{R}^{T+3}.\n\n#### The HintNet is designed to make challenging tasks more solvable by providing the model with additional information at the point of need, specifically by correcting the answer of the learner with its own answer from an augmented graph with hub nodes. The amount of help (correction) provided by the HintNet is optimized to maximize the learner's gain, and the help is determined by weighting functions for HintNet, which are optimized by meta-learning.",
        "Baselines. We evaluate our methods with five graph neural networks : GCN GCN , GAT GAT , GIN xu2018powerful , SGConv wu2019simplifying  and GTN yun2019graph . Our methods can be applied to both homogeneous graphs and heterogeneous graphs. We compare four learning strategies: Vanilla, standard training of base models only with the primary task samples; w/o meta-path, learning a primary task with sample weighting function \\mathcal{V}(\\xi;\\Theta); w/ meta-path, training with the primary task and auxiliary tasks (meta-path prediction) with a standard loss function; SELAR proposed in Section 3.2, learning the primary task with optimized auxiliary tasks by meta-learning; SELAR+Hint introduced in Section 3.3.In all the experiments, we report the mean performance of three independent runs.Implementation details are in the supplement. Our experiments were mainly performed based on NAVER Smart Machine Learning platform (NSML) sung2017nsml ; kim2018nsml .\n\n#### This paper experimentally shows that auxiliary tasks are not always beneficial by comparing four different learning strategies. The first strategy, \"Vanilla,\" involves standard training of base models only with the primary task samples. \"w/ meta-path,\" involves training with the primary task and auxiliary tasks using a standard loss function. By comparing the performance of these different strategies, the paper shows the impact of using auxiliary tasks, such as meta-path predictions, on the primary task and demonstrates that auxiliary tasks are not always beneficial.",
        "We proposed meta-path prediction as self-supervised auxiliary tasks on heterogeneous graphs.Our experiments show that the representation learning on heterogeneous graphscan benefit from meta-path prediction which encourages to capture rich semantic information.The auxiliary tasks can be further improved by our proposed method SELAR, which automatically balances auxiliary tasks to assist the primary task via a form of meta-learning.The learnt weighting function identifies more beneficial meta-paths for the primary tasks.Within a task, the weighting function can adjust the cross entropy like the focal loss, which focuses on hard examples by decreasing weights for easy samples.Moreover, when it comes to challenging and remotely relevant auxiliary tasks,our HintNet helps the learner by correcting the learner’s answer dynamically and further improves the gain from auxiliary tasks.Our framework based on meta-learning provides learning strategies to balance primary task and auxiliary tasks, and easy/hard (and positive/negative) samples.Interesting future directions include applying our framework to other domains and various auxiliary tasks.Our code is publicly available at https://github.com/mlvlab/SELAR.\n\n#### In this paper, the authors did not conduct experiments on extending the framework to other auxiliary tasks besides meta-path prediction. However, the authors mention that it is a possible direction for future work.",
        "Meta-Path HAN ; sun2011pathsim  is a path on a heterogeneous graph G that a sequence of nodes connected with heterogeneous edges, i.e., {v}_{1}\\xrightarrow{t_{1}}{v}_{2}\\xrightarrow{t_{2}}\\ldots\\xrightarrow{t_{l}}{v}_{l+1},where t_{l}\\in\\mathcal{T}^{e} denotes an l-th edge type of the meta-path.The meta-path can be viewed as a composite relation R=t_{1}\\circ t_{2}\\ldots\\circ t_{l} between node {v}_{1} and {v}_{l+1}, where R_{1}\\circ R_{2} denotes the composition of relation R_{1} and R_{2}.The definition of meta-path generalizes multi-hop connections and is shown to be useful to analyze heterogeneous graphs.For instance, in Book-Crossing dataset, ‘user-item-written.series-item-user’ indicates that a meta-path that connects users who like the same book series.\n\n#### A meta-path is a sequence of node types and edge types in a graph that describes a specific type of relationship between nodes. An example is in a recommendation system, a meta-path could be \"user-item-written.series-item-user\" which describes a relationship between users who like the same book series.",
        "Our framework SELAR is learning to learn a primary task with multiple auxiliary tasks to assist the primary task. This can be formally written as min w,Θ E [ L pr(w∗ (Θ)) ] (x,y)∼Dpr s.t. w∗ (Θ) = argmin w E L pr+au(w; Θ) (x,y)∼Dpr+au , (2) where L pr(·) is the primary task loss function to evaluate the trained model f(x; w∗ (Θ)) on metadata (a validation for meta-learning [40]) Dpr and L pr+au is the loss function to train a model on training data Dpr+au with the primary and auxiliary tasks. To avoid cluttered notation, f, x, and y are omitted. Each task Tt has Nt samples and T0 and {Tt} T t=1 denote the primary and auxiliary tasks respectively. The proposed formulation in Eq. (2) learns how to assist the primary task by optimizing Θ via meta-learning. The nested optimization problem given Θ is a regular training with properly adjusted loss functions to balance the primary and auxiliary tasks. The formulation can be more specifically written as\n\n#### In the proposed method, meta-data serves as a signal to guide the update of the model's parameters in a way that improves the primary task. It is used in the outer loop of the bi-level optimization process to evaluate the performance of the model on the primary task, represented by the primary task loss function Lpr(·). In other words, meta-data is used to provide guidance for the learning process in a way that improves the primary task.",
        "The model parameters \\mathbf{w}^{k} for tasks can be updated with optimized \\Theta^{k+1} in (7) as\\displaystyle\\mathbf{w}^{k+1}=\\mathbf{w}^{k}-\\alpha\\nabla_{\\mathbf{w}}\\mathcal{L}^{pr+au}(\\mathbf{w}^{k};\\Theta^{k+1}).(8)Remarks. The proposed formulation can suffer from the meta-overfitting antoniou2018train ; zintgraf2018fast  meaning that the parameters \\Theta to learn weights for softly selecting meta-paths and balancing the tasks with the primary task can overfit to the small meta-dataset.In our experiment, we found that the overfitting can be alleviated by meta-validation sets antoniou2018train .To learn \\Theta that is generalizable across meta-training sets, we optimize \\Theta across k different meta-datasets like k-fold cross validation using the following equation:Θk+1=Θk−β𝔼[∇Θℒp⁢r(𝐰^k(Θk))],Dp⁢r⁢(m⁢e⁢t⁢a)∼CV\\displaystyle\\Theta^{k+1}\\;=\\;\\underset{D^{pr(meta)}\\sim CV\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;}{\\Theta^{k}\\;-\\;\\;\\beta\\;\\;\\mathbb{E}\\left[\\;\\nabla_{\\Theta}\\mathcal{L}^{pr}(\\hat{\\mathbf{w}}^{k}(\\Theta^{k}))\\;\\right],}roman_Θ start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT = start_UNDERACCENT italic_D start_POSTSUPERSCRIPT italic_p italic_r ( italic_m italic_e italic_t italic_a ) end_POSTSUPERSCRIPT ∼ italic_C italic_V end_UNDERACCENT start_ARG roman_Θ start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT - italic_β blackboard_E [ ∇ start_POSTSUBSCRIPT roman_Θ end_POSTSUBSCRIPT caligraphic_L start_POSTSUPERSCRIPT italic_p italic_r end_POSTSUPERSCRIPT ( over^ start_ARG bold_w end_ARG start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( roman_Θ start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ) ) ] , end_ARG(9)where D^{pr(meta)}\\sim CV is a meta-dataset from cross validation. We used 3-fold cross validation and the gradients of \\Theta w.r.t different meta-datasets are averaged to update \\Theta^{k}, see Algorithm 1. The cross validation is crucial to alleviate meta-overfitting and more discussion is Section 4.3.\n\n#### The goal is to optimize these parameters in a way that improves the performance of the primary task by utilizing the auxiliary tasks. The optimization process becomes difficult because the primary task and auxiliary tasks may have conflicting objectives, making it challenging to find a set of parameters that work well for both. Additionally, the nested optimization problem can become computationally expensive.",
        "Sampling anchor points is the first step of our framework to locate multiple local transformations.To minimize the redundancy between local transformations, the anchor points \\mathcal{P}^{\\mathcal{A}}\\subset\\mathcal{P} are selected by the Farthest Point Sampling (FPS) algorithm.FPS randomly chooses the first point and then sequentially chooses the farthest points from previous points.This maximizes the coverage of anchor points and allows diverse transformations.\n\n#### In this paper, the anchor points are a subset of a set of points (denoted as P) that are selected using the Farthest Point Sampling (FPS) algorithm. The anchor points are chosen by first selecting a random point and then sequentially choosing the farthest points from the previous points.",
        "Smooth deformations are key to generate realistic and locally transformed samples.A naïve application of a random local transformation within its finite neighborhood may result in a discontinuous shape and an overlap of different parts. It has a high chance to lose discriminative structures.Instead, we employ the Nadaraya-Watson kernel regression [27, 28] to smoothly interpolate the local transformations in the 3D space.Given M local transformations \\{T_{j}\\}_{j=1}^{M}, our smoothly varying transformation at an arbitrary point \\mathbf{p}_{i} is given as:\\small\\hat{T}(\\mathbf{p}_{i})=\\frac{\\sum_{j=1}^{M}{K_{h}}(\\mathbf{p}_{i},\\mathbf{p}^{\\mathcal{A}}_{j})T_{j}}{\\sum_{k=1}^{M}{K_{h}}(\\mathbf{p}_{i},\\mathbf{p}^{\\mathcal{A}}_{k})},(3)where K_{h}(\\cdot,\\cdot) is a kernel function with bandwidth h, and T_{j} is the local transformation in (2) centered at \\mathbf{p}^{\\mathcal{A}}_{j}.To define \\hat{T}(\\mathbf{p}_{i}) at any point in the 3D space, we use a kernel function that has a strictly positive value for any pair of points,i.e., K_{h}(\\mathbf{p}_{i},\\mathbf{p}_{j})>0 for \\forall\\mathbf{p}_{i},\\forall\\mathbf{p}_{j}.The following proposition theoretically guarantees that our augmentation is a smooth transformation under mild conditions. The proof is in the supplement.\n\n#### A realistic sample in this context refers to a 3D object that has undergone a smooth deformation, meaning that the shape of the object changes gradually rather than abruptly. The realistic samples that the authors aim to generate are those that resemble real-world objects with diverse shapes and deformations, such as airplanes with varying wing lengths and directions, guitars with different sizes and aspect ratios, and people with different heights and postures.",
        "Smooth deformations are key to generate realistic and locally transformed samples.A naïve application of a random local transformation within its finite neighborhood may result in a discontinuous shape and an overlap of different parts. It has a high chance to lose discriminative structures.Instead, we employ the Nadaraya-Watson kernel regression [27, 28] to smoothly interpolate the local transformations in the 3D space.Given M local transformations \\{T_{j}\\}_{j=1}^{M}, our smoothly varying transformation at an arbitrary point \\mathbf{p}_{i} is given as:\\small\\hat{T}(\\mathbf{p}_{i})=\\frac{\\sum_{j=1}^{M}{K_{h}}(\\mathbf{p}_{i},\\mathbf{p}^{\\mathcal{A}}_{j})T_{j}}{\\sum_{k=1}^{M}{K_{h}}(\\mathbf{p}_{i},\\mathbf{p}^{\\mathcal{A}}_{k})},(3)where K_{h}(\\cdot,\\cdot) is a kernel function with bandwidth h, and T_{j} is the local transformation in (2) centered at \\mathbf{p}^{\\mathcal{A}}_{j}.To define \\hat{T}(\\mathbf{p}_{i}) at any point in the 3D space, we use a kernel function that has a strictly positive value for any pair of points,i.e., K_{h}(\\mathbf{p}_{i},\\mathbf{p}_{j})>0 for \\forall\\mathbf{p}_{i},\\forall\\mathbf{p}_{j}.The following proposition theoretically guarantees that our augmentation is a smooth transformation under mild conditions. The proof is in the supplement.\n\n#### The proposed method uses smoothly varying weights for transformations to generate realistic and locally transformed samples. The reason for this is that a naive application of a random local transformation within its finite neighborhood can result in a discontinuous shape and an overlap of different parts, leading to loss of discriminative structures, which can make the augmented object unrealistic. By using smoothly varying weights, the Nadaraya-Watson kernel regression is able to interpolate the local transformations in the 3D space smoothly, resulting in a more realistic and locally transformed sample.",
        "We present a simple yet effective point cloud augmentation with weighted local transformations (PointWOLF).Our method generates deformation for point clouds by a convex combination of multiple transformations with smoothly varying weights.PointWOLF first selects several anchor points and locates random local transformations (e.g., similarity transformations) at the anchor points.Based on the distance from a point in the input to the anchor points, our method differentially applies the local transformations.The smoothly varying weights based on the distance to the anchor points allow spatially continuous augmentation and generate realistic samples.Our framework can be viewed as a kernel regression with transformations.\n\n#### Maximizing the coverage of anchor points is necessary in order to ensure that the local transformations are being applied evenly across the entire input space. This allows for a more diverse set of augmented samples to be generated, which can help to improve the robustness and generalization of a model trained on the augmented data.",
        "Modern deep learning techniques, which established their popularity on structured data, began showing success on point clouds.Unlike images with clear lattice structures, each point cloud is an unordered set of points with no inherent structures that globally represent various 3D objects.Recent deep learning efforts have focused on enabling neural networks to operate on point clouds.While several point cloud datasets appeared, a particular dataset of scanned real-world objects [1] required a much greater understanding of the point cloud structures to identify highly complex real-world objects.In response, the approaches have evolved from extracting point-wise information with no structural information [2] to explicitly encoding the local structure [3].These works on network development have been making steady progress despite the scarcity of point cloud data.\n\n#### The difficulty of augmentation on point clouds compared to traditional 2D images is primarily due to the unordered and unstructured nature of point clouds. Unlike 2D images, which have a well-defined grid structure and pixels with fixed locations, point clouds are just a collection of points in 3D space. This makes it harder to apply standard image augmentation techniques, such as rotation and scaling, to point clouds. Additionally, point clouds often have missing or incomplete data, which can make it difficult to generate realistic augmentations.",
        "In this paper, we explore whether pretraining on text is inherently about learning language, or if pretraining also imbues LMs with skills for symbolic manipulation and non-linguistic reasoning (for example, performing quantitative computation such as finding the median of a set of numbers, recognizing regular expressions, or identifying whether a string is a palindrome, as shown in Figure 1). In other words, we investigate whether and how pretraining develops helpful inductive biases for non-linguistic reasoning. For this analysis, we create a set of 19 tasks from three categories of task paradigms: quantitative computation (§3.1), recognizing regular expressions (§3.2), and string reasoning (§3.3). Figure 1 shows an example for each category, and the full list of tasks is described in the table 1. We experiment with transformer and RNN based LMs (§4) for learning these tasks, and perform a comparative analysis with (non-pretrained) neural model variants from the perspective of learning metrics such as accuracy and sample efficiency.\n\n#### Non-linguistic is something which is not related to linguistic information, and it includes the tasks such as quantitative computation and decimal operation.",
        "Tables 2 and 3 shows the average accuracy of six non-linguistic tasks (palindrome classification, isogram classification, tautonym classification, odd even classification, decimal operation and median) fine-tuned using different BERT and DeBERTA representations respectively. We note that the models pretrained on all three domains outperformed the non-pretrained model (NP). This suggests that the results of experiments in Section 5 generalize to new text corpora for pretraining, and do not rely on having access to text on specific topics during pretraining. This is a non-trivial result, since it suggests for example, that the higher performance of pretrained models on tasks such as palindrome and anagram classification is not due to the pretrained models having seen information about such concepts during pretraining. This is especially so since the results even generalize to ROC stories, which contain no information on such technical concepts. \n\n#### It's false. Models which pretrained using three different data outperform all non-pretrained data.",
        "A possible rationale for explaining the beneficial effect of pretraining for non-linguistic tasks is that irrespective of whether the tasks require non-linguistic reasoning, their format is in language, and hence language models should be able to learn these tasks with fewer examples. To test this hypothesis, we also experiment with models pretrained on text from languages different from English, as well as models pretrained on computer code. These include the following models: Multilingual BERT.Multilingual BERT is pretrained on text from 102 different languages. About 21% of the pretraining text is English.Chinese BERT.Chinese BERT is a BERT model pretrained on Chinese text. Code BERT.CodeBERT Feng et al. (2020) is pretrained on code from six programming languages.\n\n#### No, CodeBERT trained by code from six programming language.",
        "Next, we describe the LMs and their variants used in NILM. We experiment with four language models, based on both Transformer and RNN architectures. BERT small.This is the bert-base-uncased model with 12 transformer encoder layers and the dimension of the representations is 768. BERT tokenizer is based on the WordPiece model Wu et al. (2016). BERT large.This is the bert-large-uncased model which has 24 transformer encoders and representations have 1024 dimensions. DeBERTa.This is a transformer based language model and its tokenizer is built using Byte Pair Encoding Sennrich et al. (2016). We consider the DeBERTa base model. It has 12 transformer encoder layers and representations have 768 dimensions. ELMO.This is an LSTM based language model Peters et al. (2018).It has 3 layers and the output representations have 1024 dimensions. \n\n#### No, because dimension of BERT-large is 1024, and DeBERTa is 768.",
        "Tables 2 and 3 shows the average accuracy of six non-linguistic tasks (palindrome classification, isogram classification, tautonym classification, odd even classification, decimal operation and median) fine-tuned using different BERT and DeBERTA representations respectively. We note that the models pretrained on all three domains outperformed the non-pretrained model (NP). This suggests that the results of experiments in Section 5 generalize to new text corpora for pretraining, and do not rely on having access to text on specific topics during pretraining. This is a non-trivial result, since it suggests for example, that the higher performance of pretrained models on tasks such as palindrome and anagram classification is not due to the pretrained models having seen information about such concepts during pretraining. This is especially so since the results even generalize to ROC stories, which contain no information on such technical concepts. \n\n#### They say that the reason of good performance of fine-tuned model is not caused by task specific knowledge.",
        "Tables 2 and 3 shows the average accuracy of six non-linguistic tasks (palindrome classification, isogram classification, tautonym classification, odd even classification, decimal operation and median) fine-tuned using different BERT and DeBERTA representations respectively. We note that the models pretrained on all three domains outperformed the non-pretrained model (NP). This suggests that the results of experiments in Section 5 generalize to new text corpora for pretraining, and do not rely on having access to text on specific topics during pretraining. This is a non-trivial result, since it suggests for example, that the higher performance of pretrained models on tasks such as palindrome and anagram classification is not due to the pretrained models having seen information about such concepts during pretraining. This is especially so since the results even generalize to ROC stories, which contain no information on such technical concepts. \n\n#### Odd classification is one of linguistic task because it does not included in six non-linguistic tasks.",
        "This task paradigm focuses on reasoning tasks over individual strings or pairs of strings. Palindrome classification.A string is a palindrome if it reads the same forward and backward. The task is to classify whether a given string is a palindrome. The string length ranges from 1 to 15.Anagram classification.Two strings are anagrams if one is formed by rearranging letters from the other. The task is to classify if a pair of strings are anagrams. The string length ranges from 2 to 15.Isogram classification.A string is an isogram if it has no repeating characters. The task is to classify whether a given string is an isogram. The string length ranges from 1 to 52.Tautonym classification.A tautonym is a word which can be broken down into two identical parts, with the same spelling. The task is to classify whether a given string is a tautonym. The string length ranges from 1 to 10. Length of a string.Output the length of a given string. The string length ranges from 1 to 10.Count of unique characters.Given a string, count the number of unique characters in it. The string lengths ranges from 10 to 30.Parity check.Given a binary string, output if the counts of ones and zeros are the same. The maximum length of the binary string is 20.Vowels classification.Given a string, classify if the string contains only vowel characters. The string length ranges from 3 to 10. Maximum frequent character.Given a string, output the character with the maximum frequency. The string length ranges from 5 to 30.\n\n#### Calculating length of a string is not a string reasoning task because it does not require character composition within or with another string.",
        "In this section, we describe the tasks used for our analysis, which we refer to as NILM (measuring Non-linguistic Inductive bias in Language Models). The tasks correspond to three task paradigms: (1) quantitative computation, (2) regular expressions, and (3) string reasoning. Each task in NILM is posed as a classification task. The descriptions for all the tasks with input and output examples, class labels and the input range are shown in Table 1. Each task has a synthetically generated dataset with train/dev/test splits222The training set size for all tasks is 10K, dev set size is 1K and test set size is 1K, except for tasks on recognizing regular expressions, where the test set size is 2K following previous work Bhattamishra et al. (2020).. To avoid biases in the datasets, relevant numbers and strings in individual examples are uniformly sampled from the appropriate ranges. \n\n#### It's true, becase NILM has three kinds of tasks, and all tasks it classification task.",
        "SNLI sort. The words in the sentences of SNLI dataset are sorted based on alphabetical order. SNLI shuffle. We randomly shuffle words in sentences in the SNLI dataset. Amazon reviews sort. Similar to SNLI sort, the words in sentences are alphabetically sorted. Amazon reviews shuffle. We randomly shuffle words in sentences in the Amazon reviews dataset.\n\n#### SNLI short consists of sentences with sorted words. However, SNLI shuffle consists of sentences with randomly shuffled words.",
        "Zipf distribution. We select 30k words (types) from the Amazon reviews dataset. Words are picked with a unigram probability that follows Zipf’s word frequency law, which all natural languages empirically follow Piantadosi (2014). For the Zipf distribution, we chose \\alpha=1 and \\beta=2.7, to match the parameters of most natural languages. The text does not follow any word order.Uniform distribution. In this dataset, words are sampled from the same vocabulary as in ‘Zipf distribution’, but with a uniform unigram probability. The text does not follow any word order.Synthetic Vocabulary. Words are selected with uniform distribution from a vocabulary to form sentences. However, instead of a vocabulary of English words, the words in the vocabulary are also synthetically generated (3 letter combinations of lower-case alphabets). In this text, the words do not possess morphology in addition to no syntax.\n\n#### Zipf distribution consists of words which picked with a unigram probability that follows Zipf's law. However, uniform distribution consists of words that sampled with a uniform unigram probability.",
        "Some previous works have explored the ability of RNN and Transformer architectures for learning regular languages Weiss et al. (2018); Sennhauser and Berwick (2018); Suzgun et al. (2019b); Bhattamishra et al. (2020), closing brackets Skachkova et al. (2018), and dynamic counting Suzgun et al. (2019a). However, they focus on the learnability of these tasks with specific architectures, and do not look at pretrained LMs, which are our focus here.\n\n#### Previous works only focus on the learnability of tasks. They do not concentrate in pretrained LMS. However, this paper focus on it.",
        "Pretrained Language Models (LMs) have shown singular succcess on a range of natural language understandings tasks, to the extent that they have become foundational for contemporary NLP systems. Several works have investigated why pretraining works so well Warstadt et al. (2019); Zhao et al. (2020). In particular, studies have shown that the pretrained LMs like BERT capture linguistic knowledge about syntax Lin et al. (2019); Wu et al. (2020), semantics Vulić et al. (2020b, a) and morphology Hofmann et al. (2020, 2021). In fact, Tenney et al. (2019) demonstrated that learned representations in pretrained LMs even internally reflect the classical NLP pipeline. Since most NLP benchmarks such as SuperGLUE Wang et al. (2019) naturally are focused on tasks such as textual entailment and reading comprehension that require linguistic knowledge and reasoning, it is unsurprising that LMs have achieved strong results on these tasks. On the other hand, little work so far has explored the abilities of pretrained LMs for learning non-linguistic tasks. \n\n#### NILM is the dataset of measuring Non-linguistic Inductive bias in Language Models. It is different with GLUE since GLUE focus on tasks require linguistic knowledge and reasoning.",
        "SNLI. We pretrained BERT small from scratch on SNLI data Bowman et al. (2015). It has 1000k sentences (570k pairs of text and hypothesis). Amazon reviews. We selected 500k movies and tv reviews from the larger Amazon reviews dataset He and McAuley (2016) and used for pretraining. Since reviews are in a free-text format, and their collection was not tailored with a NLP task in mind, they might be more representative of the complexity of real-world language use than SNLI.ROC. ROC is a corpora of 100K children stories, each made up of five sentences Mostafazadeh et al. (2017). The language in ROC is relatively simple in both vocabulary and sentence structure.\n\n#### SNLI is one of benchmark dataset published in 2015.",
        "This task paradigm focuses on tasks involving arithmetic and set statistics. Odd classification.Classify if a number is odd. Even classification.Classify if a number is even. Odd even classification.For a given number N and a string “even” or “odd”, classify if the number satisfies the string condition. Decimal operation. Subtract or divide two numbers. Operands are represented in decimal notation. Decimal & word operation. Subtract or divide two numbers. Operands are represented in decimal or word notation. Mean. Given a set of numbers, output the mean.Median. Given a set, output the median. Mode. Given a set of numbers, output the mode. \n\n#### Decimal & word operation is task of subtracting or dividing two numbers. Operands in this task are represented in decimal or word notation.",
        "Finally, in our discussion, we conceptually stretch the notion of inductive bias. The idea of inductive bias is usually associated with specific model types McCoy et al. (2020); Kharitonov and Chaabouni (2021), architectures Xu et al. (2021); Brutzkus and Globerson (2021) and regularization approaches Helmbold and Long (2015). We believe that extending this to refer to learning tasks with pretrained LMs is both reasonable and useful. \n\n#### Inductive bias is performance gain of pretrained model in different linguistic structure.",
        "In this paper, we explore whether pretraining on text is inherently about learning language, or if pretraining also imbues LMs with skills for symbolic manipulation and non-linguistic reasoning (for example, performing quantitative computation such as finding the median of a set of numbers, recognizing regular expressions, or identifying whether a string is a palindrome, as shown in Figure 1). In other words, we investigate whether and how pretraining develops helpful inductive biases for non-linguistic reasoning. For this analysis, we create a set of 19 tasks from three categories of task paradigms: quantitative computation (§3.1), recognizing regular expressions (§3.2), and string reasoning (§3.3). Figure 1 shows an example for each category, and the full list of tasks is described in the table 1. We experiment with transformer and RNN based LMs (§4) for learning these tasks, and perform a comparative analysis with (non-pretrained) neural model variants from the perspective of learning metrics such as accuracy and sample efficiency.\n\n#### The motivation of this paper is analyzing whether pretraining on text is inherently about learning language or if pretraining inject non-linguisitc reasoning to LMs.",
        "Next, we describe the LMs and their variants used in NILM. We experiment with four language models, based on both Transformer and RNN architectures. BERT small.This is the bert-base-uncased model with 12 transformer encoder layers and the dimension of the representations is 768. BERT tokenizer is based on the WordPiece model Wu et al. (2016). BERT large.This is the bert-large-uncased model which has 24 transformer encoders and representations have 1024 dimensions. DeBERTa.This is a transformer based language model and its tokenizer is built using Byte Pair Encoding Sennrich et al. (2016). We consider the DeBERTa base model. It has 12 transformer encoder layers and representations have 768 dimensions. ELMO.This is an LSTM based language model Peters et al. (2018).It has 3 layers and the output representations have 1024 dimensions. \n\n#### ELMO is LSTM based language model, but BERT and DeBERTa is transformer based language model.",
        "As previously mentioned, a possible explanation for the underperformance of non-pretrained models ise that the large number of parameters of the architecture relative to the sizes of the training data might be leading to under-fitting. To test this, we experiment with smaller Transformer-based models with varying numbers of parameters.\n\n#### Author said that underperformance of non-pretrained models comes from small data because if the model parameter size is too large compare to the data size, model training can be suffured under-fitting.",
        "Finally, we investigate the role that pretraining data plays in influencing task performance on non-linguistic tasks (§7). We experiment with pretraining on different domains of text, pretraining on perturbed representations of natural language text (such as shuffled word order), pretraining on text of computer programs (no linguistic properties of natural languages), pretraining on multi-lingual and non-English text, and pretraining with synthetic text (data sampled from synthetic distributions). Our analysis reveals that the advantages of pretraining surprisingly persist with various degrees across these variations, suggesting hithertho unexplored connections between pretraining and the learning abilities of language models. Our contributions are:\n\n#### They did Non-english and computer languages test to shows that the benefits of from pretraining have little to do with the format of the tasks. Therefore, objective of this section is to show that advantage of pretraining persist with various degrees.",
        "Finally, we investigate the role that pretraining data plays in influencing task performance on non-linguistic tasks (§7). We experiment with pretraining on different domains of text, pretraining on perturbed representations of natural language text (such as shuffled word order), pretraining on text of computer programs (no linguistic properties of natural languages), pretraining on multi-lingual and non-English text, and pretraining with synthetic text (data sampled from synthetic distributions). Our analysis reveals that the advantages of pretraining surprisingly persist with various degrees across these variations, suggesting hithertho unexplored connections between pretraining and the learning abilities of language models. Our contributions are:\n\n#### Author said  “Our observation that is behavior is seen even when pretraining on synthetically generated languages” since they showed that the benefits of pretraining persist with various degrees in non-linguistic tasks.",
        "Recognizing regular expressions: Figure 4 shows the comparative performance of pretrained LMs on non-pretrained models on the two tasks involving recognizing regular expressions. For both tasks, we note that the pretrained LMs can perfectly learn the tasks with many fewer labeled examples compared to the non-pretrained models. In both cases, the non-pretrained Transformer-based models eventually reach optimal performance as well. However, curiously the ELMO based non-pretrained models struggle with learning both tasks.\n\n#### pretrained LMs can perfectly learn the tasks with many fewer labeled examples, compared to the non-pretrained models in both tasks.",
        "Training a task-oriented conversational agent from a dialogue corpus can be naturally formulated as ofﬂine reinforcement learning (RL) problem (Levine et al., 2020; Fujimoto et al., 2019; Jaques et al., 2020), which offers the prospect to optimize the policy solely from the ﬁxed dataset without online environment interaction. Most of the existing ofﬂine RL methods are built on the off-policy Actor- Critic framework, which performs iterative optimization of the policy (i.e. actor) and the action- value function (i.e. critic) (Fujimoto et al., 2019; Janner et al., 2019; Kumar et al., 2020). Yet, a naive application of these ofﬂine RL methods generally results in poor dialogue strategies which generate responses in no way similar to human language (Lewis et al., 2017; Zhao et al., 2019; Jang et al., 2020).\n\n#### Most of the algorithms based on the policy gradient such as actor-critic are not straightforwardly applicable to the task-oriented dialogue domain",
        "We also conduct human evaluation on Amazon Mechanical Turk (AMT) to assess the quality of gen- erated responses of GPT-Critic and baseline algorithms, using the evaluation protocol as in (Yang et al., 2021; Lin et al., 2020; Zhang et al., 2020). Speciﬁcally, human workers on AMT were asked to read the context and generated response by interactive simulation via ConvLab, then score the following two evaluation metrics on a Likert scale (1-5): 1) Appropriateness : evaluates whether the generated responses are appropriate for the given context, 2) Fluency : evaluates whether the gen- erated responses are comprehensible and human-like. We compare the performance of GPT-Critic with same baselines on ConvLab evaluation. Figure 3 summarizes the overall results of human eval- uation, where 60 workers evaluate the quality of 30 randomly selected dialogues for each algorithm. The results show that GPT-Critic signiﬁcantly outperforms baseline algorithms in appropriateness which is related to task accomplishment. Moreover, the result of ﬂuency shows that GPT-Critic does not hurt the agent’s capability to generate human-like sentences.\n\n#### The authors show it by conducting the human evaluation on Amazon Mechanical Turk (AMT).",
        "We evaluate our algorithm on the MultiWOZ 2.0 dataset, which is one of the representative task- oriented dialogue benchmarks. The MultiWOZ 2.0 is a large-scale multi-domain Wizard-of-Oz dataset, where a tourist (i.e. user) converses with a clerk (i.e. system) at the information center in a touristic city. It consists of 8438/1000/1000 dialogues for training/validation/testing. For end-to-end evaluation on the MultiWOZ 2.0 dataset, we use the following automatic evaluation metrics: 1) In- form : evaluates whether the system provides an appropriate entity, 2) Success : evaluates whether the system answers all the requested information, 3) BLEU : measures the ﬂuency of the generated response (Papineni et al., 2002). We also report the Combined Score as an overall quality measure\n\n#### This work evaluates the performance in terms of task success by using following metrics: 1) In- form : evaluates whether the system provides an appropriate entity, 2) Success : evaluates whether the system answers all the requested information, 3) Book: evaluates how many booked entities satisfy the user constraints, 4) Inform (Precision / Recall / F1): evaluates how many user requests have been informed.",
        "We also conduct human evaluation on Amazon Mechanical Turk (AMT) to assess the quality of gen- erated responses of GPT-Critic and baseline algorithms, using the evaluation protocol as in (Yang et al., 2021; Lin et al., 2020; Zhang et al., 2020). Speciﬁcally, human workers on AMT were asked to read the context and generated response by interactive simulation via ConvLab, then score the following two evaluation metrics on a Likert scale (1-5): 1) Appropriateness : evaluates whether the generated responses are appropriate for the given context, 2) Fluency : evaluates whether the gen- erated responses are comprehensible and human-like. We compare the performance of GPT-Critic with same baselines on ConvLab evaluation. Figure 3 summarizes the overall results of human eval- uation, where 60 workers evaluate the quality of 30 randomly selected dialogues for each algorithm. The results show that GPT-Critic signiﬁcantly outperforms baseline algorithms in appropriateness which is related to task accomplishment. Moreover, the result of ﬂuency shows that GPT-Critic does not hurt the agent’s capability to generate human-like sentences.\n\n#### They evaluated the naturalness of the generated sentences by the fluency metric in the human evaluation.",
        "In this section, we show the experimental results of GPT-critic on both automatic evaluation and human evaluation. First, we evaluate the performances of GPT-Critic on the MultiWOZ 2.0 (Budzianowski et al., 2018) as dataset-based automatic evaluation, compared with baseline methods including ofﬂine RL algorithms. Second, for more realistic evaluation, we conduct a simulator-based evaluation on the ConvLab framework (Zhu et al., 2020). Third, we also conduct the human eval- uation to evaluate the quality of generated responses. Finally, we give a qualitative analysis of our method using generated dialogue examples on the training dataset of MultiWOZ 2.0, which shows how GPT-Critic improves the performance through the behavior cloning of self-generated dialogues. The qualitative analysis with generated dialogue examples can be found in Appendix B.\n\n#### The authors provide experimental results of CRR and Decision Transformer as baselines of offline RL algorithm.",
        "Ofﬂine Reinforcement Learning. There have been extensive studies on ofﬂine RL (Fujimoto et al., 2019; Levine et al., 2020; Kumar et al., 2020; Wang et al., 2020). Most of prior works are built on the off-policy actor-critic framework, and they focus on the overestimation issue by taking the OOD actions (Kumar et al., 2019; Lee et al., 2020; Fujimoto et al., 2019; Jaques et al., 2020; Kumar et al., 2020). However, a naive application of these ofﬂine RL methods suffer from the issue of diverging from human language in the task-oriented dialogues (Lewis et al., 2017; Zhao et al., 2019; Jang et al., 2020). On the other hand, there are a number of recent works on weighted behavior cloning, where a policy is trained by a variant of supervised learning loss (Wang et al., 2020; Peng et al., 2019; Siegel et al., 2020). The weighted behavior cloning approaches ﬁlter out bad actions, then perform behavior cloning on high-quality data. However, in the task-oriented dialogues, simply dropping the unsuccessful dialogues from the corpus is undesirable, since they may contain some task-speciﬁc information that is useful to properly respond to user requests. Our GPT-Critic aims to revise unsuccessful dialogues into successful ones, which is in contrast to the weighted behavior cloning on the ﬁxed training dataset, where the action choice is restricted to the support in the dataset (Wang et al., 2020; Peng et al., 2019; Siegel et al., 2020). More recently, Chen et al. (2021) introduce Decision Transformer, a Transformer-based architecture that casts the problem of RL as conditional sequence modeling. These ofﬂine RL methods based on behavior cloning are directly applied to the task-oriented dialogues without aforementioned issue, but their results are similar to that of behavior cloning in the task-oriented dialogues.\n\n#### CRR is a variant of weighted behavior cloning approaches that perform behavior cloning with a learned weight on a fixed dataset. In contrast to the CRR, where the action choice is restricted to the support in the given dataset, the proposed algorithm can effectively improve the policy by revising unsuccessful dialogues into successful ones.",
        "Table 3 summarizes the overall performance of GPT-Critic and baseline algorithms in end-to-end response generation setting, where the generated dialogue state and generated dialogue act are used for the DB search and response generation. The results show that GPT-Critic achieved the best performance in terms of inform rate, success rate, and combined score. Moreover, the performance of GPT-Critic on the BLEU score matches those of other pre-trained LM-based methods, since GPT-Critic inherits GPT-2’s ability to generate human-like responses through the behavior cloning of responses generated by GPT-2. The results show that GPT-Critic improves the task performance of the agent without the issue of diverging from human language. In addition, as can be shown in Table 3, the naive data augmentation is not effective since it will not change the GPT’s sampling distribution in principle.\n\n#### The authors claim that the proposed algorithm can maintain the GPT-2’s ability to generate human-like responses while improving the task performance. In the experiments, they show that the proposed method improves the task performance without the issue of diverging from human language.",
        "In addition, we also compare with recent ofﬂine RL algorithms that are free from the issue of di- verging from human language: 1) CRR (Wang et al., 2020), a value-ﬁltered regression method that performs weighted behavior cloning of ofﬂine dataset, 2) Decision Transformer (Chen et al., 2021), a Transformer-based architecture that casts the problem of RL as conditional sequence modeling. For a fair comparison, we use the same pre-trained GPT-2 model as a policy network to train the CRR and the Decision Transformer. Moreover, to show that the policy-gradient-based standard RL algorithms suffer from diverging from human language, we also provide examples of responses generated by policy-gradient-based standard RL algorithm in Appendix D.\n\n#### CRR and Decision Transformer are used as offline RL baseline algorithms in the paper.",
        "We consider the task-oriented dialogue system that can be modeled as a partially observable Markov decision process (POMDP) (Williams & Young, 2007) deﬁned by tuple (cid:104) S, A, O, T, Z, R, γ (cid:105) where S is the set of environment states s = (cid:104) g, h (cid:105) (underlying state that consists of the user goal g and dialogue history h ), A is the set of actions a (a sequence of tokens which represents dialogue act and system response ), O is the set of observations o (user utterance), T ( s (cid:48) | s, a ) = Pr( s t +1 = s (cid:48) | s t = s, a t = a ) is the transition function, Z ( o | s (cid:48) , a ) = Pr( o t +1 = o | s t +1 = s (cid:48) , a t = a ) is the observation probability, R ( g, h, a ) is the reward function indicating the utility of executing action a in history h and the user goal g , and γ ∈ (0 , 1) is a discount factor. The history at time step t , h t = { o 0 , a 0 , . . . o t − 1 , a t − 1 , o t } , is a sequence of all previous observations and actions. Since the underlying state s (e.g. user goal) is not directly observable, the agent makes decisions based on the entire observation-action history. The policy π ( a t | h t ) is mapping from history h t to a probability distribution over A . The goal is to ﬁnd an optimal policy π ∗ that maximizes the expected cumulative rewards, i.e. π ∗ = arg max π E π [ (cid:80) ∞ t =0 γ t R ( g, h t , a t )] . The action-value function of policy π is deﬁned as Q π ( h, a ) := E π [ (cid:80) ∞ t =0 γ t R ( g, h t , a t ) | h 0 = h, a 0 = a ] , where Q π is a unique solution of the Bellman equation: Q π ( h, a ) = E g [ R ( g, h, a )] + γ E π [ Q π ( h (cid:48) , a (cid:48) )] .\n\n#### In task-oriented dialogues, the actions are defined as a sequence of tokens which represents dialogue act and system response.",
        "Reinforcement Learning for Task-Oriented Dialogue Systems. Applying the standard RL meth- ods straightforwardly to optimize a task-oriented dialogue agent causes the issue of diverging from human language. To address this problem, interleaving reinforcement learning with supervised learning has been proposed but it is still not free from the issue of diverging from human language (Lewis et al., 2017). Recently, the latent representation models for language actions have been in- troduced to address the aforementioned problem (Zhao et al., 2019; Yarats & Lewis, 2018). They disentangle the semantics of the utterance and the natural language generation, and then perform goal-based training in the space of the latent variables instead of directly optimizing utterances. However, they cannot be directly applied to large-scale pre-trained language models that are not designed in a way that works inherently with discrete latent variables. Jaques et al. (2020) use KL- control to restrict the policy to stay close to its prior policy, but it still suffers from divergence from human language even with carefully chosen hyper-parameters. Furthermore, Jang et al. (2020) adopt Bayes-adaptive Monte-Carlo planning to negotiation dialogue then use it as a policy improvement operator. This approach can prevent the issue of diverging from human language through the policy improvement based on behavior cloning of self-generated dialogues. However, they assume a user model that is difﬁcult enough to be considered another problem.\n\n#### KL control means that the regularization technique to restrict the policy to stay close to its prior policy.",
        "Training a task-oriented dialogue agent can be naturally formulated as ofﬂine rein- forcement learning (RL) problem, where the agent aims to learn a conversational strategy to achieve user goals, only from a dialogue corpus. It is very challenging in terms of RL since the natural language action space is astronomical, while feasi- ble (syntactically and semantically correct) actions are very sparse. Thus, standard RL methods easily fail and generate responses diverging from human language, even when ﬁne-tuning a powerful pre-trained language model. In this paper, we introduce GPT-Critic, an ofﬂine RL method for task-oriented dialogue. GPT-Critic is built upon GPT-2, ﬁne-tuning the language model through behavior cloning of the critic-guided self-generated sentences. GPT-Critic is essentially free from the issue of diverging from human language since it learns from the sentences sam- pled from the pre-trained language model. In the experiments, we demonstrate that our algorithm outperforms the state-of-the-art in the task-oriented dialogue benchmarks including MultiWOZ 2.0 and ConvLab.\n\n#### Offline RL is one of the reinforcement learning settings that assumes the agent aims to optimize the policy solely from the ﬁxed dataset without online environment interaction.",
        "where ¯ φ is the parameters of the target network. As discussed in the prior work (Fujimoto et al., 2019; Kumar et al., 2020), optimizing this loss can be challenging in the ofﬂine RL setting due to the overestimation issue in the bootstrapping process by taking out-of-distribution (OOD) actions to evaluate the value of the next state.\n\n#### The overestimation issue means the problem when the action values are overestimated by using out-of-distribution actions in RL.",
        "In addition, we also compare with recent ofﬂine RL algorithms that are free from the issue of di- verging from human language: 1) CRR (Wang et al., 2020), a value-ﬁltered regression method that performs weighted behavior cloning of ofﬂine dataset, 2) Decision Transformer (Chen et al., 2021), a Transformer-based architecture that casts the problem of RL as conditional sequence modeling. For a fair comparison, we use the same pre-trained GPT-2 model as a policy network to train the CRR and the Decision Transformer. Moreover, to show that the policy-gradient-based standard RL algorithms suffer from diverging from human language, we also provide examples of responses generated by policy-gradient-based standard RL algorithm in Appendix D.\n\n#### CRR and Decision Transformer are the examples of offline RL algorithms that are applicable to the task-oriented dialogue domain without diverging from human language.",
        "Training a task-oriented dialogue agent can be naturally formulated as ofﬂine rein- forcement learning (RL) problem, where the agent aims to learn a conversational strategy to achieve user goals, only from a dialogue corpus. It is very challenging in terms of RL since the natural language action space is astronomical, while feasi- ble (syntactically and semantically correct) actions are very sparse. Thus, standard RL methods easily fail and generate responses diverging from human language, even when ﬁne-tuning a powerful pre-trained language model. In this paper, we introduce GPT-Critic, an ofﬂine RL method for task-oriented dialogue. GPT-Critic is built upon GPT-2, ﬁne-tuning the language model through behavior cloning of the critic-guided self-generated sentences. GPT-Critic is essentially free from the issue of diverging from human language since it learns from the sentences sam- pled from the pre-trained language model. In the experiments, we demonstrate that our algorithm outperforms the state-of-the-art in the task-oriented dialogue benchmarks including MultiWOZ 2.0 and ConvLab.\n\n#### In task-oriented dialogue, the action space is combinatorially large and a naive application of RL algorithms suffer from the issue of diverging from human language.",
        "In this section, we show the experimental results of GPT-critic on both automatic evaluation and human evaluation. First, we evaluate the performances of GPT-Critic on the MultiWOZ 2.0 (Budzianowski et al., 2018) as dataset-based automatic evaluation, compared with baseline methods including ofﬂine RL algorithms. Second, for more realistic evaluation, we conduct a simulator-based evaluation on the ConvLab framework (Zhu et al., 2020). Third, we also conduct the human eval- uation to evaluate the quality of generated responses. Finally, we give a qualitative analysis of our method using generated dialogue examples on the training dataset of MultiWOZ 2.0, which shows how GPT-Critic improves the performance through the behavior cloning of self-generated dialogues. The qualitative analysis with generated dialogue examples can be found in Appendix B.\n\n#### The main difference is that MultiWOZ banchmark provides dataset-based automatic evaluation and ConvLab framework provides a simulator-based evaluation.",
        "Training a task-oriented dialogue agent can be naturally formulated as ofﬂine rein- forcement learning (RL) problem, where the agent aims to learn a conversational strategy to achieve user goals, only from a dialogue corpus. It is very challenging in terms of RL since the natural language action space is astronomical, while feasi- ble (syntactically and semantically correct) actions are very sparse. Thus, standard RL methods easily fail and generate responses diverging from human language, even when ﬁne-tuning a powerful pre-trained language model. In this paper, we introduce GPT-Critic, an ofﬂine RL method for task-oriented dialogue. GPT-Critic is built upon GPT-2, ﬁne-tuning the language model through behavior cloning of the critic-guided self-generated sentences. GPT-Critic is essentially free from the issue of diverging from human language since it learns from the sentences sam- pled from the pre-trained language model. In the experiments, we demonstrate that our algorithm outperforms the state-of-the-art in the task-oriented dialogue benchmarks including MultiWOZ 2.0 and ConvLab.\n\n#### Since the proposed method updates the policy through behavior cloning of the self-generated human-like responses, it is essentially free from the issue of diverging from human language.",
        "In order to address the prohibitively large language action spaces, we explicitly consider the set of response candidates that are generated from the ﬁne-tuned GPT-2. The GPT-Critic selects the\n\n#### The proposed method consider the set of response candidates that are generated from the ﬁne-tuned GPT-2 as action spaces.",
        "We can theoretically show that the updated policy by the above policy improvement step has a higher value than the old policy. Furthermore, we can also theoretically show that updated policy by the higher number of candidate actions has a higher value than the policy updated by the lower number of candidate actions. We formalize this result in Theorem 1. Theorem 1. (Policy Improvement) Given a policy π and the number of sampling actions N ≥ 1 , If we update the new policy π new N by\n\n#### Yes, they theoretically show it as the policy improvement theorem in the paper.",
        "Training a task-oriented conversational agent from a dialogue corpus can be naturally formulated as ofﬂine reinforcement learning (RL) problem (Levine et al., 2020; Fujimoto et al., 2019; Jaques et al., 2020), which offers the prospect to optimize the policy solely from the ﬁxed dataset without online environment interaction. Most of the existing ofﬂine RL methods are built on the off-policy Actor- Critic framework, which performs iterative optimization of the policy (i.e. actor) and the action- value function (i.e. critic) (Fujimoto et al., 2019; Janner et al., 2019; Kumar et al., 2020). Yet, a naive application of these ofﬂine RL methods generally results in poor dialogue strategies which generate responses in no way similar to human language (Lewis et al., 2017; Zhao et al., 2019; Jang et al., 2020).\n\n#### Since a naive application of existing offline RL algorithms suffer from the issue of diverging from human language, it is not straightforward to apply them to the task-oriented dialogue.",
        "performance in all metrics related to task accomplishment. However, they also show that GPT-Critic takes longer dialogue turn for the task accomplishment because GPT-Critic is trained by maximizing the success rate without considering the dialogue turn.\n\n#### Since a proposed method is trained by maximizing the success rate without considering the dialogue turn, the proposed algorithm does not outperforms in turn metric in the results.",
        "In this section, we show the experimental results of GPT-critic on both automatic evaluation and human evaluation. First, we evaluate the performances of GPT-Critic on the MultiWOZ 2.0 (Budzianowski et al., 2018) as dataset-based automatic evaluation, compared with baseline methods including ofﬂine RL algorithms. Second, for more realistic evaluation, we conduct a simulator-based evaluation on the ConvLab framework (Zhu et al., 2020). Third, we also conduct the human eval- uation to evaluate the quality of generated responses. Finally, we give a qualitative analysis of our method using generated dialogue examples on the training dataset of MultiWOZ 2.0, which shows how GPT-Critic improves the performance through the behavior cloning of self-generated dialogues. The qualitative analysis with generated dialogue examples can be found in Appendix B.\n\n#### The author want to show that the proposed method does not suffer from the issue of diverging from human language.",
        "In order to understand the effectiveness of MC-LAVE as a policy improvement operator, we compare the performances of PUCT-RL and MC-LAVE-RL in Z ORK 1. Table 2 reports the intermediate results of planning and supervised learning in each iteration of the policy iteration. In each iteration, the policy and the Q-function are trained using planning trajectories and experience replay collected from 25 independent planning agents. As can be seen in Table 2, the performance of MC-LAVE-RL is improved more consistently than PUCT-RL, both in planning and learning. At the beginning of the policy iteration, PUCT-RL improves the performance, but it fails to overcome bottleneck and converges to a suboptimal policy: PUCT utilizes the prior policy learned by imitating the planning results of the previous iteration to estimate the exploration bonus, but this uncertainty-based method is not much effective to encourage the agent to explore the action space that is not sufﬁciently covered. On the other hand, MC-LAVE-RL not only uses the prior policy, but also uses Q-Network for credit assignment to language actions. This allows a more focused exploration on semantically promising actions and consequently overcomes the bottleneck to further improve the performance.\n\n#### The results denoted by planning report the performance of planning through the simulation, and the results denoted by learning report the performance without further simulation.",
        "First, we compare the performance of MC-LAVE-RL with the following algorithms: (1) DRRN (Hausknecht et al., 2020), a variant of the DQN algorithm (Mnih et al., 2013) for natural lan- guage action space, (2) TDQN (Hausknecht et al., 2020), an extension of LSTM-DQN algorithm (Narasimhan et al., 2015) incorporating with template-based action generation, (3) KG-A2C (Am- manabrolu & Hausknecht, 2020), an actor-critic method with knowledge graph state representation, (4) MC!Q*BERT (Ammanabrolu et al., 2020), an extension of KG-A2C with BERT-based knowl- edge graph construction and knowledge-graph-based intrinsic reward. In addition, we also compare MC-LAVE-RL with our baseline called PUCT-RL, which uses PUCT as a policy improvement op- erator.\n\n#### The authors compare the proposed method with state-of-the-art RL algorithm MC!Q*BERT on Jericho environment.",
        "First, we compare the performance of MC-LAVE-RL with the following algorithms: (1) DRRN (Hausknecht et al., 2020), a variant of the DQN algorithm (Mnih et al., 2013) for natural lan- guage action space, (2) TDQN (Hausknecht et al., 2020), an extension of LSTM-DQN algorithm (Narasimhan et al., 2015) incorporating with template-based action generation, (3) KG-A2C (Am- manabrolu & Hausknecht, 2020), an actor-critic method with knowledge graph state representation, (4) MC!Q*BERT (Ammanabrolu et al., 2020), an extension of KG-A2C with BERT-based knowl- edge graph construction and knowledge-graph-based intrinsic reward. In addition, we also compare MC-LAVE-RL with our baseline called PUCT-RL, which uses PUCT as a policy improvement op- erator.\n\n#### PUCT-RL is a planning-based RL algorithm.",
        "Table 1 summarizes handicaps leveraged in each algorithm and the performance of MC-LAVE-RL and baseline algorithms across 9 IF games included in the Jericho environment. The results show that MC-LAVE-RL outperforms or matches the state-of-the-art results on 8 out of 9 games. Although MC-LAVE-RL requires more handicap or assumption, it performs the same or better than strong baseline MC!Q*BERT which requires similar assumptions and more requirements. In addition, MC-LAVE-RL achieves higher game scores on overall games compared to PUCT-RL, which is a baseline algorithm that only excludes language-driven exploration strategy from MC-LAVE-RL. Furthermore, MC-LAVE-RL performs signiﬁcantly better than other methods on difﬁcult games such as Z ORK 1, D EEPHOME , and L UDICORP , which are categorized by Hausknecht et al. (2020) as a relatively challenging game due to the large action space and sparse rewards.\n\n#### MC!Q*BERT and PUCT-RL require the resettable simulator assumption.",
        "Training details We train our model on the training set of the ILSVRC-2012 ImageNet-1k dataset [18] without using class labels. We use the same data augmentation scheme (color jittering, Gaussian blur, and solarization) and multi-crop strategy (two 224 × 224 and six 96 × 96) used in Caron et al. [9]. We use a batch size of 4096 and employ the LARS optimizer [52] with a weight decay of 10−6. We use linearly scaled learning rate of lr × batch size/256 [27] with a base learning rate of 0.3. 5 We adjust the learning rate with 10 epochs of a linear warmup followed by cosine scheduling. We also use an exponential moving average (EMA) network by default.\n\n#### This is as it is. We mostly follow the practice of Caron et al.",
        "For many-shot recognition, we adopt the benchmark suite proposed in the transfer learning study [28], which includes the target datasets FGVC Aircraft [38], Caltech-101 [15], Stanford Cars [29], CIFAR10 [30], CIFAR-100 [30], DTD [9], Oxford 102 Flowers [41], Food-101 [3], Oxford-IIIT Pets [43], SUN397 [59], and Pascal VOC2007 [14]. These datasets cover a wide range of classification tasks, including texture, scene and fine/coarse-grained object classification. While they are all in the ‘many-shot’ regime, they include significant variety in amount of training data (2,000-75,000 images), and cardinality of classification (10-397 classes).\n\n#### A variety of range of classification tasks, including texture, scene",
        "There has been a growing interest in using a large-scale dataset to build powerful machine learning models Radford et al. (2021).Self-supervised learning (SSL), which aims to learn a useful representation without labels, is suitable for this trend; it is actively studied in the fields of natural language processing Devlin et al. (2019); Du et al. (2021) and computer vision Chen et al. (2020a); He et al. (2020).In the vision domain, recent SSL methods commonly use data augmentations and induce their visual representation to be augmentation-invariant.They have achieved state-of-the-art performance surpassing supervised representation in a variety of visual tasks, including semi-supervised learning Caron et al. (2020); Zbontar et al. (2021), transfer learning Ericsson et al. (2021), and object detection Chen et al. (2020c).\n\n#### Curernt trend of self-supervised learning methods employ a large-scale dataset. We care about batch size since this corresponds to speed of the method.",
        "There has been a growing interest in using a large-scale dataset to build powerful machine learning models Radford et al. (2021).Self-supervised learning (SSL), which aims to learn a useful representation without labels, is suitable for this trend; it is actively studied in the fields of natural language processing Devlin et al. (2019); Du et al. (2021) and computer vision Chen et al. (2020a); He et al. (2020).In the vision domain, recent SSL methods commonly use data augmentations and induce their visual representation to be augmentation-invariant.They have achieved state-of-the-art performance surpassing supervised representation in a variety of visual tasks, including semi-supervised learning Caron et al. (2020); Zbontar et al. (2021), transfer learning Ericsson et al. (2021), and object detection Chen et al. (2020c).\n\n#### SSL methods learn useful representation by solving pretext tasks without labels. In P7, we can get a hint that this benchmarks are testbed for evaluating SSL methods.",
        "We first prove the strict convexity of the optimization function f : R Lemma 1. For x ∈ R N×1+ , s(x) = P Ni xi log xiis a strictly convex function of x. Proof. Since the Hessian of s is a diagonal matrix with positive elements ∇2xs(x)i,i = 1/xi, s is astrictly convex function.\n\n#### We prove that hessian is a positive definite matrix.",
        "The MI term in Eq. 4 takes a minimum value when collapsing happens.MIRA naturally avoids collapsed solution via penalizing assignment that exhibits low MI.Specifically, unless starting from the collapsed state, MIRA finds MI-maximizing points around the model prediction; it will not choose collapsed pseudo-labels.Hence, the iterative training to predict such labels will not collapse whenever the prediction of pseudo-labels is achievable.Our empirical results verify that MIRA does not require extra training techniques or artificial constraints to address collapsing.\n\n#### Mutual information regularizer unfavors collapsed representation.",
        "Meanwhile, a line of work uses clustering for un-/self-supervised representation learning.They explicitly assign pseudo-labels to embedded representation via clustering, and the model is thereby trained to predict such labels.These clustering-based methods can account for inter-data similarity; representations are encouraged to encode the semantic structure of data.Prior works Yang et al. (2016); Xie et al. (2016); Bautista et al. (2016); Hu et al. (2017) have shown encouraging results in small-scaled settings; Caron et al. (2018) show that it can also be applied to the large-scaled dataset or even to a non-curated dataset Caron et al. (2019).Recently, several works Asano et al. (2020); Caron et al. (2020); Li et al. (2021) have adopted the philosophy of augmentation invariance and achieved strong empirical results.They typically assign pseudo-labels using augmented views while predicting the labels by looking at other differently augmented views.\n\n#### Clustering methods encourage the representations to encode the semantic structures of the data. While this can be prone to collapse, they rely on extra techniques.",
        "A.7 Experiments on the detection and segmentation task We test our method on detection segmentation of the COCO 2017 dataset with Masked R-CNN, R50-C4 on a 2x scheduled setting. We use the configuration from the MoCo official implementation. MIRA performs better than the supervised baseline and is comparable to MoCo; it is not as dominating as in the classification tasks.\n\n#### MIRA does not perform well in the detection task.",
        "The pseudo-code of MIRA for representation learning with Eq. 8 is provided in the Appendix.In the following experiments, we verify the effectiveness of MIRA for a representation learning purpose.We note that MIRA can integrate recently suggested self-supervised learning components, such as exponential moving average (EMA) or multi-crop (MC) augmentation strategy following the baselines Chen et al. (2021); Caron et al. (2020, 2021).For convenience, in the rest of this paper, we call the representation learning with MIRA also as MIRA.We discuss some further details as follows:\n\n#### MIRA does not require any artificial constraints or techniques in training, unlike other self-supervised methods. However, MIRA uses some of the techniques used in the other paper.",
        "Despite its conceptual simplicity, a naive application of clustering to representation learning is hard to achieve, especially when training with large-scale datasets.This is because clustering-based methods are prone to collapse, i.e., all samples are assigned to a single cluster; hence, recent methods heavily rely on extra training techniques or artificial constraints, such as pre-training Yan et al. (2020), sampling strategy Caron et al. (2018), equipartition constraints Asano et al. (2020); Caron et al. (2020), to avoid collapsing.However, it is unclear if these additions are appropriate or how such components will affect the representation quality.\n\n#### It’s conceptually simple",
        "We argue that such pseudo-labels should maximize the mutual information (MI) between themselves and data while accounting for the model probabilities \\bm{P}.Let \\mathcal{B}\\in\\{1,...,B\\} and \\mathcal{Y}_{\\bm{W}}\\in\\{1,...,K\\} be the random variables associated with the data index in mini-batch and labels by probability distributions \\bm{W}=\\{\\bm{w}_{i}\\}_{i=1}^{B}, respectively.Our online pseudo-label (cluster) assignment is determined by solving the following optimization problem:\\displaystyle\\bm{W^{*}}\\displaystyle=\\operatorname*{arg\\,min}_{\\bm{W}\\subset\\Delta_{K}}\\frac{1}{B}\\sum_{i=1}^{B}D_{\\text{KL}}(\\bm{w}_{i},\\bm{p}_{i})-\\beta\\hat{I}(\\mathcal{Y}_{\\bm{W}};\\mathcal{B}),(1)where \\Delta_{K}\\coloneqq\\{\\bm{w}\\in\\mathbb{R}^{K}_{+}\\mid\\bm{w}^{\\intercal}\\bm{1}_{K}=1\\}, \\hat{I} indicates an empirical (Monte Carlo) estimates of MI, and \\beta is a trade-off parameter.The problem consists of the (1) KL divergence term that makes pseudo-labels to be based on the model probability \\bm{p} and (2) MI term between the pseudo-labels and data to induce more information about data into the pseudo-labels.By combining these two terms, we provide a refined pseudo-label that take account of both the model probability and MI.\n\n#### Mutual information between pseudo-label and data without any artificial constraints.",
        "SeLa Asano et al. (2020) and SwAV Caron et al. (2020) formulate their pseudo-labeling process into optimization problems, i.e., optimal transport (OT) problem, and solve it iteratively with Sinkhorn-Knopp (SK) algorithm Cuturi (2013).To avoid collapse and apply the SK algorithm, they assume the equipartition of data into clusters.Mathematically, the difference to MIRA is in how to deal with the marginal entropy.SeLa and SwAV constrain the marginal entropy to maximum value–equipartition while MIRA decides it by MI regularization333Adding the equipartition constraint into Eq. 4, our problem converts to the OT problem of SwAV Caron et al. (2020)..Asano et al. (2020) argue that their pseudo-labels with the OT problem maximize the MI between labels and data indices under the equipartition constraint.However, it more resembles assuming MI maximization and then finding the cluster assignments that are optimal transport to the model prediction.In contrast, MIRA directly maximizes the MI by regularization without artificial constraints.While SwAV performs better than SeLa in most self-supervised benchmarks, we verify that MIRA improves over SwAV in various downstream tasks.\n\n#### Adding equipartition constraint to the objective induces the optimal transport method used in SwaV\n\ncomposition: False",
        "The pseudo-code of MIRA for representation learning with Eq. 8 is provided in the Appendix.In the following experiments, we verify the effectiveness of MIRA for a representation learning purpose.We note that MIRA can integrate recently suggested self-supervised learning components, such as exponential moving average (EMA) or multi-crop (MC) augmentation strategy following the baselines Chen et al. (2021); Caron et al. (2020, 2021).For convenience, in the rest of this paper, we call the representation learning with MIRA also as MIRA.We discuss some further details as follows:\n\n#### We may check on the reffered paper.",
        "In this paper, we propose Mutual Information Regularized Assignment (MIRA), a pseudo-labeling algorithm that enables clustering-based SSL without any artificial constraints or extra training techniques.MIRA is designed to follow the infomax principle Linsker (1988) and the intuition that good labels are something that can reduce most of the uncertainty about the data.Our method assigns a pseudo-label in a principled way by constructing an optimization problem.For a given training model that predicts pseudo-labels, the optimization problem finds a solution that maximizes the mutual information (MI) between the pseudo-labels and data while considering the model probability.We formulate the problem as a convex optimization problem and derive the necessary and sufficient condition of solution with the Karush-Kuhn-Tucker (KKT) condition.This solution can be achieved by fixed-point iteration that we prove the convergence.We remark that MIRA does not require any form of extra training techniques or artificial constraints, e.g., equipartition constraints.\n\n#### TWIST's direct optimization of MI through model parameters leads to the suboptimal solution while MIRA optimizes MI between pseudo-label and data without updating model parameters.",
        "There has been a growing interest in using a large-scale dataset to build powerful machine learning models Radford et al. (2021).Self-supervised learning (SSL), which aims to learn a useful representation without labels, is suitable for this trend; it is actively studied in the fields of natural language processing Devlin et al. (2019); Du et al. (2021) and computer vision Chen et al. (2020a); He et al. (2020).In the vision domain, recent SSL methods commonly use data augmentations and induce their visual representation to be augmentation-invariant.They have achieved state-of-the-art performance surpassing supervised representation in a variety of visual tasks, including semi-supervised learning Caron et al. (2020); Zbontar et al. (2021), transfer learning Ericsson et al. (2021), and object detection Chen et al. (2020c).\n\n#### Self-supervised learning methods perform well in semi-supervised learning, transfer learning, and object detection.",
        "Information maximization is a principal approach to learn representation and to avoid collapse.DeepInfoMax Hjelm et al. (2019) propose the MI maximization between the local and global views for representation learning; the existence of negative pairs prevents training toward the trivial solution.BarlowTwins Zbontar et al. (2021) and W-MSE Ermolov et al. (2021) address the collapsing with redundancy reduction that indirectly maximizes the content information of embedding vectors.Among clustering-based approaches, IIC Ji et al. (2019) maximizes the MI between the embedding codes to enable representation learning;similar to ours, TWIST Feng et al. (2021) proposes combining the MI between the data and class prediction as a negative loss term with an augmentation invariance consistency loss.Both IIC and TWIST use the MI as a loss function and directly optimize their model parameters with gradient descent of the loss.However, the direct optimization of MI terms by updating model parameters often leads to a sub-optimal solution Feng et al. (2021); TWIST copes with this issue by appending the normalization layer before softmax and introducing an additional self-labeling stage.In contrast, MIRA addresses the difficulty of MI maximization in a principled way via explicit optimization.\n\n#### The direct optimization constraint used in TWIST can lead to sub-optimal solution",
        "Meanwhile, a line of work uses clustering for un-/self-supervised representation learning.They explicitly assign pseudo-labels to embedded representation via clustering, and the model is thereby trained to predict such labels.These clustering-based methods can account for inter-data similarity; representations are encouraged to encode the semantic structure of data.Prior works Yang et al. (2016); Xie et al. (2016); Bautista et al. (2016); Hu et al. (2017) have shown encouraging results in small-scaled settings; Caron et al. (2018) show that it can also be applied to the large-scaled dataset or even to a non-curated dataset Caron et al. (2019).Recently, several works Asano et al. (2020); Caron et al. (2020); Li et al. (2021) have adopted the philosophy of augmentation invariance and achieved strong empirical results.They typically assign pseudo-labels using augmented views while predicting the labels by looking at other differently augmented views.\n\n#### Clustering-based methods relies on pseudo-labels on representation learning. Therefore, our testbed is focused on classification-based benchmark. Object detection is not our main interest.",
        "Our contributions are summarized as follows:•We propose MIRA, a simple and principled pseudo-label assignment algorithm based on mutual information.Our method does not require extra training techniques or artificial constraints.•We apply MIRA to clustering-based representation learning, showing comparable performance against the state-of-the-art methods with half of the training epochs.Specifically, MIRA achieves 75.6% top-1 accuracy on ImageNet linear evaluation with only 400 epochs of training and the best performance in 9 out of 11 datasets in transfer learning.•Representation by MIRA also consistently improves over other information-based SSL methods.Especially our method without multi-crop augmentation achieves 74.1% top-1 accuracy and outperforms BarlowTwins Zbontar et al. (2021), a baseline information maximization-based self-supervised method.\n\n#### Our method show better result in only half of the training.",
        "The General Language Understanding Evaluation (GLUE) benchmark Wang et al. (2019b) is a collection of 9 datasets for evaluating natural language understanding systems.666The datasets are: CoLA Warstadt et al. (2018), Stanford Sentiment Treebank (SST) Socher et al. (2013), Microsoft Research Paragraph Corpus (MRPC) Dolan and Brockett (2005), Semantic Textual Similarity Benchmark (STS) Agirre et al. (2007), Quora Question Pairs (QQP) Iyer et al. (2016), Multi-Genre NLI (MNLI) Williams et al. (2018), Question NLI (QNLI) Rajpurkar et al. (2016), Recognizing Textual Entailment (RTE) Dagan et al. (2006); Bar-Haim et al. (2006); Giampiccolo et al. (2007); Bentivogli et al. (2009) and Winograd NLI (WNLI) Levesque et al. (2011).Tasks are framed as either single-sentence classification or sentence-pair classification tasks.The GLUE organizers provide training and development data splits as well as a submission server and leaderboard that allows participants to evaluate and compare their systems on private held-out test data.\n\n#### GLUE is the benchmark dataset for BERT.",
        "QNLI:Recent submissions on the GLUE leaderboard adopt a pairwise ranking formulation for the QNLI task, in which candidate answers are mined from the training set and compared to one another, and a single (question, candidate) pair is classified as positive Liu et al. (2019b, a); Yang et al. (2019).This formulation significantly simplifies the task, but is not directly comparable to BERT Devlin et al. (2019).Following recent work, we adopt the ranking approach for our test submission, but for direct comparison with BERT we report development set results based on a pure classification approach.\n\n#### Yes, both QNLI and WNLI are part of GLUE.",
        "The ReAding Comprehension from Examinations (RACE) Lai et al. (2017) task is a large-scale reading comprehension dataset with more than 28,000 passages and nearly 100,000 questions. The dataset is collected from English examinations in China, which are designed for middle and high school students. In RACE, each passage is associated with multiple questions. For every question, the task is to select one correct answer from four options. RACE has significantly longer context than other popular reading comprehension datasets and the proportion of questionsthat requires reasoning is very large.\n\n#### RACE is the task of classifying one correct answer from 4 options.",
        "To help disentangle the importance of these factors from other modeling choices (e.g., the pretraining objective), we begin by training RoBERTa following the BERT{}_{\\textsc{large}} architecture (L=24, H=1024, A=16, 355M parameters).We pretrain for 100K steps over a comparable BookCorpus plus Wikipedia dataset as was used in Devlin et al. (2019).We pretrain our model using 1024 V100 GPUs for approximately one day.\n\n#### RoBERTa is based on BERT-large.",
        "In the original BERT pretraining procedure, the model observes two concatenated document segments, which are either sampled contiguously from the same document (with p=0.5) or from distinct documents.In addition to the masked language modeling objective, the model is trained to predict whether the observed document segments come from the same or distinct documents via an auxiliary Next Sentence Prediction (NSP) loss.\n\n#### NSP helps to improve the ability of distinguishing  the observed document segments come from the same or distinct documents in BERT.",
        "We consider five English-language corpora of varying sizes and domains, totaling over 160GB of uncompressed text. We use the following text corpora:•BookCorpus Zhu et al. (2015) plus English Wikipedia. This is the original data used to train BERT. (16GB).•CC-News, which we collected from the English portion of the CommonCrawl News dataset Nagel (2016). The data contains 63 million English news articles crawled between September 2016 and February 2019. (76GB after filtering).444We use news-please Hamborg et al. (2017) to collect and extract CC-News. CC-News is similar to the RealNews dataset described in Zellers et al. (2019).•OpenWebText Gokaslan and Cohen (2019), an open-source recreation of the WebText corpus described in Radford et al. (2019). The text is web content extracted from URLs shared on Reddit with at least three upvotes. (38GB).555The authors and their affiliated institutions are not in any way affiliated with the creation of the OpenWebText dataset.•Stories, a dataset introduced in Trinh and Le (2018) containing a subset of CommonCrawl data filtered to match the story-like style of Winograd schemas. (31GB).\n\n#### CC-News and OpenWebText are BERT-style english corpora.",
        "The NSP loss was hypothesized to be an important factor in training the original BERT model. Devlin et al. (2019) observe that removing NSP hurts performance, with significant performance degradation on QNLI, MNLI, and SQuAD 1.1.However, some recent work has questioned the necessity of the NSP loss Lample and Conneau (2019); Yang et al. (2019); Joshi et al. (2019).\n\n#### In BERT paper, author said that removing NSP can hurt the performance of the model. However, in RoBERTa paper, author said that removing NSP improves downstream task performance. Therefore, point of views in terms of NSP is different between BERT and RoBERTa.",
        "BERT takes as input a concatenation of two segments (sequences of tokens), x_{1},\\ldots,x_{N} and y_{1},\\ldots,y_{M}.Segments usually consist of more than one natural sentence.The two segments are presented as a single input sequence to BERT with special tokens delimiting them: [\\mathit{CLS}],x_{1},\\ldots,x_{N},[\\mathit{SEP}],y_{1},\\ldots,y_{M},[\\mathit{EOS}].M and N are constrained such that M+N<T, where T is a parameter that controls the maximum sequence length during training.\n\n#### It is not true. BERT takes concatenated two sequences as input like [\\mathit{CLS}],x_{1},\\ldots,x_{N},[\\mathit{SEP}],y_{1},\\ldots,y_{M}, They calculate N+M to control maximum sequence length. However, RoBERTa takes four sequences as input not like BERT.",
        "BERT takes as input a concatenation of two segments (sequences of tokens), x_{1},\\ldots,x_{N} and y_{1},\\ldots,y_{M}.Segments usually consist of more than one natural sentence.The two segments are presented as a single input sequence to BERT with special tokens delimiting them: [\\mathit{CLS}],x_{1},\\ldots,x_{N},[\\mathit{SEP}],y_{1},\\ldots,y_{M},[\\mathit{EOS}].M and N are constrained such that M+N<T, where T is a parameter that controls the maximum sequence length during training.\n\n#### It is not true. BERT takes concatenated two sequences as input like [\\mathit{CLS}],x_{1},\\ldots,x_{N},[\\mathit{SEP}],y_{1},\\ldots,y_{M}, They calculate N+M to control maximum sequence length. However, RoBERTa takes four sequences as input not like BERT.",
        "A random sample of the tokens in the input sequence is selected and replaced with the special token [\\mathit{MASK}]. The MLM objective is a cross-entropy loss on predicting the masked tokens. BERT uniformly selects 15% of the input tokens for possible replacement. Of the selected tokens, 80% are replaced with [\\mathit{MASK}], 10% are left unchanged, and 10% are replaced by a randomly selected vocabulary token.\n\n#### 80% of tokens are replaced with [MASK] during training.",
        "Devlin et al. (2019) originally trained BERT{}_{\\textsc{base}} for 1M steps with a batch size of 256 sequences.This is equivalent in computational cost, via gradient accumulation, to training for 125K steps with a batch size of 2K sequences, or for 31K steps with a batch size of 8K.\n\n#### RoBERTa use 32 times larger batch size than BERT because batch size of BERT and RoBERTa are 256 and 8K, respectively.",
        "As discussed in Section 2, BERT relies on randomly masking and predicting tokens.The original BERT implementation performed masking once during data preprocessing, resulting in a single static mask.To avoid using the same mask for each training instance in every epoch, training data was duplicated 10 times so that each sequence is masked in 10 different ways over the 40 epochs of training.Thus, each training sequence was seen with the same mask four times during training.\n\n#### They use dynamic masking to avoid using the same mask in iteration.",
        "In summary, the contributions of this paper are: (1) We present a set of important BERT design choices and training strategies and introduce alternatives that lead to better downstream task performance; (2) We use a novel dataset, CC-News, and confirm that using more data for pretraining further improves performance on downstream tasks; (3) Our training improvements show that masked language model pretraining, under the right design choices, is competitive with all other recently published methods. We release our model, pretraining and fine-tuning code implemented in PyTorch Paszke et al. (2017).\n\n#### Author said that “the data used for pretraining” have been under-emphesized. Because they improved model performance by using additional training data for pretraining.",
        "We adopt a much simpler approach for SQuAD compared to past work.In particular, while both BERT Devlin et al. (2019) and XLNet Yang et al. (2019) augment their training data with additional QA datasets, we only finetune RoBERTa using the provided SQuAD training data.Yang et al. (2019) also employed a custom layer-wise learning rate schedule to finetune XLNet, while we use the same learning rate for all layers.\n\n#### Author said that they adopt a much simpler approach for SQuAD compared to past work to emphasize that they only finetune RoBERTa using the SQuAD training data, and they use the same learning rate for all layers, not like previous works.",
        "We carefully evaluate a number of design decisions when pretraining BERT models.We find that performance can be substantially improved by training the model longer, with bigger batches over more data; removing the next sentence prediction objective; training on longer sequences; and dynamically changing the masking pattern applied to the training data.Our improved pretraining procedure, which we call RoBERTa, achieves state-of-the-art results on GLUE, RACE and SQuAD, without multi-task finetuning for GLUE or additional data for SQuAD.These results illustrate the importance of these previously overlooked design decisions and suggest that BERT’s pretraining objective remains competitive with recently proposed alternatives.\n\n#### They could say that the importance of previously overlooked design decisions on BERT, because they improved the performance significantly by training the model longer, with bigger batches over more data; removing the next sentence prediction objective; training on longer sequences; and dynamically changing the masking pattern applied to the training data.",
        "Self-training methods such as ELMo Peters et al. (2018), GPT Radford et al. (2018), BERT Devlin et al. (2019), XLM Lample and Conneau (2019), and XLNet Yang et al. (2019) have brought significant performance gains, but it can be challenging to determine which aspects of the methods contribute the most. Training is computationally expensive, limiting the amount of tuning that can be done, and is often done with private training data of varying sizes, limiting our ability to measure the effects of the modeling advances.\n\n#### It is challenging to determine which aspects of the methods contribute the most since training is computationally expensive, limiting the amount of tuning that can be done, and is often done with private training data of varying sizes, limiting our ability to measure the effects of the modeling advances.",
        "BERT-style pretraining crucially relies on large quantities of text. Baevski et al. (2019) demonstrate that increasing data size can result in improved end-task performance. Several efforts have trained on datasets larger and more diverse than the original BERT Radford et al. (2019); Yang et al. (2019); Zellers et al. (2019).Unfortunately, not all of the additional datasets can be publicly released. For our study, we focus on gathering as much data as possible for experimentation, allowing us to match the overall quality and quantity of data as appropriate for each comparison.\n\n#### The motivation of making CC-News dataset is most additional datasets in previous works are not available.",
        "We modify RoBERTa for this task by concatenating each candidate answer with the corresponding question and passage.We then encode each of these four sequences and pass the resulting [CLS] representations through a fully-connected layer, which is used to predict the correct answer.We truncate question-answer pairs that are longer than 128 tokens and, if needed, the passage so that the total length is at most 512 tokens.\n\n#### RoBERTa takes concatenated four sequence ,candidate answer with the corresponding question and passage, input not like BERT.",
        "BERT-style pretraining crucially relies on large quantities of text. Baevski et al. (2019) demonstrate that increasing data size can result in improved end-task performance. Several efforts have trained on datasets larger and more diverse than the original BERT Radford et al. (2019); Yang et al. (2019); Zellers et al. (2019).Unfortunately, not all of the additional datasets can be publicly released. For our study, we focus on gathering as much data as possible for experimentation, allowing us to match the overall quality and quantity of data as appropriate for each comparison.\n\n#### Yes, several other papers improved BERT. Baevski et al. (2019) prove that increasing training data size can improve performance. Moreover, (2019); Yang et al. (2019); Zellers et al. (2019) train BERT with larger and more diverse dataset than original BERT.",
        "We present a replication study of BERT pretraining Devlin et al. (2019), which includes a careful evaluation of the effects of hyperparmeter tuning and training set size. We find that BERT was significantly undertrained and propose an improved recipe for training BERT models, which we call RoBERTa, that can match or exceed the performance of all of the post-BERT methods.Our modifications are simple, they include: (1) training the model longer, with bigger batches, over more data; (2) removing the next sentence prediction objective; (3) training on longer sequences; and (4) dynamically changing the masking pattern applied to the training data. We also collect a large new dataset (CC-News) of comparable size to other privately used datasets, to better control for training set size effects.\n\n#### No, they used bigger batch size than BERT.",
        "The ability to understand natural language through commonsense reasoning is one of the core focuses in the field of natural language processing. To measure and study the different aspects of commonsense reasoning, several datasets are developed, such as SocialIQA (Sap et al., 2019b), CommonsenseQA (Talmor et al., 2018), and PhysicalIQA (Bisk et al., 2020), each requiring different type of commonsense knowledge (e.g., social, taxonomic, causal, declarative, etc) to select the correct answer. While large-scale neural systems (Devlin et al., 2018; Yang et al., 2019; Liu et al., 2019b) have shown human-level accuracy on these benchmarks, recent studies (Mitra et al., 2019) also criticize that these models solve individual datasets, rather than learning how to perform general semantic reasoning. To this end, Ma et al. (2021) suggested zero-shot evaluation as a genuine measure for the reasoning capability of the machine.\n\n#### It is hard to measure reasoning capability using individual datasets because the model cannot learn how to perform general semantic reasoning.",
        "To address these limitations, we propose a novel, modularized framework that aims to learn multiple expert models for KGs, then conduct zero-shot fusion to allow collaboration among KGs. For this purpose, we leverage AdapterFusion (Pfeiffer et al., 2021) where multiple tiny modules between Transformer blocks called adapters (Houlsby et al., 2019) can be combined after independent training, thus allowing a continual integration of the adapters without retraining the entire framework. Specifically, we treat the adapters as different KG-specific experts, and combine them using an attention-like fusion module. To improve the fusion of adapters, we suggest a KG-alignment adapter that guides to the apt expert adapters. Here, we use KGs in three different synthetic supervision training: (1) KG-specific QA datasets to train the KG-specific expert adapters, (2) a KG classification datasets to train the KG-alignment adapter, and (3) a balanced mixture of KG-specific QA datasets to train the fusion module. Our modularized method alleviates the interference between different KGs, which is the pitfall of MTL from our empirical observation, and thus combines multiple KGs into a synergetic zero-shot framework.\n\n#### AdapterFusion is one of the multi-task learning method based on attention-like mechanism. It aggregates pre-trained adapters in a non-destructive manner mitigating catastrophic forgetting and interference between tasks.",
        "In our setup, we repurpose synthetic QA generation (Ma et al., 2021) for the task of knowledge-driven zero-shot learning for commonsense reasoning, i.e., we transform a KG into multiple (Q_{i},A_{i}) pairs where Q_{i} is a natural language question and A_{i}=\\{A_{i,1},...,A_{i,m}\\} is the set of options with m answer candidates. Specifically, given a triple (e^{head},r,e^{tail}) in a KG, where e^{head}, e^{tail} and r denote head/tail entity and relation respectively, we transform e^{head} and r into a natural language question Q_{i} using templates. For the option set A_{i}, we use the combination of the correct answer e^{tail} and m-1 distractors which are tail entities from other triples sampled randomly (Ma et al., 2021). Details are described in Appendix B.\n\n#### They generate syntheticQS by transforming a triplet of KG into question and answer pair. Specifically, they transform the head entity and relation into question and tail entity into an answer using templates.",
        "To consider different types of reasoning, this paper extends ideas from the aforementioned zero-shot learning to the multi-source case such that it benefits from different types of commonsense knowledge on individual KGs. For example, ATOMIC (Sap et al., 2019a) focuses on social commonsense while ConceptNet (Speer et al., 2017) contains conceptual knowledge. A practical approach is multi-task learning (MTL; Caruana, 1997; Liu et al., 2019a), which learns a shared encoder for different synthetic QA datasets from multiple KGs. Despite its effectiveness, MTL scheme suffers from interference among different KGs, which results in forgetting previously learned knowledge when trained on new KG which has different kinds of knowledge (Pilault et al., 2021; Pfeiffer et al., 2021; Wang et al., 2021a; Wu et al., 2020).\n\n#### Conventional Multi-Task Learning (MTL) is known to be prone to interference between various tasks, as well as a phenomenon known as catastrophic forgetting, wherein the model struggles to retain knowledge of different types acquired during MTL.",
        "First, we modularize the KGs to preserve their intrinsic knowledge. Considering the importance of using a suitable and well-aligned KG (Ma et al., 2019, 2021) on a downstream task, the subtle difference between each KG should be learned by the model without any interference from each other. Accordingly, we adopt the adapter module (Houlsby et al., 2019) which repurposes a pre- trained language model (PLM) to incorporate each KG as tiny modules in between Transformer blocks. Specifically, as illustrated in Figure 2 (except for green area), the adapter training strategy involves injecting new layers (parameterized by Φ) into the original PLM (parameterized by θ). The weights of the original PLM are untouched, while the new adapter layers are initialized at random. Formally, we call each adapter trained with DkQA as an expert adapter for KG k, parameterized by ΦkQA.\n\n#### KG modularization is crucial for maintaining the intrinsic knowledge of each individual KG. As the selection and alignment of an appropriate KG has been shown to have a significant impact on downstream tasks, it is important that the model is able to learn the subtle differences between each KG without any interference from other KGs.",
        "where KG-invariant parameters θ are fixed and only KG-dependent parameters Φk QA are learned, which enables to store the corresponding knowledge separately without any interference. Further, we can parallelize the training of the adapter for all KGs. The efficiency of adapter training allows our modularization to be more scalable.\n\n#### Adapter enables to store the corresponding knowledge separately without any interference. We can parallelize the training of the adapter for all KGs. The efficiency of adapter training allows our modularization to be more scalable.",
        "Using the interference ratio, we can precisely compare the negative effects of multi-KG models on knowledge aggregation since the only reason to get the correct samples wrong is the interference caused by learning with additional KGs. We present the interference ratio of the models on five benchmark datasets in Figure 5. This figure shows that MTL has the higher interference ratio than the competing models across all benchmarks. Our method achieves a substantially better ratio, especially when KG-C adapter is used. This demonstrates the efficacy of our framework in mitigating interference between knowledge, which is one of the major problems of MTL.\n\n#### Use interference ratio.",
        "Once the expert adapters are learned, we combine the knowledge from each expert adapter using an attention-like mechanism. We present a novel fusion strategy as shown in Figure 2, which is referred to as the zero-shot fusion. In contrast to AdapterFusion (Pfeiffer et al., 2021) where the focus islearning to transfer knowledge to a specific targettask, our zero-shot fusion aims to generalize this transfer to any arbitrary target task. Specifically, the zero-shot fusion parameters Ψ learn to combine fixed expert adapters which are parameterized by Φ_1 QA, ..., Φ K QA. In each Transformer layer l of PLM with the injected fusion layer, the zero-shot fusion parameters ΨQA consist of query, key, and value matrices, denoted by WQ_l, WK_l, and WV_l respectively. These parameters are used to learn the balancing between the representation of each expert adapters through attention-like mechanism. While fixing both the parameters θ and all expert adapters Φ_1 QA, ..., Φ_K QA, the only trainable weights ΨQA on the fusion layer learns to combine the knowledge from different K expert adapters by using the subset of {Dk QA} K k=1 by random sampling. Here, we balance the ratio between the K knowledge-driven datasets as N samples (details are in Appendix D).\n\n#### In contrast to AdapterFusion where the focus is learning to transfer knowledge to a specific target task, our zero-shot fusion aims to generalize this transfer to any arbitrary target task.",
        "To address these limitations, we propose a novel, modularized framework that aims to learn multiple expert models for KGs, then conduct zero-shot fusion to allow collaboration among KGs. For this purpose, we leverage AdapterFusion (Pfeiffer et al., 2021) where multiple tiny modules between Transformer blocks called adapters (Houlsby et al., 2019) can be combined after independent training, thus allowing a continual integration of the adapters without retraining the entire framework. Specifically, we treat the adapters as different KG-specific experts, and combine them using an attention-like fusion module. To improve the fusion of adapters, we suggest a KG-alignment adapter that guides to the apt expert adapters. Here, we use KGs in three different synthetic supervision training: (1) KG-specific QA datasets to train the KG-specific expert adapters, (2) a KG classification datasets to train the KG-alignment adapter, and (3) a balanced mixture of KG-specific QA datasets to train the fusion module. Our modularized method alleviates the interference between different KGs, which is the pitfall of MTL from our empirical observation, and thus combines multiple KGs into a synergetic zero-shot framework.\n\n#### a balanced mixture of KG-specific QA datasets to train the fusion module.",
        "AdapterFusion uses the PLM hidden representation h^l_P LM as a query which is learned when training on a specific downstream task. In our zero-shot setting, however, we use a mixture of synthetic QA for fusion training, which is not exactly a training\n\n#### To compensate that usage a mixture of synthetic QA for fusion training, which is not exactly a training task.",
        "To address these limitations, we propose a novel, modularized framework that aims to learn multiple expert models for KGs, then conduct zero-shot fusion to allow collaboration among KGs. For this purpose, we leverage AdapterFusion (Pfeiffer et al., 2021) where multiple tiny modules between Transformer blocks called adapters (Houlsby et al., 2019) can be combined after independent training, thus allowing a continual integration of the adapters without retraining the entire framework. Specifically, we treat the adapters as different KG-specific experts, and combine them using an attention-like fusion module. To improve the fusion of adapters, we suggest a KG-alignment adapter that guides to the apt expert adapters. Here, we use KGs in three different synthetic supervision training: (1) KG-specific QA datasets to train the KG-specific expert adapters, (2) a KG classification datasets to train the KG-alignment adapter, and (3) a balanced mixture of KG-specific QA datasets to train the fusion module. Our modularized method alleviates the interference between different KGs, which is the pitfall of MTL from our empirical observation, and thus combines multiple KGs into a synergetic zero-shot framework.\n\n#### For KG-Classifier adapter training, KG classification dataset has been used. This dataset is generate by transforming a QA sample into a KG classification sample, using the concatenation of question and answer of synthetic QA as a question and the KG source as an answer.",
        "We evaluate our proposed framework on five question-answering benchmarks for commonsense\n\n#### We evaluate our proposed framework on five question-answering benchmarks for commonsense reasoning: SocialIQA (SIQA) (Sap et al., 2019b), CommonsenseQA (CSQA) (Talmor et al., 2018), Abductive NLI (a-NLI) (Bhagavatula et al., 2020), PhysicalIQA (PIQA) (Bisk et al., 2020), and WinoGrande (WG) (Sakaguchi et al., 2020).",
        "Single-Task Learning (STL): The model is pre-trained on a synthetic QA dataset generated from a single KG. Specifically, we experiment two architectural choices: PLM (STLPLM) and PLM with adapters (STL-Adapter). For each architecture, there are four STL models for each of synthetic QA datasets derived from ATOMIC, ConceptNet, WikiData, and WordNet. We note that the trained STLAdapter is an expert adapter from a specific KG in our framework. The performance of each STL baseline is shown in Appendix I Table 9 and Table 10.\n\n#### Single-Task Learning (STL): The model is pre-trained on a synthetic QA dataset generated from a single KG.",
        "Moreover, as an ablation, we compare the zeroshot fusion with and without KG-C adapter to explore the efficacy of the KG-C adapter. We can observe that zero-shot fusion with KG-C adapter improves the average accuracy by 0.4%, which implies that the use of KG-C adapter improves the overall performance and makes our method generalize better on most of the evaluation benchmarks.\n\n#### KG-C adapter improves the average accuracy of zero-shot fusion by 0.4%",
        "Further, we explore how the KG-C adapter affects zero-shot fusion which is based on an attention-like mechanism (Pfeiffer et al., 2021) compared to zero-shot fusion without KG-C adapter. Here, while zero-shot fusion without KGC adapter simply uses the representation of PLM as a query, zero-shot fusion with KG-C adapter leverages the representation of KG-C adapter. To illustrate this strength, we visualize the attention probability of [CLS] token from each fusion layer as a representative in Figure 4. The column of the darker cell indicates the adapter that has the bigger influence on the fused representation. We can observe that zero-shot fusion with KG-C adapter fuses the knowledge from different experts with a subtle difference rather than focusing on a single expert severely. This implies that KG-C adapter enables the delicate balancing between multiple knowledge sources based on the KG-alignment awareness, which leads to performance improvements in commonsense reasoning tasks. Interestingly, both cases have the ability not to focus on the expert adapter based on WikiData, which can be seen as a redundant expert.4 This observation would benefit from the further study that explores the optimal combination of KGs by expert selection or rejection.\n\n#### zero-shot fusion with KG-C adapter fuses the knowledge from different experts with a subtle difference rather than focusing on a single expert severely.",
        "In Figure 6, while the MTL tends to show the decrease of the performance when more KGs are utilized for training, our method obtains relative performance improvement across most of benchmarks. In both framework, the slightly degraded performance of the combination of KGs without ATOMIC could be due to the strong alignment between ATOMIC and SIQA. Except for the above case, we can observe that as more KGs are leveraged, the color of the cell gets greener, which implies that our method gains more advantages for better performance. This demonstrates that our method enables knowledge aggregation for multiple KGs synergetically.\n\n#### Zero-shot fusion obtains relative performance improvement across most of benchmark when more KGs are utilized for training.",
        "However, most of existing work are either assuming the existence of the alignment information between tasks and KGs (Banerjee and Baral, 2020) or an integrated KG (Ma et al., 2021). For example, \\texttt{ATOMIC}^{20}_{20} (Hwang et al., 2021), a commonsense KG which incorporates tuples from ConceptNet and ATOMIC with new relations and further crowdsourcing, combines multiple KGs into a new integrated KG, but as widely known (Ilievski et al., 2020; Hwang et al., 2021), heterogeneous schema between different KGs may limit triplets that can be integrated.111Only 172K tuples of the 3.4M tuples and 5 relations of 36 relations in ConceptNet are integrated into \\texttt{ATOMIC}^{20}_{20}. Rather than such symbolic KG integration with the inevitable loss of knowledge, in this work, we explore the neural KG integration leveraging the multiple KGs without additional processing and alignment information between KG and task.\n\n#### Rather than such symbolic KG integration with the inevitable loss of knowledge, in this work, we explore the neural KG integration leveraging the multiple KGs without additional processing and alignment information between KG and task.",
        "To consider different types of reasoning, this paper extends ideas from the aforementioned zero-shot learning to the multi-source case such that it benefits from different types of commonsense knowledge on individual KGs. For example, ATOMIC (Sap et al., 2019a) focuses on social commonsense while ConceptNet (Speer et al., 2017) contains conceptual knowledge. A practical approach is multi-task learning (MTL; Caruana, 1997; Liu et al., 2019a), which learns a shared encoder for different synthetic QA datasets from multiple KGs. Despite its effectiveness, MTL scheme suffers from interference among different KGs, which results in forgetting previously learned knowledge when trained on new KG which has different kinds of knowledge (Pilault et al., 2021; Pfeiffer et al., 2021; Wang et al., 2021a; Wu et al., 2020).\n\n#### (1) retraining the full model when adding new tasks (2) catastrophic forgetting and interference between tasks leading to difficulties of solving each task equally well and (3) inconsistent effect",
        "In our setup, we repurpose synthetic QA generation (Ma et al., 2021) for the task of knowledge-driven zero-shot learning for commonsense reasoning, i.e., we transform a KG into multiple (Q_{i},A_{i}) pairs where Q_{i} is a natural language question and A_{i}=\\{A_{i,1},...,A_{i,m}\\} is the set of options with m answer candidates. Specifically, given a triple (e^{head},r,e^{tail}) in a KG, where e^{head}, e^{tail} and r denote head/tail entity and relation respectively, we transform e^{head} and r into a natural language question Q_{i} using templates. For the option set A_{i}, we use the combination of the correct answer e^{tail} and m-1 distractors which are tail entities from other triples sampled randomly (Ma et al., 2021). Details are described in Appendix B.\n\n#### given a triple (e^{head},r,e^{tail}) in a KG, where e^{head}, e^{tail} and r denote head/tail entity and relation respectively, we transform e^{head} and r into a natural language question Q_{i} using templates.",
        "MTL (Liu et al., 2019a; Zhang and Yang, 2017; Caruana, 1997) learns a shared representation while aggregating knowledge across multiple learning tasks, often leading to better generalization ability of a model. However, parametric aggregation of knowledge with MTL has following limitations: (1) retraining the full model when adding new tasks (Houlsby et al., 2019; Pfeiffer et al., 2021, 2020b) (2) catastrophic forgetting and interference between tasks leading to difficulties of solving each task equally well (Pilault et al., 2021; Wu et al., 2020; Yu et al., 2020) and (3) inconsistent effect (Lourie et al., 2021). To deal with these challenges, Mixture-of-Experts (MoE) is a parameterized generalization of ensembling techniques, which has been adapted for MTL with gating network trained to optimize each task (Ma et al., 2018). However, simple linear gating networks are too shallow and thus may destruct task knowledge for commonsense reasoning.\n\n#### Conventionally, MTL stands for multiple learning tasks. Here, for experiment, the author call the model pre-trained on multiple synthetic QA datasets as MTL.",
        "In the future, our work can be extended to adapt our methods to further various multiple KGs with studies of appropriate scale for KG modularization. In addition, based on our hypothesis that the existence of an optimal combination, we can explore the study for the optional use of modularized KG experts for the best transfer learning.\n\n#### In the future, our work can be extended to adapt our methods to further various multiple KGs with studies of appropriate scale for KG modularization. In addition, based on our hypothesis that the existence of an optimal combination, we can explore the study for the optional use of modularized KG experts for the best transfer learning.",
        "In Figure 6, while the MTL tends to show the decrease of the performance when more KGs are utilized for training, our method obtains relative performance improvement across most of benchmarks. In both framework, the slightly degraded performance of the combination of KGs without ATOMIC could be due to the strong alignment between ATOMIC and SIQA. Except for the above case, we can observe that as more KGs are leveraged, the color of the cell gets greener, which implies that our method gains more advantages for better performance. This demonstrates that our method enables knowledge aggregation for multiple KGs synergetically.\n\n#### In both framework, the slightly degraded performance of the combination of KGs without ATOMIC could be due to the strong alignment between ATOMIC and SIQA.",
        "Inspired by this new metric, in this work, we focus on building unsupervised zero-shot multiple-choice QA systems. That is, we target an arbitrary commonsense reasoning task where conventional approaches (that rely heavily on task-specific supervision) are not applicable to such zero-shot learning scenarios. To learn QA models without expensive annotation efforts, recent works (Ma et al., 2021; Banerjee and Baral, 2020; Malaviya et al., 2020) propose to generate a synthetic QA dataset using a commonsense KG such as ATOMIC (Sap et al., 2019a) and ConceptNet (Speer et al., 2017). Such an approach mostly focuses only on one specific type of reasoning relations (e.g., if-then relation, or declarative relation), neglecting the fact that real-world QA systems require simultaneously considering different types of reasoning abilities (e.g., declarative and social, or causal and physical reasoning; Ilievski et al., 2021; Chang et al., 2021).\n\n#### This work has been motivated from the fact that real-world QA systems require simultaneously considering different types of reasoning abilities. Therefore, this paper target an arbitrary commonsense reasoning task where conventional approaches are not applicable to such zero-shot learning scenarios.",
        "We propose to use the representation of KGClassifier adapter as a query in attention-like mechanism, referred to as the zero-shot fusion with KGClassifier adapter. That is, using the hidden representation h^{l}_{KGC} of a KG-Classifier adapter parameterized by ΦKGC as a query, we substitute Q^{l} in Eq. (11) as follows:\n\n#### using the hidden representation h^{l}_{KGC} of a KG-Classifier adapter parameterized by ΦKGC as a query",
        "We compare our framework with the following baselines. First, to show the characteristics of each benchmark, we use the random or the most frequent label as Random and Majority baseline, respectively. RoBERTa-L and GPT2-L is the performance of each PLM without any finetuning. Also, as the baseline for the unsupervised learning model using KGs, we report the performance of Self-talk (Shwartz et al., 2020), COMET-DynaGen (Bosselut and Choi, 2019), SMLM (Banerjee and Baral, 2020) as presented in original papers.\n\n#### Majority is the results when selecting with the most frequent label as an answer.",
        "QA from ATOMIC (Sap et al., 2019a)\n\n#### Q: Dana speeds on the highway. Dana is seen as A1: considerate A2: risky(X) A3: lazy",
        "We apply the proposed NAS method with the supernet architecture described above. The depth of 5 stages is set to 3,4,7,4,11, respectively. The latency constraint is set to 2.5 ms that corresponds to the latency of EfficientNet-B1 on our target NPU, MIDAP. Table 6 compares our search results with the state-of-the-art models: EdgeTPU (Gupta and Akin, 2020), EfficientNet (Tan and Le, 2019a), Once-For-All (Cai et al., 2019). The latency of the other models is obtained by running the network on the MIDAP cycle-accurate simulator. We compare the accuracy without quantization, assuming that quantization effects will be similar to all models.\n\n#### They compared their network with state-of-the-art models in Table 6. Table 6 shows that the baseline model achieved higher accuracy than comparisons with similar latency.",
        "Even though the proposed methodology can be applied to any type of NPU, the current implementation is made for an adder-tree type NPU, called MIDAP (Kanget al., 2019).It has a fully-pipelined micro-architecture that consists of separate hardware modules and memory modules for convolution, activation function, and various reduction operations. Since it enables us to make a fully static schedule of operations without resource contention in the data path, we can estimate the end-to-end latency of a CNN quite accurately analytically. Unexpected delay may incur from off-chip DRAM delay that is not fully hidden by double buffering.\n\n#### They modify the supernet architecture by varying the number of blocks in stages, and adds MixConv to the search space. This enables more diverse combinations of kernel sizes and expansion ratios than original MixConv. Moreover, they eases the search process. As a result, they could find a better network than existing network models. Note that their method can be used to any type of NPU.",
        "As shown in Table 6, the baseline model, ours-M, found by the proposed NAS technique has higher accuracy than the other models on our target NPU; ours-M achieves more than 1.7% higher top-1 accuracy than EfficientNet-lite2 with similar latency. Moreover, it is 0.5% higher than EfficientNet-B1, even without using SE and h-swish activation function. Note that the number of parameters and the number of FLOPS in ours-M is larger than EfficientNet-B1. It implies that the complexity of the network is not a direct indicator of the end-to-end latency of the network. The end-to-end latency depends on the NPU architecture, and the proposed NAS technique could find a larger network with shorter latency by adding the latency factor to the loss function directly. The main benefit comes from different block assignment to stages.\n\n#### Other criteria, such as complexity of the network or the number of MAC operations, is not a proper measure of latency. Thus targeting on latency is important.",
        "Figure 6 depicts our building block structure. This block starts and ends with 1×1 convolution, with N searchable superkernels in the middle. Each searchable superkernel is designed similarly to Eq. (3), while we may use different threshold values in each superkernel. The kernel sizes and expansion ratios are selected among predetermined values. If the j-th searchable superkernel chooses an expansion ratio e_{j}, the j-th kernel has e_{j} times more channels than the first 1×1 convolution. Compared with the original MixConv suggested in (Tan and Le, 2019b), the proposed building block supports more diverse combinations of kernel sizes and expansion ratios. It enhances the efficiency of search results on our target NPU (Table 5).\n\n#### A superkernel is a component for searching expansion ratio and kernel sizes. Supernet defines the largest network we can search.",
        "Even though the proposed methodology can be applied to any type of NPU, the current implementation is made for an adder-tree type NPU, called MIDAP (Kanget al., 2019).It has a fully-pipelined micro-architecture that consists of separate hardware modules and memory modules for convolution, activation function, and various reduction operations. Since it enables us to make a fully static schedule of operations without resource contention in the data path, we can estimate the end-to-end latency of a CNN quite accurately analytically. Unexpected delay may incur from off-chip DRAM delay that is not fully hidden by double buffering.\n\n#### The end-to-end latency can be estimated quite accurately, and MIDAP can efficiently support which which lower the MAC utilization in other NPUs.",
        "Another good feature of MIDAP is that it efficiently supports the following operations that would lower the MAC (multiply-accumulate) utilization in other NPUs that have many MAC units: pooling, DWConv, and squeeze-and-excitation (SE). For DWConv operation, it does not use an adder tree but an alternative hardware logic that consists of a set of individual accumulators connected to the multiply units. For pooling and SE operations, reduction logic is included in the pipeline.Note that MIDAP has not been implemented as a real hardware chip yet but as a virtual prototype with a cycle-accurate simulator. Thanks to the cycle-accurate simulator that considers the DRAM access contention and parametrized DRAM access delay, we could build an accurate analytical model for end-to-end latency estimation, based on the profiling result with the simulator.\n\n#### MIDAP can support DWConv, SE more efficiently than other NPUs. However, MIDAP is not implemented as a real hardware chip yet, but the cycle-accurate simulator is open-sourced.",
        "Figure 11 depicts an example distribution of activation values produced by two different SE blocks for three different images. The authors of the original paper (Hu et al., 2018) conjectured that if such distribution from a SE block does not differ widely between image classes, the SE block is not important. Thus, after training, they obtained averaged activation values of a SE block over multiple images in the same class.They compared the distributions of the averaged values over different image classes. They observed that removing the SE blocks that have similar distributions over different image classes incurs only a marginal loss in accuracy.\n\n#### Removing SE blocks having similar distributions over different image classes are known to incur only a marginal loss in accuracy. Thus, for each channel c, authors calculated the standard deviation \\sigma_{c} of activation values over different images. Small value of \\sigma_{c} would mean that SE block is having similar distrubution over different images. Thus they defined the metric as the average of \\sigma_{c} over all channels. Specifically, they sample from 10K images from the training dataset, and remove until only about 60% of blocks are remained.",
        "There are two methods to find an architecture with a loose latency constraint. One is to use compound scaling that scales a small network with shorter latency, and the other is to search a network directly. To compare these two methods,we first scaled ours-M using the same scaling coefficients that we used to scale ours-M+ to ours-L+ and trained it. When conducting a direct search, we scaled the depth and width of the supernet and the input image size first and applied the proposed NAS technique for the scaled supernet. We used batch size 512 instead of 1024 during the architecture search due to the memory limitation of TPU. The comparison result is shown in Table 7 in terms of top-1 accuracy(%) and the latency on the target NPU(ms).Two results were similar while direct search needed 10 hours on TPUv3; It means that compound scaling is an effective method to find a large network fast.\n\n#### Searching in a small supernet then scaling was better than directly searching in a big supernet; The accuracy was similar, but the direct search needed much higher search cost.",
        "Thus, we place more blocks to stages with larger width in the supernet, making the cumulative depth up to a specific stage is proportional to the width of the stage, which is similar to PyramidNet (Han et al., 2017). A recent study (Radosavovic et al., 2020) also claims that neural architectures with a linear relationship between the cumulative depth and the width tend to have higher accuracy with a similar amount of computation complexity. Our experiment shows that our modification to supernet enhances the efficiency of the search result in terms of accuracy as well as latency (Table 4).\n\n#### The previous study shows the linear design is beneficial in terms of computational complexity, while the author shows the result in terms of latency.",
        "Figure 11 depicts an example distribution of activation values produced by two different SE blocks for three different images. The authors of the original paper (Hu et al., 2018) conjectured that if such distribution from a SE block does not differ widely between image classes, the SE block is not important. Thus, after training, they obtained averaged activation values of a SE block over multiple images in the same class.They compared the distributions of the averaged values over different image classes. They observed that removing the SE blocks that have similar distributions over different image classes incurs only a marginal loss in accuracy.\n\n#### Previous work shows the potential of removing SE blocks, and authors confirms the benefit of removal with an experimental result.",
        "While most NAS techniques are not compared with a random search method, the authors (Li and Talwalkar, 2019) reported that a random search method is highly competitive. So we conducted an experiment to compare the proposed NAS technique with two random search methods, exploring the same search space defined by the supernet structure of ours-M.First, we designed a simple random search method that has the similar time complexity of the proposed technique. In this method, we randomly generate 15 models having a similar latency with ours-M, from the same search space. Then we train each of them for 1 epoch with cosine learning rate decay. After evaluating each of them, we choose the architecture with the topmost top-1 accuracy and fully train it. In the second method, called random selection, we randomly generate 20 models having a similar latency with ours-M and train them fully and take the architecture with the highest top-1 accuracy. Since the random selection method performs search and training simultaneously, it is slower than the proposed technique by the number of randomly generated models.\n\n#### The randomly searched network on the same supernet could not outperform the proposed result with Single-Path NAS. Thus the search strategy was beneficial.",
        "The existing hardware-aware differentiable NAS methods mostly define some hyperparameters to balance between accuracy and latency, including SinglePath NAS, whose loss function is defined as Eq. (6). Since there is no information on the target latency in the loss function, in case there is a strict latency constraint, they have to pay additional search costs for the hyperparameters to let the final architecture have no larger latency than the constraint. In addition, this process needs to be repeated whenever the target latency is changed.\n\n#### Previous method needs additional search cost for hyperparameter, since they have no information for target latency. The author's method directly includes the target latency, resulting in ease of search process.",
        "Among diverse techniques to decrease the search cost, Single-Path NAS (Stamoulis et al., 2019) was recently proposed to find a good architecture faster than the existing differentiable NAS techniques. This technique is extended to broaden the search space by including the squeeze-and-excitation (SE) block in the search space (Stamoulis et al., 2020). Our work is grounded on the original Single-Path NAS technique.\n\n#### The author's aim is building a fast NAS methodology. Single-Path NAS could search a good architecture faster than existing NAS techniques. It builds a faster NAS technique by reducing the number of trainable parameters. Another reason is that Single-Path NAS can be efficiently extended to support MixConv.",
        "Let \\mathbf{w}_{k,e} denote the depthwise convolution kernel of candidate MBConv with kernel size k and expansion ratio e (MBConv{}_{k,e}). First, they introduce a large \\mathbf{w}_{5,6}, which is the DWConv kernel of MBConv{}_{5,6}. Then, the inner core of \\mathbf{w}_{5,6} can be considered as \\mathbf{w}_{3,6}, a DWConv kernel of MBConv{}_{3,6}.A superkernel containing these two kernel size options can be expressed as Figure 4:(1)\\mathbf{w}_{*,6}=\\mathbf{w}_{3,6}+\\mathbbm{1}(\\rm{use\\leavevmode\\nobreak\\ kernel\\leavevmode\\nobreak\\ size\\leavevmode\\nobreak\\ 5})\\cdot\\mathbf{w}_{5\\backslash 3,6}where \\mathbf{w}_{5\\backslash 3,e} means the outer part, \\mathbf{w}_{5,e}-\\mathbf{w}_{3,e}.Next, they formulate conditions to determine the kernel size. They define a certain threshold value t and compare the norm of the kernel weights with the threshold. If the norm of a subset weight is larger than the threshold, it remains in the supernet. To this end, Eq. (1) is changed as follows:(2)\\mathbf{w}_{*,6}(t_{k=5})=\\mathbf{w}_{3,6}+\\mathbbm{1}(\\lVert\\mathbf{w}_{5\\backslash 3,6}\\rVert^{2}>t_{k=5})\\cdot\\mathbf{w}_{5\\backslash 3,6}\n\n#### They define a trainable threshold value t, and compare the norm of the kernel weights with the threshold, to determine the kernel size.",
        "In this section, we will briefly review the Single-Path NAS technique and our target NPU.Before going further, we define some terminologies used in this paper, as shown in Figure 3. A neural architecture consists of stages at the top level. A stage consists of a sequence of blocks whose output feature maps have the same dimension. In the proposed supernet, a block is defined as MBConv that typically starts with 1×1 conv (expansion layer) and ends with 1×1 conv. Adopting the MixConv approach, the depthwise convolution layer consists of parallel superkernels whose kernel size will be determined during the NAS process. The width of block denotes the number of channels in the final output feature map of the block, and the width of stage is the width of the final block in the stage. We will call the total number of blocks starting from the very first block in the network up to the last block in a specific stage S, as the cumulative depth up to stage S.\n\n#### The total number of blocks starting from the very first bloci in the network up to the last block in a specific stage.",
        "Extensive studies have been conducted to find a better activation function than ReLU, and the swish activation function (Ramachandranet al., 2017) was found. Several neural networks (Tan and Le, 2019b; Mei et al., 2019; Tan and Le, 2019a) use swish activation function instead of ReLU to improve accuracy. Howard et al. (Howard et al., 2019) proposed a quantization-friendly version of the swish activation function called h-swish that has a similar impact on accuracy. So, we replace ReLU with h-swish (Howard et al., 2019) activation function.\n\n#### Previous works showed that using swish activation function instead of ReLU showed better accuracy, and h-swish shows similar impact on accuracy. The authors verify that replacing ReLU with h-swish and adding SE improves the accuracy by around 1%.",
        "As shown in Table 4, a supernet with linear depth outperforms a supernet with constant depth in terms of accuracy with similar latency. It confirms that this simple change of block assignment in supernet gives notable accuracy boost with the same latency constraint, without any additional optimization techniques.\n\n#### Using the conventional, constant depth method would drop the accuracy.",
        "Figure 9 shows the estimated latency and simulated latency of randomly generated 100 models on our search space. It validates the accuracy of the proposed latency model, whose mean absolute percentage error(MAPE) is about 0.16%.\n\n#### The latency of randomly generated models shows that the latency model is accurate.",
        "Siamese Networks Koch et al. (2015) can be interpreted asa single layer message-passing iteration of our model, and using the same initialnode embedding (5) {\\bf x}_{i}^{(0)}=(\\phi(x_{i}),h_{i}) , using a non-trainableedge feature\\varphi({\\bf x}_{i},{\\bf x}_{j})=\\|\\phi(x_{i})-\\phi(x_{j})\\|~{},~{}\\tilde{A}^{(0)}=\\text{softmax}(-\\varphi)~{},and resulting label estimation\\hat{Y}_{*}=\\sum_{j}\\tilde{A}_{*,j}^{(0)}\\langle{\\bf x}_{j}^{(0)},u\\rangle~{},with u selecting the label field from {\\bf x}. In this model,the learning is reduced to learning image embeddings \\phi(x_{i}) whoseeuclidean metric is consistent with the label similarities.\n\n#### Learned distance from Siamese network can be used to solve one-shot problems. This network can play a role as a single layer message-passing iteration of our model.",
        "Besides few-shot learning, a related task is the ability to learn from a mixture oflabeled and unlabeled examples — semi-supervised learning, as wellas active learning, in which the learner has the option to request those missing labelsthat will be most helpful for the prediction task.Our graph-based architecture is naturally extended to these setups withminimal changes in the training design.We validate experimentally the model on few-shot image classification, matchingstate-of-the-art performance with considerably fewer parameters,and demonstrate applications to semi-supervised and active learning setups.\n\n#### Active learning is training strategy which uses both labeld and unlabeld data in training as well as semi-supervised learning.",
        "One such instance is the ability to learn from few examples, in the so-called few-shot learning tasks.Rather than relying on regularization to compensate for the lack of data, researchers have exploredways to leverage a distribution of similar tasks, inspired by human learning Lake et al. (2015).This defines a new supervised learning setup (also called ‘meta-learning’) in which the input-outputpairs are no longer given by iid samples of images and their associated labels, but by iid samples ofcollections of images and their associated label similarity.\n\n#### Few-shot learning is learning from few examples. Therefore, zero-shot learning is learning from no real example.",
        "Another related area of research concerns deep learning architectures on graph-structured data.The GNN was first proposed in Gori et al. (2005); Scarselli et al. (2009), as a trainable recurrent message-passingwhose fixed points could be adjusted discriminatively.Subsequent works Li et al. (2015); Sukhbaatar et al. (2016) have relaxed the model by untying the recurrent layer weights and proposed several nonlinear updates through gating mechanisms.Graph neural networks are in fact natural generalizations of convolutional networks to non-Euclidean graphs. Bruna et al. (2013); Henaff et al. (2015) proposed to learn smooth spectral multipliers of the graph Laplacian, albeit with high computational cost, and Defferrard et al. (2016); Kipf & Welling (2016) resolved the computational bottleneck by learning polynomials of the graph Laplacian, thus avoiding the computation of eigenvectors and completing the connection with GNNs. In particular, Kipf & Welling (2016)was the first to propose the use of GNNs on semi-supervised classification problems.We refer the reader to Bronstein et al. (2017) for an exhaustive literature review on the topic.GNNs and the analogous Neural Message Passing Models are finding application in many different domains. Battaglia et al. (2016); Chang et al. (2016) develop graph interaction networks that learn pairwise particle interactions and apply them to discrete particle physical dynamics. Duvenaud et al. (2015); Kearnes et al. (2016) study molecular fingerprints using variants of the GNN architecture, and Gilmer et al. (2017) further develop the model by combining it with set representations Vinyals et al. (2015), showing state-of-the-art results on molecular prediction.\n\n#### Demerit of GNN is high computational complexity.  Kipf & Welling (2016) used polynomials of the graph Laplacian to resolve the computational bottleneck of GNN.",
        "We evaluate our model by performing different q-shot, K-way experiments on both datasets. For every few-shot task \\mathcal{T}, we sample K random classes from the dataset, and from each class we sample q random samples. An extra sample to classify is chosen from one of that K classes.\n\n#### N-way and M-shot means that we sample N random classes from the dataset, and we sample M random samples from each class.",
        "Besides few-shot learning, a related task is the ability to learn from a mixture oflabeled and unlabeled examples — semi-supervised learning, as wellas active learning, in which the learner has the option to request those missing labelsthat will be most helpful for the prediction task.Our graph-based architecture is naturally extended to these setups withminimal changes in the training design.We validate experimentally the model on few-shot image classification, matchingstate-of-the-art performance with considerably fewer parameters,and demonstrate applications to semi-supervised and active learning setups.\n\n#### Unlike Few-shot learning, semi-supervised learning is training strategy which uses both labeled and unlabeled examples.",
        "Another related area of research concerns deep learning architectures on graph-structured data.The GNN was first proposed in Gori et al. (2005); Scarselli et al. (2009), as a trainable recurrent message-passingwhose fixed points could be adjusted discriminatively.Subsequent works Li et al. (2015); Sukhbaatar et al. (2016) have relaxed the model by untying the recurrent layer weights and proposed several nonlinear updates through gating mechanisms.Graph neural networks are in fact natural generalizations of convolutional networks to non-Euclidean graphs. Bruna et al. (2013); Henaff et al. (2015) proposed to learn smooth spectral multipliers of the graph Laplacian, albeit with high computational cost, and Defferrard et al. (2016); Kipf & Welling (2016) resolved the computational bottleneck by learning polynomials of the graph Laplacian, thus avoiding the computation of eigenvectors and completing the connection with GNNs. In particular, Kipf & Welling (2016)was the first to propose the use of GNNs on semi-supervised classification problems.We refer the reader to Bronstein et al. (2017) for an exhaustive literature review on the topic.GNNs and the analogous Neural Message Passing Models are finding application in many different domains. Battaglia et al. (2016); Chang et al. (2016) develop graph interaction networks that learn pairwise particle interactions and apply them to discrete particle physical dynamics. Duvenaud et al. (2015); Kearnes et al. (2016) study molecular fingerprints using variants of the GNN architecture, and Gilmer et al. (2017) further develop the model by combining it with set representations Vinyals et al. (2015), showing state-of-the-art results on molecular prediction.\n\n#### Previous researches such as Duvenaud et al. (2015)and Kearnes et al. (2016) used GNN.",
        "Matching networks Vinyals et al. (2016) use a set representation for the ensemble of images in \\mathcal{T},similarly as our proposed graph neural network model, but with two important differences.First, the attention mechanism considered in this set representationis akin to the edge feature learning, with the difference that the mechanism attends always to the same node embeddings, as opposed to our stacked adjacency learning, which is closer to Vaswani et al. (2017). In other words, instead of the attention kernel in (3),matching networks consider attention mechanisms of the form \\tilde{A}_{*,j}^{(k)}=\\varphi({\\bf x}_{*}^{(k)},{\\bf x}_{j}^{(T)}),where {\\bf x}_{j}^{(T)} is the encoding function for the elements of the support set, obtained with bidirectional LSTMs. In that case, the support set encoding is thus computed independently of the target image.Second, the label and image fields are treated separately throughout the model, with a final step that aggregates linearly the labels using a trained kernel. This may prevent the model to leverage complex dependencies between labels and images at intermediate stages.\n\n#### It's not true. Matching network uses attention mechanism, not BERT.",
        "Supervised end-to-end learning has been extremely successful in computer vision, speech, or machine translation tasks,thanks to improvements in optimization technology, larger datasets and streamlined designs of deep convolutional or recurrent architectures. Despite these successes, this learning setup does not cover many aspects where learning is nonetheless possible and desirable.\n\n#### There were great succeed in computer vision and speech tasks. However, this learning setup does not cover many aspects where learning is nonetheless possible and desirable.",
        "Omniglot is a dataset of 1623 characters from 50 different alphabets, each character/class has been drawn by 20 different people. Following Vinyals et al. (2016) implementation we split the dataset into 1200 classes for training and the remaining 423 for testing. We augmented the dataset by multiples of 90 degrees as proposed by Santoro et al. (2016).\n\n#### Omniglot is a dataset consist of 1623 characters from 50 different alphabets. In this dataset, 20 different people drew each character.",
        "The typical measure used for reporting progress in language modeling is perplexity, which is the average per-word log-probability on the holdout data set: e^{-\\frac{1}{N}\\sum_{i}\\ln{p_{w_{i}}}}. We follow the standard procedure and sum over all the words (including the end of sentence symbol).\n\n#### As the average per-word log-probability, perplexity is a measure of how confused the language model is in predicting the next word.",
        "Language Modeling (LM) has been a central task in NLP. The goal of LM is to learn a probability distribution over sequences of symbols pertaining to a language. Much work has been done on both parametric (e.g., log-linear models) and non-parametric approaches (e.g., count-based LMs). Count-based approaches (based on statistics of N-grams) typically add smoothing which account for unseen (yet possible) sequences, and have been quite successful. To this extent, Kneser-Ney smoothed 5-gram models (Kneser & Ney, 1995) are a fairly strong baseline which, for large amounts of training data, have challenged other parametric approaches based on Neural Networks (Bengio et al., 2006).\n\n#### The paper does not discuss what smoothing is or how it helps some LMs account for unseen sequences.",
        "A crucial aspect which we discuss in detail in later sections is the size of our models. Despite the large number of parameters, we try to minimize computation as much as possible by adopting a strategy proposed in (Sak et al., 2014) of projecting a relatively big recurrent state space down so that the matrices involved remain relatively small, yet the model has large memory capacity.\n\n#### Paper does not discuss what a recurrent state space is.",
        "In (Kim et al., 2015), the words characters are processed by a 1-d CNN (Le Cun et al., 1990) with max-pooling across the sequence for each convolutional feature. The resulting features are fed to a 2-layer highway network (Srivastava et al., 2015b), which allows the embedding to learn semantic representations. The model was evaluated on small-scale language modeling experiments for various languages and matched the best results on the PTB data set despite having 60% fewer parameters.\n\n#### The paper does not discuss the difference between 1D CNN and highway networks.",
        "z_{w}=h^{T}CNN(chars_{w})+h^{T}Mcorr_{w}where M is a matrix projecting a low-dimensional embedding vector corr_{w} back up to the dimensionality of the projected LSTM hidden state of h. This amounts to adding a bottleneck linear layer, and brings the CNN Softmax much closer to our best result, as can be seen in Table 1, where adding a 128-dim correction halves the gap between regular and the CNN Softmax.\n\n#### It is a means of improvement over words that have different meaning but are spelled similarly.",
        "Following (Zaremba et al., 2014) we use dropout (Srivastava, 2013) before and after every LSTM layer. The biases of LSTM forget gate were initialized to 1.0 (Jozefowicz et al., 2015). The size of the models will be described in more detail in the following sections, and the choices of hyper-parameters will be released as open source upon publication.\n\n#### Dropout is a neural network component parametrized with a probability. The paper does not discuss how it alleviates overfitting.",
        "p(Y=k|W)\\propto_{Y}\\frac{p_{d}(w_{k})}{p_{n}(w_{k})}and, following a similar argument than for NCE, if we define p(Y=k|W)=softmax(s_{\\theta}(w_{k})-\\log p_{n}(w_{k})) then p^{\\prime}(w)=softmax(s_{\\theta}(w,h)) is a good approximation of p_{d}(word). Note that the only difference between NCE and IS is that, in NCE, we define a binary classification task between true or noise words with a logistic loss, whereas in IS we define a multiclass classification problem with a Softmax and cross entropy loss. We hope that our derivation helps clarify the similarities and differences between the two. In particular, we observe that IS, as it optimizes a multiclass classification task (in contrast to solving a binary task), may be a better choice. Indeed, the updates to the logits with IS are tied whereas in NCE they are independent.\n\n#### IS performs better.",
        "The character-level features allow for a smoother and compact parametrization of the word embeddings. Recent efforts on small scale language modeling have used CNN character embeddings for the input embeddings (Kim et al., 2015). Although not as straightforward, we propose an extension to this idea to also reduce the number of parameters of the Softmax layer. Recall from Section 2.3 that the Softmax computes a logit as z_{w}=h^{T}e_{w} where h is a context vector and e_{w} the word embedding. Instead of building a matrix of |V|\\times|h| (whose rows correspond to e_{w}), we produce e_{w} with a CNN over the characters of w as e_{w}=CNN(chars_{w}) – we call this a CNN Softmax. We used the same network architecture to dynamically generate the Softmax word embeddings without sharing the parameters with the input word-embedding sub-network. For inference, the vectors e_{w} can be precomputed, so there is no computational complexity increase w.r.t. the regular Softmax.\n\n#### The paper discusses one advantage of character-level embeddings over word-level embeddings. There is no comprehensive discussion on why the resulting performance does not degrade.",
        "Assigning probability distributions over large vocabularies is computationally challenging. For modeling language, maximizing log-likelihood of a given word sequence leads to optimizing cross-entropy between the target probability distribution (e.g., the target word we should be predicting), and our model predictions p. Generally, predictions come from a linear layer followed by a Softmax non-linearity: p(w)=\\frac{\\exp(z_{w})}{\\sum_{w^{\\prime}\\in V}\\exp(z_{w^{\\prime}})} where z_{w} is the logit corresponding to a word w. The logit is generally computed as an inner product z_{w}=h^{T}e_{w} where h is a context vector and e_{w} is a “word embedding” for w.\n\n#### The paper does not discuss the detailed workings of the established relation.",
        "Unsurprisingly, size matters: when training on a very large and complex data set, fitting the training data with an LSTM is fairly challenging. Thus, the size of the LSTM layer is a very important factor that influences the results, as seen in Table 1. The best models are the largest we were able to fit into a GPU memory. Our largest model was a 2-layer LSTM with 8192+1024 dimensional recurrent state in each of the layers. Increasing the embedding and projection size also helps but causes a large increase in the number of parameters, which is less desirable. Lastly, training an RNN instead of an LSTM yields poorer results (about 5 perplexity worse) for a comparable model size.\n\n#### The paper does not discuss how the positive effects are brought about.",
        "Recent work on sentence-level RE can be divided into two lines.One focuses on injecting external knowledge into PLMs.Methods of such, including ERNIE Zhang et al. (2019) and KnowBERT Peters et al. (2019), take entity embedding pretrained from knowledge graphs as inputs to the Transformer.Similarly, K-Adapter Wang et al. (2020) introduces a plug-in neural adaptor that injects factual and linguistic knowledge into the language model.LUKE Yamada et al. (2020) further extends the pretraining objective of masked language modeling to entities and proposes an entity-aware self-attention mechanism.The other line of work focuses on continually pretraining PLMs on text with linked entities using relation-oriented objectives.Specifically, BERT-MTB Baldini Soares et al. (2019) proposes a matching-the-blanks objective that decides whether two relation instances share the same entities.Despite extensively studied, existing RE models still perform far from perfect.On the commonly-used benchmark TACRED Zhang et al. (2017), the SOTA F_{1} result only increases from 70.1\\% (BERT{}_{\\text{LARGE}}) to 72.7\\% (LUKE) after applying PLMs to this task.It is unclear what building block is missing to constitute a promising RE system.\n\n#### It is true. LUKE Yamada et al. (2020) is one of SOTA model in RE task. This model extends the pretraining objective of masked language modeling to entities and proposes an entity-aware self-attention mechanism.",
        "As one of the fundamental information extraction (IE) tasks,relation extraction (RE) aims at identifying the relationship(s) between two entities in a given piece of text from a pre-defined set of relationships of interest.For example, given the sentence “Bill Gates founded Microsoft together with his friend Paul Allen in 1975” and an entity pair (“Bill Gates”, “Microsoft”), the RE model is expected to predict the relation ORG:FOUNDED_BY.On this task, SOTA models based on PLMs Devlin et al. (2019); Joshi et al. (2020) have gained significant success.\n\n#### Relation Extraction(RE) task is task of finding relationship between two entities. For instance, with given text “Bill Gates founded Microsoft together with his friend Paul Allen in 1975” and an entity pair (“Bill Gates”, “Microsoft”), the RE model should find the relation ORG:FOUNDED_BY",
        "In this work, we discuss two obstacles that have hindered the performance of existing RE models.First, the RE task provides a structured input of both the raw texts and side information of the entities, such as entity names, spans, and types (typically provided by NER models), which are shown important to the performance of RE models Peng et al. (2020).However, existing methods fall short of representing the entity information comprehensively in the text, leading to limited characterization of the entities.Second, human-labeled RE datasets (e.g., TACRED), may contain a large portion of noisy or ill-defined labels, causing the model performance to be misestimated.Alt et al. (2020) relabeled the development and test set of TACRED and found that 6.62\\% of labels are incorrect.Stoica et al. (2021) refined many ill-defined relation types and further re-annotated the TACRED dataset using an improved annotation strategy to ensure high-quality labels.To this end, we propose an improved RE baseline, where we introduce the typed entity marker to sentence-level RE, which leads to promising improvement of performance over existing RE models.\n\n#### There are two obstacles of RE. First, existing method has limit of characterization of the entities. Second, there are many noises in human labeled data. They improve the model performance by addressing these problems.",
        "Recent work on sentence-level RE can be divided into two lines.One focuses on injecting external knowledge into PLMs.Methods of such, including ERNIE Zhang et al. (2019) and KnowBERT Peters et al. (2019), take entity embedding pretrained from knowledge graphs as inputs to the Transformer.Similarly, K-Adapter Wang et al. (2020) introduces a plug-in neural adaptor that injects factual and linguistic knowledge into the language model.LUKE Yamada et al. (2020) further extends the pretraining objective of masked language modeling to entities and proposes an entity-aware self-attention mechanism.The other line of work focuses on continually pretraining PLMs on text with linked entities using relation-oriented objectives.Specifically, BERT-MTB Baldini Soares et al. (2019) proposes a matching-the-blanks objective that decides whether two relation instances share the same entities.Despite extensively studied, existing RE models still perform far from perfect.On the commonly-used benchmark TACRED Zhang et al. (2017), the SOTA F_{1} result only increases from 70.1\\% (BERT{}_{\\text{LARGE}}) to 72.7\\% (LUKE) after applying PLMs to this task.It is unclear what building block is missing to constitute a promising RE system.\n\n#### Yes, there are several works of constructing RE model. ERNIE Zhang et al. (2019) and KnowBERT Peters et al. (2019) construct RE model by injecting external knowledge into PLMs. BERT-MTB Baldini Soares et al. (2019) continually pretrain PLMs on text with linked entities using relation-oriented objectives.",
        "Datasets. The datasets we have used in the experiments include three versions of TACRED: the original TACRED Zhang et al. (2017), TACREV Alt et al. (2020), and Re-TACRED Stoica et al. (2021).Alt et al. (2020) observed that the TACRED dataset contains about 6.62\\% noisily-labeled instances and relabeled the development and test set.Stoica et al. (2021) further refined the label definitions in TACRED and relabeled the whole dataset.We provide the statistics of the datasets in Appendix A.\n\n#### They used three datasets, the original TACRED Zhang et al. (2017), TACREV Alt et al. (2020), and Re-TACRED Stoica et al. (2021).",
        "In this work, we discuss two obstacles that have hindered the performance of existing RE models.First, the RE task provides a structured input of both the raw texts and side information of the entities, such as entity names, spans, and types (typically provided by NER models), which are shown important to the performance of RE models Peng et al. (2020).However, existing methods fall short of representing the entity information comprehensively in the text, leading to limited characterization of the entities.Second, human-labeled RE datasets (e.g., TACRED), may contain a large portion of noisy or ill-defined labels, causing the model performance to be misestimated.Alt et al. (2020) relabeled the development and test set of TACRED and found that 6.62\\% of labels are incorrect.Stoica et al. (2021) refined many ill-defined relation types and further re-annotated the TACRED dataset using an improved annotation strategy to ensure high-quality labels.To this end, we propose an improved RE baseline, where we introduce the typed entity marker to sentence-level RE, which leads to promising improvement of performance over existing RE models.\n\n#### Entity names, spans and types are important to the performance of RE models Peng et al. (2020). Since types are typically provided by NER models, improvement of NER technology can improve RE technology.",
        "Compared methods.We compare with the following methods.PA-LSTM Zhang et al. (2017) adopts bi-directional LSTM Hochreiter and Schmidhuber (1997) and positional-aware attention Bahdanau et al. (2015) to encode the text into an embedding, which is then fed into a softmax layer to predict the relation.C-GCN Zhang et al. (2018) is a graph-based model, which feeds the pruned dependency tree of the sentence into the graph convolutional network Kipf and Welling (2017) to obtain the representation of entities.SpanBERT Joshi et al. (2020) is a PLM based on the Transformer Vaswani et al. (2017). It extends BERT Devlin et al. (2019) by incorporating a training objective of span prediction and achieves improved performance on RE.KnowBERT Peters et al. (2019) jointly trains a language model and an entity linker, which allows the subtokens to attend to entity embedding that is pretrained on knowledge bases.LUKE Yamada et al. (2020) pretrains the language model on both large text corpora and knowledge graphs. It adds frequent entities into the vocabulary and proposes an entity-aware self-attention mechanism.\n\n#### SpanBERT Joshi et al. (2020) achieved improved performance on RE than BERT. Therefore, RE model should use spanBERT to improve model performance.",
        "We first provide an analysis on different entity representation techniques. In this analysis, we use the base and large versions of BERT Devlin et al. (2019) and the large version of RoBERTa Liu et al. (2019) as the encoder.Table 1 shows the performance of the PLMs incorporated with different entity representation techniques.For each technique, we also provide an example of the processed text.We have several observations from the results.First, the typed entity marker and its variants outperform untyped entity representation techniques by a notable margin.Especially, the RoBERTa model achieves an F_{1} score of 74.6\\% using the typed entity marker (punct), which is significantly higher than the SOTA result of 72.7\\% by LUKE Yamada et al. (2020).This shows that representing all categories of entity information is helpful to the RE task.It also shows that keeping entity names in the input improves the performance of RE models.Second, symbols used in entity markers have an obvious impact on the performance of RE models.Although the original and punct versions of entity representation techniques represent the same categories of entity information, they do lead to a difference in model performance.Particularly, introducing new special tokens hinders the model performance drastically on RoBERTa.On RoBERTa{}_{\\text{LARGE}}, the entity marker underperforms the entity marker (punct) by 0.7\\%, the typed entity marker underperforms the typed entity marker (punct) by 3.6\\%, while the entity mask gets a much worse result of 60.9\\%.\n\n#### Their improved RE baseline achieved SOTA performance on the RE-TACRED dataset with f1 score of 91.1%. Moreover, Using RoBERTa Liu et al. (2019) as the backbone, they improved baseline model on TACRED and TACREV with f1 score 74.6% and 83.2%, respectively. The RoBERTa model achieves 1.9% higher f1 score than the SOTA model LUKE Yamada et al.",
        "•Entity mask Zhang et al. (2017). This technique introduces new special tokens [SUBJ-TYPE] or [OBJ-TYPE] to mask the subject or object entities in the original text, where TYPE is substituted with the respective entity type.This technique was originally proposed in the PA-LSTM model Zhang et al. (2017), and was later adopted by PLMs such as SpanBERT Joshi et al. (2020).Zhang et al. (2017) claim that this technique prevents the RE model from over-fitting specific entity names, leading to more generalizable inference.•Entity marker Zhang et al. (2019); Baldini Soares et al. (2019). This technique introduces special tokens pairs [E1], [/E1] and [E2], [/E2] to enclose the subject and object entities, therefore modifying the input text to the format of “[E1] subj [/E1] … [E2] obj [/E2]”333subj and obj are respectively the original token spans of subject and object entities..•Entity marker (punct) Wang et al. (2020); Zhou et al. (2021). This technique is a variant of the previous technique that encloses entity spans using punctuation.It modifies the input text to “@ subj @ … # obj #”. The main difference from the previous technique is that this one does not introduce new special tokens into the model’s reserved vocabulary.•Typed entity marker Zhong and Chen (2021). This technique further incorporates the NER types into entity markers.It introduces new special tokens \\langleS:TYPE\\rangle, \\langle/S:TYPE\\rangle, \\langleO:TYPE\\rangle, \\langle/O:TYPE\\rangle, where TYPE is the corresponding NER type given by a named entity tagger. The input text is accordingly modified to “\\langleS:TYPE\\rangle subj \\langle/S:TYPE\\rangle … \\langleO:TYPE\\rangle obj \\langle/O:TYPE\\rangle”.•Typed entity marker (punct). We propose a variant of the typed entity marker technique that marks the entity span and entity types without introducing new special tokens.This is to enclose the subject and object entities with “@” and “#”, respectively.We also represent the subject and object entity types using their label text, which is prepended to the entity spans and is enclosed by “*” for subjects or “\\wedge” for objects.The modified text is “@ * subj-type * subj @ … # \\wedge obj-type \\wedge obj # ”, where subj-type and obj-type is the label text of NER types.\n\n#### It's not true. Two term has different meaning. Entity marker is the teqnique introduces special tokens pairs to enclose the object and subject entities, whereas entity mask is the teqnique introduces new special tokens to mask the object or object entities.",
        "Scale is a key challenge for entity linking; there are millions of possible entities to consider for each mention. To efficiently filter or rank the candidates, existing methods use different sources of external information, including manually curated mention tables Ganea and Hofmann (2017), incoming Wikipedia link popularity Yamada et al. (2016), and gold Wikipedia entity categories Gillick et al. (2019). In this paper, we show that BERT-based models set new state-of-the-art performance levels for large scale entity linking when used in a zero shot setup, where there is no external knowledge and a short text description provides the only information we have for each entity. We also present an extensive evaluation of the accuracy-speed trade-off inherent to large pre-trained models, and show is possible to achieve very efficient linking with modest loss of accuracy.\n\n#### The paper shows the scalability of the proposed simple two-stage method with the experiments conducted on the zero-shot entity-linking dataset where external entity knowledge is not available, which enables the model to be used on various entity linking tasks that contain millions of possible entities to consider. The state-of-the-art result and the extensive evaluation of the accuracy-speed trade-off support that the proposed method is efficient and scalable.",
        "As expected, the cross-encoder performs better than the bi-encoder on ranking. However, both models exceed state-of-the-art performance levels, demonstrating that the overall approach is highly effective. We observe that our model also performs well when we change the underlying Knowledgebase to full Wikipedia, and even without fine-tuning on the dataset. In Table 5 we show that our bi-encoder model is highly effective at retrieving relevant entities, where the underlying Knowledgebase is full Wikipedia.\n\n#### BLINK model is a two-stage method using two encoders: bi-encoder and cross-encoder. With the qualitative analysis, the authors compared the BLINK with its bi-encoding version which uses a bi-encoder for candidate ranking instead of a cross-encoder, and showed that the cross-encoding version utilizing context information better than the bi-encoding version. Therefore we can say that BLINK has two different versions.",
        "Due to its larger memory and compute footprint, we use the cross-encoder in a re-ranking stage, over a small set (≤100)\\leq 100)≤ 100 ) of candidates retrieved with the bi-encoder. The cross-encoder is not suitable for retrieval or tasks that require fast inference.\n\n#### Since the cross-encoder has large memory consumption and compute footprint, it is time-consuming and not suitable for tasks that require fast inference. However, it is relatively accurate compared to the bi-encoder, which is the reason the author utilized knowledge distillation so that they can obtain some accuracy gain from the cross-encoder. Therefore, we can say that using a cross-encoder is time-consuming but accurate.",
        "Table 8 presents some examples from our bi-encoder and cross-encoder model predictions, to provide intuition for how these two models consider context and mention for entity linking.\n\n#### Cross-encoder exerts its power for the cases requiring disambiguation with the given context. Table 8 shows some examples where the cross-encoder can accurately identify and linked entities through the context while the bi-encoder failed.\nFor example, the cross-encoder links \"Ronaldo\" to a corret person with the context of \"Juventus\", while the bi-encoder links to another football player that are Brazilian. Another example shows that the cross-encoder can identify that the sentence is describing gothic art instead of gothic fiction.",
        "Table 8 presents some examples from our bi-encoder and cross-encoder model predictions, to provide intuition for how these two models consider context and mention for entity linking.\n\n#### In the third example of Table 8, the cross-encoder linked the mention to the wrong entity \"Ancient Greek philosophy\", which is likely because of a word \"philosophers\" in the context.",
        "is widely used for evaluating entity linking systems Ji et al. (2010).444https://tac.nist.gov Following prior work, we measure in-KB accuracy (P@1). There are 1,074 and 1,020 annotated mention/entity pairs derived from 1,453 and 2,231 original news and web documents on training and evaluation dataset, respectively. All the entities are from the TAC Reference Knowledgebase which contains 818,741 entities with titles, descriptions and other meta info.\n\n#### TACKBP-2010 is the dataset for evaluating entity linking systems that are widely used in research in this field like \"Khalife and Vazirgiannis (2018)\" and \"Raiman and Raiman (2018)\". This dataset is made in 2010 and contains the entities in the TAC Reference Knowledge Base which contains 818,741 entities with titles, descriptions, and other meta information. This paper also used the TACKBP-2010 for fine-tuning the model. While it is likely that TACKB and 2010 are from the name of the knowledge base and when the dataset was made, it is not clear what P stands for in TACKBP-2010.",
        "Scale is a key challenge for entity linking; there are millions of possible entities to consider for each mention. To efficiently filter or rank the candidates, existing methods use different sources of external information, including manually curated mention tables Ganea and Hofmann (2017), incoming Wikipedia link popularity Yamada et al. (2016), and gold Wikipedia entity categories Gillick et al. (2019). In this paper, we show that BERT-based models set new state-of-the-art performance levels for large scale entity linking when used in a zero shot setup, where there is no external knowledge and a short text description provides the only information we have for each entity. We also present an extensive evaluation of the accuracy-speed trade-off inherent to large pre-trained models, and show is possible to achieve very efficient linking with modest loss of accuracy.\n\n#### In the zero-shot settings, the set of documents/mentions/entities from training data is not visible in test data, which means the information of the entity that should be linked at test time is not learned directly from the training set. This setting is related to scalability, which is important for the entity linking tasks since there can be lots of possible entity candidates for each mention. The proposed BERT-based models can deal with these settings and show their accuracy and efficiency in scale.",
        "was constructed by Logeswaran et al. (2019) from Wikia.333https://www.wikia.com.The task is to link entity mentions in text to an entity dictionary with provided entity descriptions, in a set of domains. There are 49K, 10K, and 10K examples in the train, validation, test sets respectively.The entities in the validation and test sets are from different domains than the train set, allowing for evaluation of performance on entirely unseen entities. The entity dictionaries cover different domains and range in size from 10K to 100K entities.\n\n#### In the Wikia dataset, entities in the validation and test sets are from different domains than the train set. This setting allows the model evaluation can be done in a zero-shot setting since the set of entities are separated in training and test so that the model can't see the entities when linked at the test time.",
        "Scale is a key challenge for entity linking; there are millions of possible entities to consider for each mention. To efficiently filter or rank the candidates, existing methods use different sources of external information, including manually curated mention tables Ganea and Hofmann (2017), incoming Wikipedia link popularity Yamada et al. (2016), and gold Wikipedia entity categories Gillick et al. (2019). In this paper, we show that BERT-based models set new state-of-the-art performance levels for large scale entity linking when used in a zero shot setup, where there is no external knowledge and a short text description provides the only information we have for each entity. We also present an extensive evaluation of the accuracy-speed trade-off inherent to large pre-trained models, and show is possible to achieve very efficient linking with modest loss of accuracy.\n\n#### The BLINK model used a two-stage approach for entity linking based on fine-tuned BERT architectures that first encode the mention context and entity text with the bi-encoder for the candidate retrieval and utilize the cross-encoder to score and rank them. These pre-trained architectures are simple yet scalable and effective for entity link tasks without the help of task-specific heuristics or external knowledge. The authors showed that BLINK can achieve state-of-the-art performance for the large-scale entity linking on the dataset with a zero-shot setup. (WikilinksNED Unseen-Mentions and TACKBP-201)",
        "Scale is a key challenge for entity linking; there are millions of possible entities to consider for each mention. To efficiently filter or rank the candidates, existing methods use different sources of external information, including manually curated mention tables Ganea and Hofmann (2017), incoming Wikipedia link popularity Yamada et al. (2016), and gold Wikipedia entity categories Gillick et al. (2019). In this paper, we show that BERT-based models set new state-of-the-art performance levels for large scale entity linking when used in a zero shot setup, where there is no external knowledge and a short text description provides the only information we have for each entity. We also present an extensive evaluation of the accuracy-speed trade-off inherent to large pre-trained models, and show is possible to achieve very efficient linking with modest loss of accuracy.\n\n#### The BLINK model can be said to be valuable since the model is simple yet scalable and effective compared to existing works. The proposed BERT-based model can perform entity linking with large-scale and zero-shot setups, which is crucial in real-world use cases that often contain a lot of unseen entities. BLINK also achieved a new state-of-the-art result for two zero-shot benchmarks by using only the provided text description without external knowledge, which shows the effectiveness of the proposed model.",
        "This paper contributes: (i) 2 architectures (Local and Global) for joint entity linking (EL) and corefence resolution,(ii) an extended AIDA dataset (Hoffart et al., 2011), adding new annotations of linked and NIL coreference clusters,(iii) experimental analysis on 2 datasets where our joint coref+EL models achieve up to +5% F1-score on both tasks compared to standalone models. We also show up to+50% in accuracyfor hard cases of ELwhereentity mentionslackthe correct entity in their candidate list.\n\n#### Yes, they add new annotations of linked and NIL coreference clusters.",
        "This paper contributes: (i) 2 architectures (Local and Global) for joint entity linking (EL) and corefence resolution,(ii) an extended AIDA dataset (Hoffart et al., 2011), adding new annotations of linked and NIL coreference clusters,(iii) experimental analysis on 2 datasets where our joint coref+EL models achieve up to +5% F1-score on both tasks compared to standalone models. We also show up to+50% in accuracyfor hard cases of ELwhereentity mentionslackthe correct entity in their candidate list.\n\n#### Yes, Joint model achieve superior performance.",
        "Table 2 shows the results of our compared models for EL andcoreference resolutiontasks.Answering (Q1), we observe a general improvement in performance of our coref+EL joint models (Local and Global) compared to Standalone on the EL task.Furthermore, this difference is bigger when using our cluster-level hard metrics.This also answers (Q2) by indicating that the joint models tend to produce more coherent cluster-based predictions.To make this more explicit, Table 3 compares the accuracy for singleton clusters (i.e., clusters composed by a single entity mention), denoted as S, to that of clusters composed by multiple mentions, denoted as M.We observe that the difference in performance between our joint models andStandalone is bigger on M clusters (with a consistentsuperiorityof Global), indicating that our approach indeed produces more coherent predictions for mentions that refer to the same concept.\n\n#### Yes, Joint model achieve superior performance on coreference resolution task.",
        "To solve EL in the general case, evenwhen the first mention does not have the correct entity, we propose bidirectional connections between mentions, thus leading to a maximum spanning tree problem in our Global approach.Here we define a score for a (sub)tree t, noted as \\Phi_{\\mathrm{tr}}(t):\\Phi_{\\mathrm{tr}}(t)=\\sum_{(i,j)\\in t}\\Phi_{\\mathrm{cl}}(u_{i},u_{j}),(7)where u_{i} and u_{j} are two connected nodes (i.e., root, candidate entities or spans) in t.For a ground truth cluster c\\in C (with C being the set of all such clusters), with its set444For a single cluster annotation, indeed it is possible that multiple correct trees can be drawn. of correct subtree representations \\mathcal{T}_{c}, we model the cluster’s likelihood with its subtree scores. We minimize the negative log-likelihood \\mathcal{L} of all clusters:\\displaystyle\\mathcal{L}\\displaystyle=-\\log\\frac{\\prod_{c\\in C}\\sum_{t\\in\\mathcal{T}_{c}}\\exp\\big{(}\\Phi_{\\mathrm{tr}}(t)\\big{)}}{\\sum_{t\\in\\mathcal{T}_{\\textit{all}}}\\exp\\big{(}\\Phi_{\\mathrm{tr}}(t)\\big{)}}.(8)Naively enumerating all possible spanning trees (\\mathcal{T}_{\\textit{all}} or \\mathcal{T}_{c}) implied by this equation is infeasible, since their number is exponentially large.We use the adapted Kirchhoff’s Matrix Tree Theorem(MTT; Koo et al. (2007); Tutte (1984))to solve this:the sum of the weights of the spanning trees in a directed graph rooted in r is equal to the determinant of the Laplacian matrix of the graph with the row and column corresponding to r removed (i.e., the minor of the Laplacian with respect to r). This way, eq. (8) can be rewritten as\\displaystyle\\mathcal{L}\\displaystyle=-\\log\\frac{\\prod_{c\\in C}{\\det\\Big{(}\\mathbf{\\hat{L}}_{c}\\big{(}\\mathbf{\\Phi_{\\mathrm{cl}}}\\big{)}\\Big{)}}}{\\det\\Big{(}\\mathbf{L}_{r}\\big{(}\\mathbf{\\Phi_{\\mathrm{cl}}}\\big{)}\\Big{)}},(9)where \\mathbf{\\Phi_{\\mathrm{cl}}} is the weighted adjacency matrix of the graph, and \\mathbf{L}_{r} is the minor of the Laplacian with respect to the root node r. An entry in the Laplacian matrix iscalculatedas\\displaystyle\\medmath{L_{i,j}=\\begin{cases}\\sum\\limits_{k}\\exp(\\Phi_{\\mathrm{cl}}(u_{k},u_{j}))&\\text{if $i=j$}\\\\-\\exp(\\Phi_{\\mathrm{cl}}(u_{i},u_{j}))&\\text{otherwise}\\end{cases}},(10)Similarly, \\mathbf{\\hat{L}}_{c} is a modified Laplacian matrix where the first row is replaced with the root r selection scores \\Phi_{\\mathrm{cl}}(r,u_{j}).For clarity, Appendix A presents a toy example with detailed steps to calculate the loss in eq. (9).\n\n#### They lead to a maximum spanning tree problem in their global approach by proposing bidirectional connections between mentions. However, we cannot know maximum spanning tree only with this information.",
        "Our first approach (Local in Fig. 1(a)) is motivated by current state-of-the-artcoreference resolution models(Joshi et al., 2019; Wu et al., 2020)that predict a single antecedent for each span to resolve.We extend this architecture by also considering entity links as potential antecendents:in the example of Fig. 1, the mention “Alliance” can be either connected to its antecedent mention “NATO” or to any of its candidate links (Alliance or Alliance,_Ohio).While straightforward,this approach cannot solvecases where the first coreferenced mention does not include the correct entity in its candidate list(e.g., if the order of “NATO” and “Alliance” mentions in Fig. 1 would be reversed).We therefor propose a second approach, Global, which by construction overcomes this inherent limitation by using bidirectional connections between mentions.Because that implies cycles could be formed, we resort to solving a maximum spanning tree problem.Mentions that refer to the same entity form a cluster, represented as a subtree rooted by the single entity they link to.To encode the overall document’s clusters in a single spanning tree, we introduce a virtual root node(see Fig. 1(b)).222Coreference clusters without a linked entity, i.e., a NIL cluster, have a link of a mention directly to the root.\n\n#### Local model optimize the marginalized probability of the correct antecedents for each given span whereas global model overcomes inherent limitation by using bidirectional connections between mentions.",
        "We considered two datasets to evaluate our proposed models: DWIE (Zaporojets et al., 2021) and AIDA (Hoffart et al., 2011).Since AIDA essentially does not contain coreference information, we had to extend it by(i) adding missing mention links in order to make annotations consistent on the coreference cluster level, and(ii) annotating NIL coreference clusters.We note this extended dataset as AIDA{}^{+}. See Table 1 for the details.\n\n#### They considered DWIE (Zaporojets et al., 2021) and AIDA (Hoffart et al., 2011). They only extend AIDA dataset by adding missing mention links becaue it does not contain coreference information. Therefore, DWIE contains important corner cases.",
        "In order to tackle research question (Q3), we study the accuracy of our models on the important corner case that involves mentions without correct entity in their candidate lists.This is illustrated in Table 4, which focuses on such mentionsin clusters where at least one mention contains the correct entity in its candidate list.As expected, theStandalone model cannot link such mentions, as it is limited to the localcandidate list.In contrast, both our joint approaches can solve some of these cases by using the correct candidates from other mentions in the cluster, with a superior performance of our Global model compared to the Local one.\n\n#### They build their model jointly to make model can use the correct candidates from other mentions in the cluster.",
        "In order to tackle research question (Q3), we study the accuracy of our models on the important corner case that involves mentions without correct entity in their candidate lists.This is illustrated in Table 4, which focuses on such mentionsin clusters where at least one mention contains the correct entity in its candidate list.As expected, theStandalone model cannot link such mentions, as it is limited to the localcandidate list.In contrast, both our joint approaches can solve some of these cases by using the correct candidates from other mentions in the cluster, with a superior performance of our Global model compared to the Local one.\n\n#### Global model is necessary when it should use correct candidates from other mentions in the cluster.",
        "We considered two datasets to evaluate our proposed models: DWIE (Zaporojets et al., 2021) and AIDA (Hoffart et al., 2011).Since AIDA essentially does not contain coreference information, we had to extend it by(i) adding missing mention links in order to make annotations consistent on the coreference cluster level, and(ii) annotating NIL coreference clusters.We note this extended dataset as AIDA{}^{+}. See Table 1 for the details.\n\n#### AIDA+ is extended AIDA by adding missing mention links.",
        "Our model takes as input(i) the full document text, and(ii) an alias table with entity candidates for each of the possible spans.Our end-to-end approach allows to jointly predict the mentions, entity links and coreference relations between them.\n\n#### They explained their model as end-to-end since the model can jointly predict the mentions, entity links and coreference relations between them.",
        "We use the front look thumbnail images of 70,000 unique products to build Fashion-MNIST. Those products come from different gender groups: men, women, kids and neutral. In particular, white-color products are not included in the dataset as they have low contrast to the background. The thumbnails (51\\times 73) are then fed into the following conversion pipeline, which is visualized in Figure 1.\n\n#### categories are men , women , kids and neutral.\n\ncomposition: False",
        "Finally, the dataset is divided into a training and a test set. The training set receives a randomly-selected 6,000 examples from each class. Images and labels are stored in the same file format as the MNIST data set, which is designed for storing vectors and multidimensional matrices. The result files are listed in Table 1. We sort examples by their labels while storing, resulting in smaller label files after compression comparing to the MNIST. It is also easier to retrieve examples with a certain class label. The data shuffling job is therefore left to the algorithm developer.\n\n#### Training set has 6,000 example from each class. \n\ncomposition: False",
        "Our aim with this work is to create a good benchmark dataset which has all the accessibility of MNIST, namely its small size, straightforward encoding and permissive license. We took the approach of sticking to the 10 classes 70,000 grayscale images in the size of 28\\times 28 as in the original MNIST. In fact, the only change one needs to use this dataset is to change the URL from where the MNIST dataset is fetched. Moreover, Fashion-MNIST poses a more challenging classification task than the simple MNIST digits data, whereas the latter has been trained to accuracies above 99.7% as reported in Wan et al. (2013); Ciregan et al. (2012).\n\n#### MNIST dataset\n\ncomposition: False",
        "The reason MNIST is so popular has to do with its size, allowing deep learning researchers to quickly check and prototype their algorithms. This is also complemented by the fact that all machine learning libraries (e.g. scikit-learn) and deep learning frameworks (e.g. Tensorflow, Pytorch) provide helper functions and convenient examples that use MNIST out of the box.\n\n#### The popularity is related to size which allows researchers to check and prototype their model.",
        "This paper introduced Fashion-MNIST, a fashion product images dataset intended to be a drop-in replacement of MNIST and whilst providing a more challenging alternative for benchmarking machine learning algorithm. The images in Fashion-MNIST are converted to a format that matches that of the MNIST dataset, making it immediately compatible with any machine learning package capable of working with the original MNIST dataset.\n\n#### MNIST provides more challenging classification task.",
        "We also looked at the EMNIST dataset provided by Cohen et al. (2017), an extended version of MNIST that extends the number of classes by introducing uppercase and lowercase characters. However, to be able to use it seamlessly one needs to not only extend the deep learning framework’s MNIST helpers, but also change the underlying deep neural network to classify these extra classes.\n\n#### To be able to use it seamlessly one needs to not only extend the deep learning framework’s MNIST helpers but also change the underlying deep neural network to classify these extra classes.",
        "Fashion-MNIST is based on the assortment on Zalando’s website222Zalando is the Europe’s largest online fashion platform. http://www.zalando.com. Every fashion product on Zalando has a set of pictures shot by professional photographers, demonstrating different aspects of the product, i.e. front and back looks, details, looks with model and in an outfit. The original picture has a light-gray background (hexadecimal color: #fdfdfd) and stored in 762\\times 1000 JPEG format. For efficiently serving different frontend components, the original picture is resampled with multiple resolutions, e.g. large, medium, small, thumbnail and tiny.\n\n#### It is based on Zolando's website Every fashion product on Zalando has a set of pictures shot by professional photographers, demonstrating different aspects of the product, i.e. front and back looks, details, looks with model, and an outfit. For the class labels, they have  used the silhouette code of the product",
        "Fashion-MNIST is based on the assortment on Zalando’s website222Zalando is the Europe’s largest online fashion platform. http://www.zalando.com. Every fashion product on Zalando has a set of pictures shot by professional photographers, demonstrating different aspects of the product, i.e. front and back looks, details, looks with model and in an outfit. The original picture has a light-gray background (hexadecimal color: #fdfdfd) and stored in 762\\times 1000 JPEG format. For efficiently serving different frontend components, the original picture is resampled with multiple resolutions, e.g. large, medium, small, thumbnail and tiny.\n\n#### Zalando’s website222Zalando is the Europe’s largest online fashion platform.",
        "Finally, the dataset is divided into a training and a test set. The training set receives a randomly-selected 6,000 examples from each class. Images and labels are stored in the same file format as the MNIST data set, which is designed for storing vectors and multidimensional matrices. The result files are listed in Table 1. We sort examples by their labels while storing, resulting in smaller label files after compression comparing to the MNIST. It is also easier to retrieve examples with a certain class label. The data shuffling job is therefore left to the algorithm developer.\n\n#### Yes, it is true that shuffling task of data is left to algorithm developer by authors",
        "The reason MNIST is so popular has to do with its size, allowing deep learning researchers to quickly check and prototype their algorithms. This is also complemented by the fact that all machine learning libraries (e.g. scikit-learn) and deep learning frameworks (e.g. Tensorflow, Pytorch) provide helper functions and convenient examples that use MNIST out of the box.\n\n#### all machine learning libraries (e.g. scikit-learn) and deep learning frameworks (e.g. Tensorflow, Pytorch)",
        "This paper introduced Fashion-MNIST, a fashion product images dataset intended to be a drop-in replacement of MNIST and whilst providing a more challenging alternative for benchmarking machine learning algorithm. The images in Fashion-MNIST are converted to a format that matches that of the MNIST dataset, making it immediately compatible with any machine learning package capable of working with the original MNIST dataset.\n\n#### It performs benchmarking machine learning algorithms\n\ncomposition: False",
        "Fashion-MNIST is based on the assortment on Zalando’s website222Zalando is the Europe’s largest online fashion platform. http://www.zalando.com. Every fashion product on Zalando has a set of pictures shot by professional photographers, demonstrating different aspects of the product, i.e. front and back looks, details, looks with model and in an outfit. The original picture has a light-gray background (hexadecimal color: #fdfdfd) and stored in 762\\times 1000 JPEG format. For efficiently serving different frontend components, the original picture is resampled with multiple resolutions, e.g. large, medium, small, thumbnail and tiny.\n\n#### Images and labels are stored in the same file format as the MNIST data set, which is designed for storing vectors and multidimensional matrices. The original picture has a light-gray background (hexadecimal color: #fdfdfd) and is stored in 762 imes 1000 JPEG format.",
        "This paper introduced Fashion-MNIST, a fashion product images dataset intended to be a drop-in replacement of MNIST and whilst providing a more challenging alternative for benchmarking machine learning algorithm. The images in Fashion-MNIST are converted to a format that matches that of the MNIST dataset, making it immediately compatible with any machine learning package capable of working with the original MNIST dataset.\n\n#### yes  FashionMNIST dataset can be used to train and test deep learning models",
        "The reason MNIST is so popular has to do with its size, allowing deep learning researchers to quickly check and prototype their algorithms. This is also complemented by the fact that all machine learning libraries (e.g. scikit-learn) and deep learning frameworks (e.g. Tensorflow, Pytorch) provide helper functions and convenient examples that use MNIST out of the box.\n\n#### the author talks about using various ML and DL models and getting the accuracy as well, but exactly which models are used has not been specified.",
        "The MNIST dataset comprising of 10-class handwritten digits, was first introduced by LeCun et al. (1998) in 1998. At that time one could not have foreseen the stellar rise of deep learning techniques and their performance. Despite the fact that today deep learning can do so much the simple MNIST dataset has become the most widely used testbed in deep learning, surpassing CIFAR-10 (Krizhevsky and Hinton, 2009) and ImageNet (Deng et al., 2009) in its popularity via Google trends111https://trends.google.com/trends/explore?date=all&q=mnist,CIFAR,ImageNet. Despite its simplicity its usage does not seem to be decreasing despite calls for it in the deep learning community.\n\n#### MNIST dataset is widely used in DL.",
        "We provide some classification results in Table 3 to form a benchmark on this data set. All algorithms are repeated 5 times by shuffling the training data and the average accuracy on the test set is reported. The benchmark on the MNIST dataset is also included for a side-by-side comparison. A more comprehensive table with explanations on the algorithms can be found on https://github.com/zalandoresearch/fashion-mnist.\n\n#### Yes the author used hyper-parameter tuning.",
        "This paper introduced Fashion-MNIST, a fashion product images dataset intended to be a drop-in replacement of MNIST and whilst providing a more challenging alternative for benchmarking machine learning algorithm. The images in Fashion-MNIST are converted to a format that matches that of the MNIST dataset, making it immediately compatible with any machine learning package capable of working with the original MNIST dataset.\n\n#### The purpose of dataset is a drop-in replacement of MNIST and whilst providing a more challenging alternative for benchmarking machine learning algorithms and create good benchmark.",
        "The MNIST dataset comprising of 10-class handwritten digits, was first introduced by LeCun et al. (1998) in 1998. At that time one could not have foreseen the stellar rise of deep learning techniques and their performance. Despite the fact that today deep learning can do so much the simple MNIST dataset has become the most widely used testbed in deep learning, surpassing CIFAR-10 (Krizhevsky and Hinton, 2009) and ImageNet (Deng et al., 2009) in its popularity via Google trends111https://trends.google.com/trends/explore?date=all&q=mnist,CIFAR,ImageNet. Despite its simplicity its usage does not seem to be decreasing despite calls for it in the deep learning community.\n\n#### The MNIST dataset comprising of 10-class handwritten digits, was first introduced by LeCun et al.",
        "For the class labels, we use the silhouette code of the product. The silhouette code is manually labeled by the in-house fashion experts and reviewed by a separate team at Zalando. Each product contains only one silhouette code. Table 2 gives a summary of all class labels in Fashion-MNIST with examples for each class.\n\n#### The silhouette code is manually labeled by the in-house fashion experts and reviewed by a separate team at Zalando.",
        "We perform a thorough comparison of Mask R-CNN to the state of the art along with comprehensive ablations on the COCO dataset [28]. We report the standard COCO metrics including AP (averaged over IoU thresholds), AP{}_{50}, AP{}_{75}, and AP{}_{S}, AP{}_{M}, AP{}_{L} (AP at different scales). Unless noted, AP is evaluating using mask IoU. As in previous work [5, 27], we train using the union of 80k train images and a 35k subset of val images (trainval35k), and report ablations on the remaining 5k val images (minival). We also report results on test-dev [28].\n\n#### The standard COCO metrics were used for the comparison of Mask R-CNN to the state of the art on the COCO dataset, but the reason is not strongly discussed int paragraphs.",
        "The vision community has rapidly improved object detection and semantic segmentation results over a short period of time. In large part, these advances have been driven by powerful baseline systems, such as the Fast/Faster R-CNN [12, 36] and Fully Convolutional Network (FCN) [30] frameworks for object detection and semantic segmentation, respectively. These methods are conceptually intuitive and offer flexibility and robustness, together with fast training and inference time. Our goal in this work is to develop a comparably enabling framework for instance segmentation.\n\n#### Vision community has rapidly improved object detection and semantic segmentation results over a short period of time. In significant part, these gains have been driven by powerful basic systems, such as the Fast/Faster R-CNN and Fully Convolutional Network (FCN) frameworks. The purpose of this effort is to provide a comparable enabling framework for instance segmentation.",
        "Instance segmentation is challenging because it requires the correct detection of all objects in an image while also precisely segmenting each instance. It therefore combines elements from the classical computer vision tasks of object detection, where the goal is to classify individual objects and localize each using a bounding box, and semantic segmentation, where the goal is to classify each pixel into a fixed set of categories without differentiating object instances.111Following common terminology, we use object detection to denote detection via bounding boxes, not masks, and semantic segmentation to denote per-pixel classification without differentiating instances. Yet we note that instance segmentation is both semantic and a form of detection. Given this, one might expect a complex method is required to achieve good results. However, we show that a surprisingly simple, flexible, and fast system can surpass prior state-of-the-art instance segmentation results.\n\n#### Instance segmentation is a new type of computer vision task that aims to solve the problem of how to represent all objects in an image. It combines elements from the classical computer vision tasks of object detection and localizing each object using a bounding box, and semantic segmentation.",
        "Mask R-CNN is conceptually simple: Faster R-CNN has two outputs for each candidate object, a class label and a bounding-box offset; to this we add a third branch that outputs the object mask. Mask R-CNN is thus a natural and intuitive idea. But the additional mask output is distinct from the class and box outputs, requiring extraction of much finer spatial layout of an object. Next, we introduce the key elements of Mask R-CNN, including pixel-to-pixel alignment, which is the main missing piece of Fast/Faster R-CNN.\n\n#### Output of Mask -RNN are class label , bounding box and object mask.",
        "Mask R-CNN adopts the same two-stage procedure, with an identical first stage (which is RPN). In the second stage, in parallel to predicting the class and box offset, Mask R-CNN also outputs a binary mask for each RoI. This is in contrast to most recent systems, where classification depends on mask predictions (e.g. [33, 10, 26]). Our approach follows the spirit of Fast R-CNN [12] that applies bounding-box classification and regression in parallel (which turned out to largely simplify the multi-stage pipeline of original R-CNN [13]).\n\n#### Two stages are RPN and  In the second stage, in addition to predicting the class and box offset, Mask R-CNN also produces a binary mask for each RoI.",
        "Formally, during training, we define a multi-task loss on each sampled RoI as L=L_{cls}+L_{box}+L_{mask}. The classification loss L_{cls} and bounding-box loss L_{box} are identical as those defined in [12]. The mask branch has a Km^{2}-dimensional output for each RoI, which encodes K binary masks of resolution m\\times m, one for each of the K classes. To this we apply a per-pixel sigmoid, and define L_{mask} as the average binary cross-entropy loss. For an RoI associated with ground-truth class k, L_{mask} is only defined on the k-th mask (other mask outputs do not contribute to the loss).\n\n#### For an RoI associated with ground-truth class k, L_{mask} is only defined on the k-th mask, where L is the average binary cross-entropy loss. The classification loss L Cls and bounding-box loss L_Box .",
        "A mask encodes an input object’s spatial layout. Thus, unlike class labels or box offsets that are inevitably collapsed into short output vectors by fully-connected (fc) layers, extracting the spatial structure of masks can be addressed naturally by the pixel-to-pixel correspondence provided by convolutions.\n\n#### Using class labels and box layouts make collapsing into short output vector by fully connected layers inevitable.",
        "At test time, the proposal number is 300 for the C4 backbone (as in [36]) and 1000 for FPN (as in [27]). We run the box prediction branch on these proposals, followed by non-maximum suppression [14]. The mask branch is then applied to the highest scoring 100 detection boxes. Although this differs from the parallel computation used in training, it speeds up inference and improves accuracy (due to the use of fewer, more accurate RoIs). The mask branch can predict K masks per RoI, but we only use the k-th mask, where k is the predicted class by the classification branch. The m\\timesm floating-number mask output is then resized to the RoI size, and binarized at a threshold of 0.5.\n\n#### various hyperparameter are:\nlearning rate of 0.02 ,bounding-box NMS with a threshold of 0.5 , floating-number mask output is  resized to the RoI size, and binarized at a threshold of 0.5.",
        "Mask R-CNN is conceptually simple: Faster R-CNN has two outputs for each candidate object, a class label and a bounding-box offset; to this we add a third branch that outputs the object mask. Mask R-CNN is thus a natural and intuitive idea. But the additional mask output is distinct from the class and box outputs, requiring extraction of much finer spatial layout of an object. Next, we introduce the key elements of Mask R-CNN, including pixel-to-pixel alignment, which is the main missing piece of Fast/Faster R-CNN.\n\n#### Yes it does.",
        "RoIPool [12] is a standard operation for extracting a small feature map (e.g., 7\\times7) from each RoI. RoIPool first quantizes a floating-number RoI to the discrete granularity of the feature map, this quantized RoI is then subdivided into spatial bins which are themselves quantized, and finally feature values covered by each bin are aggregated (usually by max pooling). Quantization is performed, e.g., on a continuous coordinate x by computing [x/16], where 16 is a feature map stride and [\\cdot] is rounding; likewise, quantization is performed when dividing into bins (e.g., 7\\times7). These quantizations introduce misalignments between the RoI and the extracted features. While this may not impact classification, which is robust to small translations, it has a large negative effect on predicting pixel-accurate masks.\n\n#### RoIPool performs coarse spatial quantization for feature extraction. Quantization introduces misalignments between the RoI and the extracted features. While this may not impact classification, it has a large negative effect on predicting pixel-accurate masks.",
        "We perform a thorough comparison of Mask R-CNN to the state of the art along with comprehensive ablations on the COCO dataset [28]. We report the standard COCO metrics including AP (averaged over IoU thresholds), AP{}_{50}, AP{}_{75}, and AP{}_{S}, AP{}_{M}, AP{}_{L} (AP at different scales). Unless noted, AP is evaluating using mask IoU. As in previous work [5, 27], we train using the union of 80k train images and a 35k subset of val images (trainval35k), and report ablations on the remaining 5k val images (minival). We also report results on test-dev [28].\n\n#### Metrics used for comparison are AP , multi-scale train/test, horizontal flip test, and online hard example mining (OHEM).",
        "Mask R-CNN is conceptually simple: Faster R-CNN has two outputs for each candidate object, a class label and a bounding-box offset; to this we add a third branch that outputs the object mask. Mask R-CNN is thus a natural and intuitive idea. But the additional mask output is distinct from the class and box outputs, requiring extraction of much finer spatial layout of an object. Next, we introduce the key elements of Mask R-CNN, including pixel-to-pixel alignment, which is the main missing piece of Fast/Faster R-CNN.\n\n#### The reason is that Faster R-CNN. has two outputs for each candidate object, a class label, and a bounding-box offset; to this, we add a third branch that outputs the object mask. But the additional mask output is distinct from the class and box outputs, requiring extraction of a much finer spatial layout of an object. This model performs better than the model presented due to RoIAlign but is 0.9 points box AP lower than Mask R- CNN.",
        "Mask R-CNN decouples mask and class prediction: as the existing box branch predicts the class label, we generate a mask for each class without competition among classes (by a per-pixel sigmoid and a binary loss). In Table 2b, we compare this to using a per-pixel softmax and a multinomial loss (as commonly used in FCN [30]). This alternative couples the tasks of mask and class prediction, and results in a severe loss in mask AP (5.5 points). This suggests that once the instance has been classified as a whole (by the box branch), it is sufficient to predict a binary mask without concern for the categories, which makes the model easier to train.\n\n#### it is sufficient to predict a binary mask without concern for the categories once the instance has been classified as a whole because Mask R-CNN decouples mask and class prediction: as the existing box branch predicts the class label,a mask is generated  for each class without competition among classes (by a per-pixel sigmoid and a binary loss)",
        "Our default instantiation predicts class-specific masks, i.e., one m\\timesm mask per class. Interestingly, Mask R-CNN with class-agnostic masks (i.e., predicting a single m\\timesm output regardless of class) is nearly as effective: it has 29.7 mask AP vs. 30.3 for the class-specific counterpart on ResNet-50-C4. This further highlights the division of labor in our approach which largely decouples classification and segmentation.\n\n#### Both  class specific or class agnostic masks in general is nearly as effective.",
        "Our framework can easily be extended to human pose estimation. We model a keypoint’s location as a one-hot mask, and adopt Mask R-CNN to predict K masks, one for each of K keypoint types (e.g., left shoulder, right elbow). This task helps demonstrate the flexibility of Mask R-CNN.\n\n#### Yes we can use Faster R-CNN for human pose estimation.",
        "Our framework can easily be extended to human pose estimation. We model a keypoint’s location as a one-hot mask, and adopt Mask R-CNN to predict K masks, one for each of K keypoint types (e.g., left shoulder, right elbow). This task helps demonstrate the flexibility of Mask R-CNN.\n\n#### A keypoint's position is represented as a one-hot mask, then adopt Mask R-CNN to predict K masks, one for each of K keypoint types (e.g., left shoulder, right elbow) Each keypoint is seen as a single-hot binary mask, with minimum modification that may be done to identify instance-specific poses.",
        "More importantly, we have a unified model that can simultaneously predict boxes, segments, and keypoints while running at 5 fps. Adding a segment branch (for the person category) improves the AP{}^{\\text{kp}} to 63.1 (Table 4) on test-dev. More ablations of multi-task learning on minival are in Table 5. Adding the mask branch to the box-only (i.e., Faster R-CNN) or keypoint-only versions consistently improves these tasks. However, adding the keypoint branch reduces the box/mask AP slightly, suggesting that while keypoint detection benefits from multitask training, it does not in turn help the other tasks. Nevertheless, learning all three tasks jointly enables a unified system to efficiently predict all outputs simultaneously (Figure 7).\n\n#### mask R-CNN is bettar than Faster R-CNN in multitasking",
        "Our method, called Mask R-CNN, extends Faster R-CNN [36] by adding a branch for predicting segmentation masks on each Region of Interest (RoI), in parallel with the existing branch for classification and bounding box regression (Figure 1). The mask branch is a small FCN applied to each RoI, predicting a segmentation mask in a pixel-to-pixel manner. Mask R-CNN is simple to implement and train given the Faster R-CNN framework, which facilitates a wide range of flexible architecture designs. Additionally, the mask branch only adds a small computational overhead, enabling a fast system and rapid experimentation.\n\n#### Adding a segment branch improves the AP, additionally, the mask branch only adds a small computational overhead, enabling a fast system and rapid experimentation",
        "Mask R-CNN is conceptually simple: Faster R-CNN has two outputs for each candidate object, a class label and a bounding-box offset; to this we add a third branch that outputs the object mask. Mask R-CNN is thus a natural and intuitive idea. But the additional mask output is distinct from the class and box outputs, requiring extraction of much finer spatial layout of an object. Next, we introduce the key elements of Mask R-CNN, including pixel-to-pixel alignment, which is the main missing piece of Fast/Faster R-CNN.\n\n#### Mask R-CNN has pixel-to-pixel alignment whereas Faster R-CNN doesn't.Mask R-CNN, extends Faster R-CNN by adding a branch for predicting segmentation masks on each Region of Interest (RoI), in parallel with the existing branch for classification and bounding box regression",
        "Instance segmentation is challenging because it requires the correct detection of all objects in an image while also precisely segmenting each instance. It therefore combines elements from the classical computer vision tasks of object detection, where the goal is to classify individual objects and localize each using a bounding box, and semantic segmentation, where the goal is to classify each pixel into a fixed set of categories without differentiating object instances.111Following common terminology, we use object detection to denote detection via bounding boxes, not masks, and semantic segmentation to denote per-pixel classification without differentiating instances. Yet we note that instance segmentation is both semantic and a form of detection. Given this, one might expect a complex method is required to achieve good results. However, we show that a surprisingly simple, flexible, and fast system can surpass prior state-of-the-art instance segmentation results.\n\n#### In this paper, It is shown that a surprisingly simple, flexible, and fast system can surpass prior state-of-the-art instance segmentation results. We use object detection to denote detection via bounding boxes, not masks, and semantic segmentation to denote per-pixel classification without differentiating instances. Given this, one might expect a complex method to be required to achieve good results.",
        "To evaluate SELF-INSTRUCT empirically, we run this framework on GPT3 (Brown et al., 2020), which is a vanilla LM (§4). The iterative SELF-INSTRUCT process on this model leads to about 52k instructions, paired with about 82K instance inputs and target outputs. We observe that the resulting data provides a diverse range of creative tasks and over 50% of them have less than 0.3 ROUGE-L overlaps with the seed instructions (§4.2). On this resulting data, we build GPT3SELF-INST by fine-tuning GPT3 (i.e., the same model used for generating the instructional data). We evaluate GPT3SELF-INST in comparison to various other models on both typical NLP tasks included in SUPER-NATURALINSTRUCTIONS (Wang et al., 2022), and a set of new instructions that are created for novel usage of instruction-following models (§5). The SUPERNI results indicate that GPT3SELF-INST outperforms GPT3 (the original model) by a large margin (+33.1%) and nearly matches the performance of InstructGPT001. Moreover, our human evaluation on the newly-created instruction set shows that GPT3SELF-INST demonstrates a broad range of instruction-following ability, outperforming models trained on other publicly available instruction datasets and leaving only a 5% gap behind InstructGPT001.\n\n#### Based on the introduction, it appears as though the authors may have finetuned their GPT3-Self Instruct model with 82k samples.",
        "Our pipeline for generating the instruction data consists of four steps: 1) instruction generation, 2) identifying whether the instruction represents a classification task or not, 3) instance generation with the input-first or the output-first approach, and 4) filtering low-quality data.\n\n#### The main reason why this is a crucial step is because the authors’ pipeline uses a different approach for classification tasks. For non-classification tasks, the authors first prompt a language model to come up with the input fields require, then provide sample inputs, for which the language model generates outputs. However, for classification tasks, the authors first generate the list of classes, and then require the model to provide an example for that instruction for each class. They do this because the first approach, used for non-classification instructions, does not work well for unbalanced classes. This step, of identifying classification tasks, is important since it is not possible to use the same generation technique for both classification and non-classification tasks effectively with the same generation method."
    ]
}